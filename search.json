[
  {
    "objectID": "blog/2024-08-10-introducing-surveydown/index.html",
    "href": "blog/2024-08-10-introducing-surveydown/index.html",
    "title": "Introducing {surveydown}: A markdown-based framework for generating surveys with Quarto and shiny (that now exists!!!)",
    "section": "",
    "text": "You may have read my previous blog post about an R packaged I called ‚Äúsurveydown‚Äù. That post described some ideas I was thinking about for a package that would allow people to design surveys using markdown and R. But the package didn‚Äôt exist yet, it was just an idea.\nWell, I have good news: the package now exists!\nIn this post, I‚Äôm going to show you a quick overview of the {surveydown} R package for making markdown-based surveys as well as a little about why we built surveydown."
  },
  {
    "objectID": "blog/2024-08-10-introducing-surveydown/index.html#open-source",
    "href": "blog/2024-08-10-introducing-surveydown/index.html#open-source",
    "title": "Introducing {surveydown}: A markdown-based framework for generating surveys with Quarto and shiny (that now exists!!!)",
    "section": "Open source",
    "text": "Open source\nsurveydown is built entirely with open-source technologies, making it transparent and customizable. Best of all, no expensive licenses! Just install and use it!"
  },
  {
    "objectID": "blog/2024-08-10-introducing-surveydown/index.html#own-your-data",
    "href": "blog/2024-08-10-introducing-surveydown/index.html#own-your-data",
    "title": "Introducing {surveydown}: A markdown-based framework for generating surveys with Quarto and shiny (that now exists!!!)",
    "section": "Own your data",
    "text": "Own your data\nWith surveydown, you retain full ownership and control of your survey data. The responses are stored in your own Supabase database, ensuring that you have complete access to the data. This is particularly important for researchers dealing with sensitive information or those who need to comply with specific data protection regulations. We‚Äôre still working on enabling you to use your own hosted database, which will provide even more flexibility."
  },
  {
    "objectID": "blog/2024-08-10-introducing-surveydown/index.html#ease-of-editing",
    "href": "blog/2024-08-10-introducing-surveydown/index.html#ease-of-editing",
    "title": "Introducing {surveydown}: A markdown-based framework for generating surveys with Quarto and shiny (that now exists!!!)",
    "section": "Ease of editing",
    "text": "Ease of editing\nDesigning a survey in surveydown is a pretty straightforward process. The markdown-based approach allows for quick modifications and easy navigation through your survey. And since it‚Äôs built on Quarto, you can use all of the features of Quarto to make your survey look great, like changing the theme, adding custom CSS, etc. You can also easily preview your survey as you edit it, and even run your survey locally to test it out before you deploy it, either with a button click in RStudio or with a quarto serve command in the terminal."
  },
  {
    "objectID": "blog/2024-08-10-introducing-surveydown/index.html#did-i-mention-you-can-run-r-code-in-your-survey",
    "href": "blog/2024-08-10-introducing-surveydown/index.html#did-i-mention-you-can-run-r-code-in-your-survey",
    "title": "Introducing {surveydown}: A markdown-based framework for generating surveys with Quarto and shiny (that now exists!!!)",
    "section": "Did I mention you can run R code in your survey?",
    "text": "Did I mention you can run R code in your survey?\nEvery surveydown survey uses R code chunks for questions. But you can also insert R code for all sorts of other things. For example, if you wanted to randomize the values shown in a question, you could write some R code for that. Want to insert a plot of something? Write a little ggplot code. You can also add interactive components to your surveys, such as showing a respondent how their responses compare to others in real time."
  },
  {
    "objectID": "blog/2024-08-10-introducing-surveydown/index.html#easy-version-control-and-collaboration",
    "href": "blog/2024-08-10-introducing-surveydown/index.html#easy-version-control-and-collaboration",
    "title": "Introducing {surveydown}: A markdown-based framework for generating surveys with Quarto and shiny (that now exists!!!)",
    "section": "Easy version control and collaboration",
    "text": "Easy version control and collaboration\nBecause the entire survey is defined in a single plain text file, surveydown naturally integrates with version control systems like Git. This allows you to track changes over time, collaborate with team members, and maintain a clear history of your survey‚Äôs development."
  },
  {
    "objectID": "blog/2024-08-10-introducing-surveydown/index.html#reproducible",
    "href": "blog/2024-08-10-introducing-surveydown/index.html#reproducible",
    "title": "Introducing {surveydown}: A markdown-based framework for generating surveys with Quarto and shiny (that now exists!!!)",
    "section": "Reproducible",
    "text": "Reproducible\nSurveydown promotes reproducible research by allowing you to define your entire survey in a single, self-contained plain text document. This has a ton of benefits:\n\nWant someone else to be able to reproduce your experiment? Just give them the .qmd file and any other files they need (e.g., images, data, etc.), and they can reproduce your survey on their own computer.\nWant to print out your survey for an appendix? Render the survey with all pages visible then print it to pdf.\nWant others to see your survey live? Just set the database into pause mode and your survey will function without recording any responses.\n\nReproducibility is something we had in mind from the start with this project, and we‚Äôve tried to make it as easy as possible for your surveydown surveys to be fully reproducible."
  },
  {
    "objectID": "blog/2024-08-10-introducing-surveydown/index.html#getting-started",
    "href": "blog/2024-08-10-introducing-surveydown/index.html#getting-started",
    "title": "Introducing {surveydown}: A markdown-based framework for generating surveys with Quarto and shiny (that now exists!!!)",
    "section": "Getting started",
    "text": "Getting started\nAfter getting everything installed, we recommend starting with a template survey project. To do so, run the following in the R console:\n\nsurveydown::sd_create_survey(\"path/to/folder\")\n\nThis will create a folder with the following files:\n\nexample.qmd: a template survey you should edit.\nexample.Rproj: An RStudio project file (helpful if you‚Äôre working in RStudio)\n_extensions: A folder with the surveydown Quarto extension needed to make everything work (don‚Äôt modify this).\n\nIf you have the example open in RStudio, you can click the ‚ÄúRun document‚Äù button, or in your terminal run quarto serve example.qmd. Either approach should render the example survey into a shiny app that you can preview in a browser. Don‚Äôt worry just yet about setting up your database or making the survey live - for now, we‚Äôre going to focus on designing the survey and running it locally to preview it. The example survey should look like this:"
  },
  {
    "objectID": "blog/2024-08-10-introducing-surveydown/index.html#adding-pages",
    "href": "blog/2024-08-10-introducing-surveydown/index.html#adding-pages",
    "title": "Introducing {surveydown}: A markdown-based framework for generating surveys with Quarto and shiny (that now exists!!!)",
    "section": "Adding pages",
    "text": "Adding pages\nIn surveydown, pages are delineated using ‚Äúfences‚Äù, like this:\n::: {#welcome .sd-page}\n\nPage 1 content here\n\n:::\n\n::: {#page2 .sd-page}\n\nPage 2 content here\n\n:::\nAs you can see, we use three colon symbols :::, called a ‚Äúfence‚Äù, to mark the start and end of pages. This notation is commonly used in Quarto for a variety of use cases, like defining subfigures in images.\nIn the starting fence, you need to define a page name (e.g.¬†welcome and page2 in the example above) and you need to define the class as .sd-page. Then anything you put between the page fences will appear on that page.\nTo navigate to the next page, you need to insert a sd_next() function call inside a code chunk, like this:\n\n```{r}\nsd_next(next_page = 'page2')\n```\n\nThe above code chunk will create a ‚ÄúNext‚Äù button that goes on to page 2 that looks like this:\n\n\nNext\n\n\nYou would need to place the code chunk in between the ::: fences of the welcome page in order to have a ‚ÄúNext‚Äù button that goes on to page 2. You can also send the user to other pages by just changing the next_page argument. Finally, you can also change the label of the button by changing the label argument, like this:\n\n```{r}\nsd_next(next_page = 'page2', label = 'Next page')\n```\n\n\n\nNext page"
  },
  {
    "objectID": "blog/2024-08-10-introducing-surveydown/index.html#adding-questions",
    "href": "blog/2024-08-10-introducing-surveydown/index.html#adding-questions",
    "title": "Introducing {surveydown}: A markdown-based framework for generating surveys with Quarto and shiny (that now exists!!!)",
    "section": "Adding questions",
    "text": "Adding questions\nEvery survey question is created using the sd_question() function inside a code chunk. The question type is defined by the type argument. For example, to add a multiple choice question, you could insert the following code chunk:\n\n```{r}\nsd_question(\n  type  = 'mc',\n  id    = 'penguins',\n  label = \"Which is your favorite type of penguin?\",\n  option = c(\n    'Ad√©lie'    = 'adelie',\n    'Chinstrap' = 'chinstrap',\n    'Gentoo'    = 'gentoo'\n  )\n)\n```\n\nThe above code chunk will create a multiple choice question that looks like this:\n\n\n\n\nWhich is your favorite type of penguin? *\n\n\n\n\n\nAd√©lie\n\n\n\n\n\nChinstrap\n\n\n\n\n\nGentoo\n\n\n\n\n\n\n\nThe sd_question() function can be used to create a variety of question types, like text input, select drop down choices, and more by changing the type argument.\nThe function has many other arguments for customizing the look and feel of the question (e.g., height and width, etc.)."
  },
  {
    "objectID": "blog/2024-08-10-introducing-surveydown/index.html#the-server-chunk",
    "href": "blog/2024-08-10-introducing-surveydown/index.html#the-server-chunk",
    "title": "Introducing {surveydown}: A markdown-based framework for generating surveys with Quarto and shiny (that now exists!!!)",
    "section": "The server chunk",
    "text": "The server chunk\nAt the very bottom of the .qmd file is a special ‚Äúserver‚Äù code chunk (that‚Äôs the #| context: server bit) that defines the app server. This is where you can customize and control the survey flow logic as well as where you define the database that will store the survey response data. It looks like this:\n\n```{r}\n#| context: server\n\n# Define the database settings\ndb &lt;- sd_database()\n\n# Define the configuration settings\nconfig &lt;- sd_config()\n\n# The sd_server() function initiates your survey - don't change this\nsd_server(\n  input   = input,\n  session = session,\n  config  = config,\n  db      = db\n)\n```\n\nThe sd_database() function is where you set up your database. The sd_server() function makes everything run, which you can safely ignore - just don‚Äôt change it and all will be good!\nThe middle part (the sd_config() function) is where you can define custom control logic for the survey, such as conditional display (conditionally displaying a question based on responses to questions), or conditional skip (conditionally sending the respondent to a page based on responses to questions)."
  },
  {
    "objectID": "blog/2024-08-10-introducing-surveydown/index.html#going-live",
    "href": "blog/2024-08-10-introducing-surveydown/index.html#going-live",
    "title": "Introducing {surveydown}: A markdown-based framework for generating surveys with Quarto and shiny (that now exists!!!)",
    "section": "Going live!",
    "text": "Going live!\nOnce you are happy with your survey, you can deploy it live to any server of your choice. Since it‚Äôs a shiny app, you can deploy it to shinyapps.io for free!"
  },
  {
    "objectID": "blog/2024-08-10-introducing-surveydown/index.html#conditional-display",
    "href": "blog/2024-08-10-introducing-surveydown/index.html#conditional-display",
    "title": "Introducing {surveydown}: A markdown-based framework for generating surveys with Quarto and shiny (that now exists!!!)",
    "section": "Conditional display",
    "text": "Conditional display\nLet‚Äôs say we had a fourth option for ‚Äúother‚Äù in our multiple choice question about penguins. If the respondent chose it, you may want a second question to popup that allows them to specify the other penguin type. To implement this, you would need to define both questions, e.g.:\n\n```{r}\nsd_question(\n  type  = 'mc',\n  id    = 'penguins',\n  label = \"Which is your favorite type of penguin?\",\n  option = c(\n    'Ad√©lie'    = 'adelie',\n    'Chinstrap' = 'chinstrap',\n    'Gentoo'    = 'gentoo',\n    'Other'     = 'other'\n  )\n)\n\nsd_question(\n  type  = \"text\",\n  id    = \"penguins_other\",\n  label = \"Please specify the other penguin type:\"\n)\n```\n\nThen in the server code chunk, you could use the show_if argument to define that the penguins_other question would only be shown if the respondent chose the other option in the penguins question, like this:\n\nconfig &lt;- sd_config(\n  show_if = tibble::tribble(\n    ~question_id,  ~question_value, ~target,\n    \"penguins\",    \"other\",         \"penguins_other\"\n  )\n)\n\nThis will make the penguins_other question only appear if the respondent chose the other option in the penguins question, like this:\n\n\n\n\nHere we‚Äôre using the tibble::tribble() function to define a data frame with three columns:\n\nquestion_id: The id of the triggering question.\nquestion_value: The triggering value.\ntarget: The id of the target question to display.\n\nYou don‚Äôt have to use tibble::tribble(), and in fact if you have a lot of show_if conditions, then you could create a csv file with all of your conditions in it and read it in to set the show_if conditions (just make sure the header has the same three column names), e.g.:\n\nconfig &lt;- sd_config(\n  show_if = readr::read_csv('path/to/show_if_conditions.csv')\n  )\n)"
  },
  {
    "objectID": "blog/2024-08-10-introducing-surveydown/index.html#conditional-skip",
    "href": "blog/2024-08-10-introducing-surveydown/index.html#conditional-skip",
    "title": "Introducing {surveydown}: A markdown-based framework for generating surveys with Quarto and shiny (that now exists!!!)",
    "section": "Conditional skip",
    "text": "Conditional skip\nOften times you‚Äôll want to screen people out of a survey based on responses to questions. For example, let‚Äôs say you only wanted to only include people who own a vehicle. On your first page (e.g., with page name welcome), you could screen out people who do not own a vehicle.\nFirst, define a question about their vehicle ownership, e.g.:\n\n```{r}\nsd_question(\n  type  = 'mc',\n  id    = 'vehicle_ownership',\n  label = \"Do you own your vehicle?\",\n  option = c(\n    'Yes' = 'yes',\n    'No'  = 'no'\n  )\n)\n```\n\nThen in the server code chunk, you could use the skip_if argument in sd_config() to define the behavior of the next button on the welcome page, like this:\n\nconfig &lt;- sd_config(\n  skip_if = tibble::tribble(\n    ~question_id,        ~question_value, ~target,\n    \"vehicle_ownership\", \"no\",            \"screenout\"\n  )\n)\n\nThis sets up a condition where if the respondent chooses no on the vehicle_ownership question, they will be sent to a page named screenout. You could put such a page at the end of the survey, something like this:\n::: {#screenout .sd-page}\n\nSorry, but you are not qualified to take our survey.\n\n:::\nNotice that I don‚Äôt have a sd_next() on this screenout page. That is how you define an end point for the survey taker. If there‚Äôs no ‚ÄúNext‚Äù button, then they cannot navigate anywhere else, so the survey is over."
  },
  {
    "objectID": "blog/2024-08-10-introducing-surveydown/index.html#required-responses",
    "href": "blog/2024-08-10-introducing-surveydown/index.html#required-responses",
    "title": "Introducing {surveydown}: A markdown-based framework for generating surveys with Quarto and shiny (that now exists!!!)",
    "section": "Required responses",
    "text": "Required responses\nBy default, no questions are required. However, you can make questions required by adding the question id to the required argument in sd_config(), like this:\n\nconfig &lt;- sd_config(\n  required_questions = c(\"vehicle_ownership\", \"penguins_other\")\n)\n\nThis will make the respondent unable to proceed until they have answered the required questions. It will also place a red asterisk (*) next to the question label to indicate that the question is required.\nYou can also make all questions required by setting all_questions_required = TRUE like this:\n\nconfig &lt;- sd_config(\n  all_questions_required = TRUE\n)"
  },
  {
    "objectID": "blog/2024-08-10-introducing-surveydown/index.html#reactivity",
    "href": "blog/2024-08-10-introducing-surveydown/index.html#reactivity",
    "title": "Introducing {surveydown}: A markdown-based framework for generating surveys with Quarto and shiny (that now exists!!!)",
    "section": "Reactivity",
    "text": "Reactivity\nOne other feature that is particularly powerful is the ability to use R code in your survey via Shiny‚Äôs reactive programming. This allows you to make your survey more interactive and to use the full power of R to create custom functionality.\n\nDemo 1: Displaying content based on previous responses\nLet‚Äôs say you wanted to create a survey that asked the respondent‚Äôs name, and then displayed a personalized message based on their name. You could do this by first asking their name:\n\nsd_question(\n  type  = \"text\",\n  id    = \"name\",\n  label = \"What is your name?\"\n)\n\nThen you can use the sd_display_value(\"name\") function to display the value of the name question in other parts of your survey. For example:\n\nWelcome, `r sd_display_value(\"name\")`!\n\nWhich would render as something like ‚ÄúWelcome, Dave!‚Äù (assuming the respondent entered ‚ÄúDave‚Äù in the name question). This works because the sd_display_value() function is reactive, meaning it will update the display based on the respondent‚Äôs responses.\n\n\nDemo 2: Displaying randomized question labels\nLet‚Äôs say you wanted to show a series of questions, but you wanted to randomize the labels shown for each question. You could do this by first defining a list of labels, and then using the sd_question_reactive() function to create a question that will display a random label from the list.\nFor example, let‚Äôs ask the respondent to rate different car brands from a random set of brands. You could first pre-define the randomized sets of brands for each respondent and store it as a csv file, like this:\n\nbrands &lt;- c(\"Toyota\", \"Ford\", \"Chevrolet\", \"Honda\", \"Nissan\", \"Tesla\")\ndesign &lt;- data.frame(\n  respondent_id = rep(1:10, each = 3),\n  brand = unlist(lapply(1:10, function(x) sample(brands, 3, replace = FALSE)))\n)\nwrite_csv(design, \"design.csv\")\n\nThis would make a design file that looks like this:\n\n\n  respondent_id     brand\n1             1     Honda\n2             1      Ford\n3             1    Nissan\n4             2      Ford\n5             2    Nissan\n6             2 Chevrolet\n\n\nNote that this would not be done in your survey.qmd file - it‚Äôs just a one-time thing to create the design (probably stored in an R file).\nThen in your server code chunk, you could read in the design file and use it to randomize the labels for each question based on a randomly chosen respondent:\n\ndesign &lt;- read_csv(\"design.csv\")\nresp_id &lt;- sample(design$respondent_id, 1)\ndf_resp &lt;- design %&gt;% filter(respondent_id == resp_id)\n\noptions &lt;- c(1, 2, 3)\nnames(options) &lt;- df_resp$brand\n\nsd_question_reactive(\n  type  = \"mc\",\n  id    = \"brands\",\n  label = \"Which of these brands do you like best?\",\n  option = options\n)\n\nHere the sd_question_reactive() function is used because the labels depend on the randomly chosen respondent. This means the labels will be different for each respondent.\nSince this is a reactive question, this code must be placed inside the server code chunk, not where you want it to appear in the survey. To define where in the survey the question should appear, you use the sd_display_question() function with the id set to the same value as the id in the sd_question_reactive() function, like this:\n\nsd_display_question(id = \"brands\")\n\nNow the brands question will be displayed in the survey where you put this code chunk.\nNote that all question responses are automatically saved to the database, but if you wanted to store some other value (e.g.¬†the randomly chosen respondent_id), you could do that with the sd_store_value() function, like this:\n\nsd_store_value(resp_id)"
  },
  {
    "objectID": "blog/2021-07-03-in-search-of-keyboard-nirvana/index.html",
    "href": "blog/2021-07-03-in-search-of-keyboard-nirvana/index.html",
    "title": "In search of keyboard nirvana",
    "section": "",
    "text": "When I entered grad school, I started spending far more time typing on a computer than I had before. After a few months in, I started searching for a better typing experience and ways to reduce the amount of keystrokes needed to get the job done. Now a decade later, I have most definitely taken the red pill and become far more aware of solutions and technologies I never would have imagined back then. This post is a brief summary of my journey in search of keyboard nirvana.\n\n\n\n\n\nMe back in 2011 reading about mechanical keyboards.\n\n\n\n\n\nMechanical keyboards\nOne of my first roommates in graduate school was a remarkably fast typist and used this loud, clacky mechanical keyboard (I had to wear earplugs or listen to music to get anything done when he was typing). Curiosity got the best of me, and after trying out his keyboard for a few minutes I immediately understood why people use mechanical keyboards. There is something about the combination of aural and tactile feedback you get when typing on a keyboard with mechanical switches that makes the typing experience just‚Ä¶better. But it wasn‚Äôt just aesthetically better - I was able to type at a faster speed and with fewer errors when using a mechanical keyboard.\nNeedless to say, I immediately started searching for a mechanical keyboard to replace my crummy old Apple keyboard. Somewhere along my searching, I came across articles about people who ‚Äúre-mapped‚Äù their keyboards so that some key presses would trigger other events. This seemed like a powerful idea for reducing key strokes, and after a bit more searching I discovered Karabiner Elements for mac. This software is invaluable. I made loads of customizations to simplify common operations. I became so dependent on it that I decided to design a custom key cap set for my first mechanical keyboard from WASD Keyboards to match my Karabiner Elements settings\n\n\n\n\n\nA rendering of my first custom mechanical keyboard, from WASD Keyboards.\n\n\n\n\n\n\nRemapping your keyboard\nThere are many software options for customizing and re-mapping your keyboard. I use Karabiner Elements for mac, but AutoHotkey is probably the most popular option for Windows users.\nThe use cases for these programs are endless, but I want to highlight one very powerful idea: adding keyboard layers. Every keyboard has at least two layers: the normal layer, and the ‚Äúshift‚Äù layer that converts lower-case letters to upper-case and numbers to symbols. Unfortunately, some of the most useful keys (e.g.¬†navigation arrows) are not conveniently located and require you to move your hand every time you want to use them. So one of the first things I implemented in re-mapping my keyboard was to try and move those navigation arrows back to ‚Äúhome row‚Äù:\n\n\n\n\n\nWhere I wanted to relocate the navigation arrows.\n\n\n\n\nMy solution was to introduce a ‚ÄúCapslock‚Äù layer. This layer works just like the shift layer, except it gets triggered when holding down the otherwise rarely-used Capslock key. This layer uses J / I / K / L as arrow keys for navigating the cursor selecting text, and it re-maps the S / D / F keys into cut, copy, and paste as well as N and H into backspace and delete:\n\n\n\n\n\nMy capslock layer.\n\n\n\n\nAs you can see in the demo below, this modification enables me to navigate the cursor and edit code / text without ever having to leave home row:\n\n\n\n\nYour browser does not support HTML video. \n\nI use Karabiner Elements for lots of other things too, like:\n\nLaunching applications like Google Chrome or Terminal with a single hotkey.\nOpening Google Chrome to a webpage (e.g.¬†gmail) with a single hotkey.\nTyping my email send off (\"Cheers,\\nJP\") with a single hotkey.\n\nYou can see all of my Karabiner Elements settings here.\n\n\nTowards better ergonomics with split keyboards\nTypical keyboard layouts are not that ergonomic, and after several years of using my WASD keyboard I eventually started developing wrist pain. My specific pain was from prolonged ulnar deviation, where the hands are bent outward at the wrist joint. So I started searching for a split keyboard to be able to hold my hands at a more natural position while typing (split keyboards actually fix a lot of ergonomic problems).\n\n\n\n\n\nSplit keyboards fix a lot of ergonomic problems, like ulnar deviation.\n\n\n\n\nAfter doing a lot of research on different split boards, I decided to try out the Ergodox EZ, a highly-rated (albeit quite expensive) keyboard. I chose the Ergodox EZ as it had a 30-day return policy (though you have to pay the return shipping), and because the company that makes the Ergodox (ZSA) has some of the most highly-rated customer service of any company ever. I figured if I didn‚Äôt like it, I could probably return it without too much hassle.\n\n\n\n\n\nThe Ergodox EZ.\n\n\n\n\nOne of the other features that attracted me to the Ergodox is their Oryx configurator software. This is an in-browser web application that enables you to fully customize every single key on the keyboard through a very user-friendly UI. All of a sudden, many of the key features that I loved about Karabiner Elements (such as re-mapping my Capslock key to use navigation arrows on the home row) could be programmed directly into the keyboard itself. This meant I could use the keyboard on any computer and have the same re-mapped keys at the ready.\n\n\n\n\n\nScreenshot of the Oryx software.\n\n\n\n\nThere are a lot of things to like about the Ergodox. First, the Oryx software was a game changer. Being able to directly control what each key does gave me all sorts of new ideas that made my typing incredibly efficient and far more comfortable than anything I had used in the past. But the single biggest improvement was probably the thumb key cluster. Your thumbs are quite strong, but on most keyboards they‚Äôre only useful for the space bar and maybe some contorted use of modifier keys. In contrast, the Ergodox has several keys right under each thumb, enabling far more efficient and comfortable access to using your thumb to type.\nMy single biggest improvement in using the thumb keys was to swap what used to be my capslock layer trigger to a thumb key. Now instead of holding down the capslock key with my much weaker left pinky finger to trigger a new layer, I could use my much stronger left thumb, freeing up my left pinky finger to actually type key strokes.\nAll together, the Ergodox EZ was a major improvement in my typing, both in terms of ergonomics and efficiency. My typing speed also increased from ~70 on an Apple keyboard to ~90 on the Ergodox. But after about six months of use, I still found some things weren‚Äôt quite right with the board. This review is a great summary of the pros and cons of the Ergodox, but my single biggest complaint was the precise location of the thumb key clusters. Most thumb keys were just too far away to be useful, and even the main thumb keys were a little too far out for my hands.\n\n\n\n\n\nMe after about 6 months of using the Ergodox EZ thumb cluster.\n\n\n\n\n\n\nBuilding my own split keyboard\nIf you‚Äôre at the point where you‚Äôre typing on an Ergodox EZ, it doesn‚Äôt take long before you start realizing there‚Äôs an entire world out there of DIY keyboard hobbists obsessed with ergonomics and custom built keyboards. A short perusal of r/ErgoMechKeyboards and you‚Äôll see a wide range of bizarre keyboards you never would have imagined existed, with names like Iris, Lily58, Kyria, and Corne.\n\n\n\n\n\nMe after first discovering r/ErgoMechKeyboards.\n\n\n\n\nAs an engineering faculty member at George Washington University, many of the tools needed to dive into building my own keyboard (e.g.¬†a soldering iron) were readily available to me via the makers space in the GW Innovation Center. So I convinced myself that making a keyboard would be a fun excuse to learn some new skills and meet more of the engineering students at GW (this was in 2018, only a few months after I had started at GW). I decided to make a Lily58, mostly because the parts were quite cheap and available at keyhive.xyz.\n\n\n\n\n\nMe and my first ever DIY keyboard (a Lily58), assembled (mostly) in the GW Innovation Center.\n\n\n\n\nThe project of building a Lily58 was a great learning experience, and I am more greatful for the people I met in the GWIC than in what I learned about building keyboards. Turns out building a keyboard covers quite a lot of engineering skills, including:\n\nSoldering microelectronics and circuitry.\nCAD design for making case components.\n3D printing and laser cutting those case components.\nProgramming the keyboard firmware.\n\nI got to work with some talented GW undergraduates on Friday afternoons working on each of these tasks. Someone even got this very promotional-esque shot of me working with a student soldering some microelectronics:\n\n\n\n\n\nA very staged-looking (but actually wasn‚Äôt staged) photo of me working with a student in the GWIC.\n\n\n\n\nI have to say that working with student in the GWIC has been a real highlight of my little keyboard journey. Given that most of what I do and teach as a professor involves the virtual space of data analysis and programming, it was great to get to do some ‚Äúhands on‚Äù engineering tasks with students outside of the classroom.\n\n\nTowards an ‚ÄúEnd Game‚Äù\nIn the world of DIY keyboards, many speak of a mythical ‚ÄúEnd Game‚Äù keyboard - one that is so perfected that you hang up your soldering iron, never to build another keyboard again. Of course, in reality each keyboard project is a step in another direction that almost inevitably leads to yet another keyboard project. It‚Äôs a similar logic to biking rule #12:\n\n\n\n\n\n‚Ä¶where N is the current number of bikes owned.\n\n\n\n\nIn my case, I have now built no less than four keyboards, so I believe I can officially call building custom keyboards a hobby (problem?).\n\n\n\n\n\nMost peoples‚Äô reaction after I show them my keyboards.\n\n\n\n\nFor each new keyboard project, I either found something new I wanted to try out, or I found something I didn‚Äôt quite like about the last project (or both). For my Lily58, the biggest issue was simply the build quality wasn‚Äôt that high. I used sockets to hold the key switches in place so I could swap out different switches, but whenever I traveled with the board many of the switches would fall out, which got annoying pretty fast.\nSo I decided to build an Iris keyboard ‚Äì a close cousin to the Lily58 in terms of the key layout. I also decided to keep a detailed record of my build process as I learned so many tiny details in the process that I figured could help others looking to build their own keyboards (e.g.¬†installing a rotary encoder).\n\n\n\n\n\nMy second keyboard - an Iris Rev 2.\n\n\n\n\n\nA rotary what now?\n\nOn most of my DIY boards, I have a rotary encoder on the right hand side, which is like a rotational switch. I use them for a variety of things. Perhaps the most obvious might be as a volume knob, but I also have my keyboards configured such that the rotary encoder triggers different behaviors depending on the active layer, including volume control, scrolling up and down, scrolling left and right, and zooming in and out.\n\n\n\n\n\nA rotary encoder I mounted on my Iris keyboard.\n\n\n\n\nMy Iris was a fantastic keyboard. Again, I worked a lot on it in the GWIC, using the 3D printers to print the case and soldering equipment to assemble much of the components. After some heavy use though, the rotary encoder broke off, and it was essentially irreparable, so I decided to build what seemed like a more robust keyboard ‚Äì the Kyria.\n\n\n\n\n\nMy third keyboard - a Kyria Rev 1.\n\n\n\n\nDesigned by Thomas Baart, the Kyria keyboard has arguably the best assembly documentation of any keyboard kit I‚Äôve seen, and as such it is usually the board I recommend to first-time builders. Thomas put a lot of thought into the design of the board, and in general I would say this is probably the best quality board I have built (more photos here, and details about the board here). I also learned a bit more about using CAD with this keyboard as I modified the 3D printed case using Fusion 360 (thanks again to GW‚Äôs institutional license!). That said, the layout of this board just isn‚Äôt quite as comfortable for my hands as the Iris layout. In particular, the column stagger is much more aggressive, and it just doesn‚Äôt quite work for my hands.\nSo that leads me to my latest (and hopefully last?) build: a Wireless Corne (more photos here). The Corne keyboard has a near identical layout with the Iris, minus the number row. By this point, I had moved to using as many as five different keyboard layers, one of which being a numpad on my right hand, so I no longer used the number row anyway. Going wireless was also a very attractive option as I enjoy working in coffee shops and libraries on my laptop, so traveling with a compact and wireless keyboard would be much more convenient. As with my Iris, I kept a detailed build log.\n\n\n\n\n\nMy (final?) keyboard - a Wireless Corne.\n\n\n\n\n\n\nFirmware\nI would be remiss if I didn‚Äôt at least mention the incredible open source software that runs all of these DIY keyboards. The main software most people use to power their keyboards is QMK Firmware. The software has become so developed that there‚Äôs even an open source keyboard configurator, similar to the Oryx software for the Ergodox. QMK is packed with loads of features, but perhaps most importantly is the highly flexible layer configurations, enabling you to map multiple layers so that your hands rarely ever need to leave the home row position.\nQMK‚Äôs wireless cousin is ZMK Firmware, which I am running on my wireless Corne. ZMK is newer and shares many of the same features as QMK, though not quite as many. It is also designed quite differently, and I would say it has a slightly steeper learning curve compared to QMK. If you‚Äôre newer to building your own keyboard, using QMK with the GUI configurator.\n\n\nTrade offs in going split\nThere are several drawbacks to adopting a split keyboard, but I want to discuss two common ones:\n\nCost\nLearning curve\n\n\nCost\nPerhaps one of the biggest drawbacks of split keyboards is that they generally cost more than traditional keyboards. Nonetheless, there are lots of good options for under or around $100 USD, such as:\n\nMicrosoft Scult ($60)\nKINESIS Freestyle ($99.00)\nLogitech ERGO K860 ($125.00)\n\nSome of the more premium split boards can cost quite a lot more, such as the Ergodox EZ at ~$350. And even building your own split keyboard isn‚Äôt all that cheap, with the final cost usually ranging from ~$100 to $250 depending on the parts used.\nBut despite the sometimes higher cost, I encourage you to re-frame your thinking about the value you get from your keyboards.\nFirst, if you use your keyboard on a daily basis for your job, you should consider your keyboard as a professional instrument. Professional musicians invest thousands of dollars into their instruments, and likewise professional chefs invest thousands of dollars into their knives. So if you type for a profession, why not spend only a few hundred dollars on a professional keyboard?\nSecond, consider your keyboard as a medical device. Billions of people depend on glasses to see well, and a typical pair of glasses can easily cost several hundred dollars. And just as using a correctly-prescribed pair of glasses is important for the health of your eyes, using a more ergonomic keyboard is important for the health of your fingers, hands, wrists, and shoulders (yes, all of those things are affected by how you type).\nSo yes, purchasing an ergonomic keyboard may cost you a little more up front, but it is generally an investment worth making, and especially if you are already finding yourself in pain from typing.\n\n\nLearning curve\nAdopting any new technology generally comes with a learning curve, and moving to a split keyboard is no different. But how hard it is to adapt to a new keyboard varies by a variety of factors.\nFirst, if you already are proficient at touch-typing (meaning you use all 10 fingers to type and you don‚Äôt need to look down at the key legends), adopting a split keyboard probably won‚Äôt be too challenging. For me, I found I was a little slower and made more errors for a few days when first using a split board, but after about a week I was back to otherwise ‚Äúnormal‚Äù typing speed. If you are not a proficient touch typist, I recommend getting up to a good typing speed (~60 WPM) before adopting a split keyboard. This is because split boards essentially force you to use the appropriate hand for each key, so if you are also learning how to type while using the split keyboard, you may find it extra challenging.\nSecond, the type of split keyboard can matter quite a lot. Some boards, such as the Microsoft Sculpt, have two split halves but are otherwise quite similar in the key positions compared to typical keyboards. Others, such as the Ergodox EZ, use an ‚Äúortholinear‚Äù layout, meaning that each row of keys align into columns with no stagger across rows. These columnar layouts are arguably more ergonomic and comfortable to type on, but they can take a little longer to get used to.\nMy recommendation is to try out a split board of some type and practice using it on a site like keybr.com. Get used to it first and give it at least a week of regular use before judging it. It can take a week or more for it to stop feeling strange, and your hands will thank you in the long run.\n\n\n\nAlternative layouts?\nThe one thing I tried along this journey that I generally do not recommend is learning a new keyboard layout, such as Colemak or Dvorak.\nIn case you didn‚Äôt know, the typical QWERTY layout is actually a pretty poor layout in terms of typing efficiency and ergonomics. There are lots of stories about why this layout was originally chosen. Some say it was intentionally designed to be inefficient so that early typewriter arms wouldn‚Äôt jam up if someone got to typing too fast. My favorite story is that early typewriter salesmen didn‚Äôt know how to type, but the QWERTY layout enabled them to type ‚Äútypewriter‚Äù by using only the upper row, making it easier to remember the sequence.\nWhatever the reason for designing the layout, QWERTY is pretty bad, but we‚Äôre all unfortunately pretty much stuck with it as the defacto standard. Being the keyboard enthusiast that I am, I have attempted several times to adopt Colemak, but I have never been able to get my speed anywhere near my speed with QWERTY. But I also do not see much benefit to using a different layout, especially relative to the steep learning curve in mastering it. I do not feel any discomfort using QWERTY, and my typing speed on a split keyboard is ~90 words per minute, which is plenty fast enough to be an efficient typist. So, this is just to say that if you came across this post looking for tips on ergonomic typing, I would much more heavily weigh using a split keyboard over the particular key layout on that keyboard. That said, if you‚Äôre not that proficient yet at any layout, you might save yourself some trouble and just start with an alternative to QWERTY.\n\n\nTools to build your own keyboard\nAt this point in my keyboard journey, I‚Äôm starting to wonder how different my life might be today if I had taken the blue pill. Certainly my hands and shoulders would be in much worse shape, but I might also just be happy using a simple old Apple keyboard. Ignorance can sometimes be bliss.\n\n\n\n\n\nMe in 2021 with about three too many keyboards in my office.\n\n\n\n\nNonetheless, should you choose to go down this path, hopefully I can save you a bit of time with some suggested tools. First, you‚Äôll need some pretty standard equipment. Here are my recommendations:\n\nA cheap soldering iron is all you really need to get the job done. No need to spend a fortune, especially if you won‚Äôt use it too often.\nA brass sponge to clean the soldering iron tip is a must. A good brass sponge will make up for anything lacking in a cheap iron.\nA cheap solder fan is a good idea, especially if you‚Äôre working in small spaces. Solder fumes are pretty toxic, and these little things actually work very well.\nReverse tweezers are a lifesaver for holding tiny parts.\nA Silicon mat is really nice so you don‚Äôt burn your desk and lose tiny parts.\nNot super necessary, but some sort of quad hand tool can be helpful for holding everything still when working.\n\nIn terms of suppliers, most keyboard parts shops are regional. In the U.S., both Keyhive and Littlekeyboards have a lot to offer.\nIf you want to learn more about and / or compare the many different split keyboards out there, check out this Shiny App I made (source code here). I made it both to help the community of split keyboard users find their next board, but also to learn and practice a lot about building Shiny Apps.\n\n\n\n\n\nScreenshot of my splitKbCompare app.\n\n\n\n\nFinally, if you do choose to adopt any of the solutions I wrote about in this post, please do reach out (Twitter, Reddit) - I‚Äôm happy to help however I can!\n\n\n\n\n\nChoose wisely.\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "blog/2021-05-04-expand-your-productivity-with-espanso/index.html",
    "href": "blog/2021-05-04-expand-your-productivity-with-espanso/index.html",
    "title": "Expand your productivity with espanso",
    "section": "",
    "text": "I recently discovered a wonderfully useful little program called espanso ‚Äì a ‚Äútext expander‚Äù that I now use on a daily basis. Text expander programs ‚Äúexpand‚Äù short text ‚Äútriggers‚Äù into longer / more complex strings of text, like this:\nThere are lots of these programs out there, such as Typinator, or the creatively-named ‚Äútextexpander‚Äù (macOS even has a build-in expander). But I prefer to use open source software whenever possible (the espanso source code is on GitHub), and especially when using software that tracks the text you type (imagine how easy it would be to grab passwords with this type of software). Plus espanso is free üòÑ. Of course if you‚Äôd like to support the project you can donate here.\nMore than anything, I started (and kept) using espanso because I found it to be remarkably simple to use and easy to customize. So far, it has integrated quite nicely into my day-to-day workflow. In fact, I have become such a fan of espanso that I decided to sit down and write a whole post highlighting some of the ways I use it."
  },
  {
    "objectID": "blog/2021-05-04-expand-your-productivity-with-espanso/index.html#html",
    "href": "blog/2021-05-04-expand-your-productivity-with-espanso/index.html#html",
    "title": "Expand your productivity with espanso",
    "section": "HTML",
    "text": "HTML\nI don‚Äôt write a lot of html, but occasionally I‚Äôll use it to insert an image in a RMarkdown document. And usually I want that image centered. The basic template I usually start with is:\n\n&lt;center&gt;\n&lt;img src=\"\" width=100%&gt;\n&lt;/center&gt;\n\nI use the trigger hhimg (which I remember as ‚Äúhtml‚Äù + ‚Äúimg‚Äù) to insert this snippet. Here‚Äôs the code to define this expansion:\n\n  - trigger: \"hhimg\"\n    replace: \"&lt;center&gt;\\n&lt;img src=\\\"$|$\\\" width=100%&gt;\\n&lt;/center&gt;\"\n\nNotice the $|$ symbols inside the quotes following ‚Äúsrc‚Äù. This sets the location of the cursor once the expansion is complete, allowing me to quickly type in the name of the path to the image I want to insert. Another one of those little bonus features about espanso that is just ü§å *chef‚Äôs kiss*."
  },
  {
    "objectID": "blog/2021-05-04-expand-your-productivity-with-espanso/index.html#r",
    "href": "blog/2021-05-04-expand-your-productivity-with-espanso/index.html#r",
    "title": "Expand your productivity with espanso",
    "section": "R",
    "text": "R\nSince I use R more than any other language, I‚Äôve come up with a lot of R-specific shortcuts. But before I dive into them, a quick side note:\nOne important modification I learned (thanks to some help on the espanso Reddit community) is that if you‚Äôre working in RStudio, the expansions don‚Äôt quite work correctly on their own (I believe it might have something to do with RStudio‚Äôs autofill feature). To fix it, I had to insert the force_clipboard: true setting into each espanso expansion. For example, in my snippet to read in a CSV file, I inserted this option between the trigger and expansion text like this:\n\n  - trigger: \"rrcsv\"\n    force_clipboard: true\n    replace: \"read_csv($|$)\"\n\nOkay with that in mind, I‚Äôll highlight a few R expansions I use a lot. I‚Äôve organized this based on my common workflow for exploring data:\n\nAdd a setup chunk (if working in Rmd)\nLoad libraries & data\nWrangle data\nVisualize\n\n\nAdd a setup chunk\nI usually include a ‚Äúsetup‚Äù chunk in most of my Rmd files, but it‚Äôs really hard to remember all the specific details for various settings, so I made a dedicated expansion just for this. With this expansion, I can insert my whole default setup chunk with rrsetup:\n  - trigger: \"rrsetup\"\n    force_clipboard: true\n    replace: |\n              ```{r setup, include=FALSE}\n              knitr::opts_chunk$set(\n                warning = FALSE,\n                message = FALSE,\n                fig.path = \"figs/\",\n                fig.width = 7.252,\n                fig.height = 4,\n                comment = \"#&gt;\",\n                fig.retina = 3\n              )\n              ```\n\n\nLoad libraries & data\n\n\n\nI use some simple shortcuts to load individual libraries, like rrtidy to expand to library(tidyverse). But (as shown in the above image) I also set up an expansion to load some of my most often used libraries and settings. By typing rrstart, I get this expansion:\n\nlibrary(tidyverse)\nlibrary(cowplot)\noptions(dplyr.width = Inf)\n\nWith my libraries loaded, I then read in my data. I use rrcsv to expand to read_csv($|$), rrex to expand to read_excel($|$), and rrhere to expand to here::here($|$), which I use to define paths to files.\n\nSide note: if you don‚Äôt already, you should definitely try using the {here} package to define paths.\n\n\n\nWrangle data\n\n\n\nI usually wrangle my data using tidyverse commands, and I have come up with a few expansions for some common ‚Äúpipelines‚Äù. For example, one common sequence is to do grouped summary operations. I use the rrgs (‚Äúgs‚Äù for ‚Äúgrouped summary‚Äù) trigger to load the code block:\n\n    group_by() %&gt;%\n    summarise()\n\nLikewise, I use the rrgm trigger to load the code block for a grouped mutate:\n\n    group_by() %&gt;%\n    mutate()\n\nThere are so many of these you could put together!\n\n\nVisualize\n\n\n\nSince {ggplot2} has such a distinct syntax, I decided to start my ggplot code snippets with gg rather than rr. Some of my favoriate {ggplot2} expansions are the scaling shortcuts:\n\nggsxc ‚Äì&gt; scale_x_continuous()\nggsyc ‚Äì&gt; scale_y_continuous()\nggsxd ‚Äì&gt; scale_x_discrete()\nggsyd ‚Äì&gt; scale_y_discrete()\n\nI also use some snippets for common geoms, like ggpoint:\n\nggplot() +\n    geom_point(aes(x = , y = ))\n\nand ggcol:\n\nggplot() +\n    geom_col(aes(x = , y = , fill = ))"
  },
  {
    "objectID": "blog/2023-04-06-markdown-surveys/index.html",
    "href": "blog/2023-04-06-markdown-surveys/index.html",
    "title": "{surveydown}: An open source, markdown-based survey framework (that doesn‚Äôt exist yet)",
    "section": "",
    "text": "I do a lot of research using surveys. My current platform of choice is formr, a flexible platform for making surveys using  (see my blog post on how to use it to implement a choice-based conjoint survey). While formr is powerful in terms of it‚Äôs flexibility, it has a bit of a learning curve and isn‚Äôt the easiest tool for novices. And alternative platforms like Qualtrics, Google forms, etc. have their own issues, one of which is simply that they use a WYSIWYG interface, which makes it difficult to collaborate, version control, reproduce, etc.\nI want a markdown-based survey framework. Users should be able to draft plain text / markdown / RMarkdown files that can be compiled into a web-based survey. My inspiration is packages like {xaringan}, which compiles RMarkdown files into HTML presentation slides using remark.js.\nThis framework doesn‚Äôt yet exist (or at least I am not award of one that does), but I am confident we could relatively quickly build a working prototype. I‚Äôve even got a name for it: {surveydown}\nSo this post is a call for help. I am laying out my goals for such a framework and asking if anyone out there wants to help take a crack at building it.\n\nUser interface\nMy prototype for a markdown-based survey framework would have the following features:\n\n1. All survey content is defined in plain text files (e.g.¬†Rmd, yml, etc.)\n\n\n2. All survey questions are defined in a _questions.yml file\nHere‚Äôs an example:\n\nage:\n  type: numeric\n  required: true\n  text: \"What's your age?\"\n  option: 25\n\ngender:\n  type: mc\n  required: true\n  text: \"Which best describes your gender?\"\n  option:\n    - female: \"Female\"\n    - male: \"Male\"\n    - opt_out: \"Prefer not to say\"\n\nSome fields in this file might be:\n\ntype: Defines the type of question (e.g.¬†numeric = a numeric entry box, mc = multiple choice, etc.).\nrequired: Respondent must answer the question to continue in the survey (defaults to false).\ntext: The question text.\noption: The set of choices for the question.\n\nThe names used for each question would be used as the column names in the resulting data file once respondents have completed the survey. For example, since I have two questions called age and gender, the resulting data might look something like this:\n\n\n#&gt; # A tibble: 3 √ó 3\n#&gt;   respondent   age gender \n#&gt;        &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;  \n#&gt; 1          1    25 female \n#&gt; 2          2    30 male   \n#&gt; 3          3    32 opt_out\n\n\nHere I am storing the option values (e.g.¬†\"opt_out\") instead of the option labels (e.g.¬†\"Prefer not to say\") in each cell, though this could be optional.\n\n\n3. All content displayed in the survey is defined in plain text / Rmd files\nFor example, a basic survey might have the following files:\n\nwelcome.Rmd: Basic welcome page.\nscreener.Rmd: Contains screen questions to filter out only elligible respondents.\nother.Rmd: Other questions for those who got through the screener.\nend.Rmd: Final survey page.\n\nThe welcome.Rmd file might have the following content:\n\n# Welcome!\n\n---\n\nThis is a survey!\n\nHere the --- symbol would indicate a page break in the survey, similar to how slide breaks work in {xaringan}.\n\n\n4. Survey questions are inserted with a simple interface, e.g.¬†{{ }}\nFor example, a double curly bracket could be used to insert the age and gender questions, like this:\n\n{{ question age }}\n\n{{ question gender }}\n\nThis allows the survey designer the ability to separately handle the survey questions from all other content. That way they don‚Äôt have to dig through their Rmd files to edit the question labels or response options - they can just edit the _questions.yml file and everything else in the survey remains unchanged.\n\n\n5. Survey control logic is defined in a _survey.yml file\nIn this file, the user should be able to control the sequencing of the survey content, such as skipping questions depending on a specific response in a screener question. An example might be:\n\nsurvey:\n  welcome.Rmd\n  screener.Rmd\n  skip:\n    condition: age &gt; 40\n    distination: end_screen.Rmd\n  other.Rmd\n  end.Rmd\n  stop\n  end_sreen.Rmd\n  stop\n\nThe logic in this example would show the respondent the content in welcome.Rmd and screener.Rmd, and then it would evaluate the response to the age question (assuming it was shown in screener.Rmd). In this survey, the respondent is sent to the end_screen.Rmd page if their age is greater than 40, otherwise they would continue on to the other.Rmd and end.Rmd pages. A word like stop would be a special word that stops the survey at that point.\n\n\n6. Ability to run code in the survey\nThe ability to run code during a survey is perhaps the most promising aspect this framework. The formr platform can do exactly this, and it is the inspiration for why I feel this feature must be built into {surveydown} one way or another.\nHow to implement this is an open challenge. There are a number of ways to do it, and the exact implementation will probably depend on other aspects of how the package is built, but one idea is to leverage an idea related to child documents. I can imagine that users could make child Rmd files that contain code chunks that define aspects of questions, and then reference them in the _questions.yml file, something like this:\n\napples:\n  type: mc\n  text: \"What's your favorite apple?\"\n  child: /child/apples.Rmd\n\nWhat exactly would go in the /child/apples.Rmd file is yet to be defined, but it might require code chunks that contain {surveydown} functions for defining aspects of the question, such as the text, options, etc. This obviously has not yet been well thought out, but I mention it here as it is an important concept to keep in mind as other aspects of the framework are constructed.\n\n\n\nA quick prototype\nRather than start completely from scratch, I decided to build on the {shinysurveys} package (by Jonathan Trattner and Lucy D‚ÄôAgostino McGowan) for a very quick prototype of this framework. My prototype is not at all complete - most of the features I have listed are not implemented. All it really does is allow the user to define questions in a _questions.yml file, and then runs a shiny app with those questions in series (so no Rmd files, page breaks, etc.). The code for this prototype can be found in the repo I set up for this project: github.com/jhelvy/surveydown\nThe _questions.yml file contains this:\n\nage:\n  type: numeric\n  required: true\n  text: \"What's your age?\"\n  option: 25\n\ngender:\n  type: mc\n  required: true\n  text: \"Which best describes your gender?\"\n  option:\n    - female: \"Female\"\n    - male: \"Male\"\n    - opt_out: \"Prefer not to say\"\n    - self_desc: \"Prefer to self describe\"\n\ngender_self_describe:\n  type: text\n  text: \"Which best describes your gender?\"\n  dependence: gender\n  dependence_value: \"Prefer to self describe\"\n\neducation:\n  type: select\n  text: \"What is the highest level of education you have attained?\"\n  option:\n    - hs_no: \"Did not attend high school\"\n    - hs_some:  \"Some high school\"\n    - hs_grad: \"High school graduate\"\n    - college_some: \"Some college\"\n    - college_grad: \"College\"\n    - grad: \"Graduate Work\"\n    - no_response: \"Prefer not to say\"\n\nrexper:\n  type: mc\n  text: \"Have you ever learned to program in R?\"\n  option:\n    - yes: \"Yes\"\n    - no: \"No\"\n\nWhen run, the basic example makes a shiny survey that looks like this:\n\n\n\n\n\n\n\nGif from https://vsgif.com/gif/2859497\n\n\n\nPlatforms\nOkay, I‚Äôve got a very basic survey working in Shiny, but it‚Äôs far from complete. It doesn‚Äôt even have a database backend or anything - just a UI built from a _questions.yml file. And Shiny may not be the best platform to build this framework in - it‚Äôs just the first thing I found that I could quickly implement without having to learn too much. There are other options, and that‚Äôs where I would really like to hear from others about the best direction to go next.\nAt the highest level, I believe the goal should be to develop the framework as an R or python package. Since I prefer R and am more familiar with similar packages like {xaringan}, my starting point would be to develop an R package that uses R code to convert the text files defined by a user into the code for an online survey.\nThis framework could use a number of different underlying platforms though to implement the final survey. So in some ways we have to work backwards - find a platform we like that makes good surveys and supports an easy database backend for storing responses, then build the R (or python) package that converts the markdown text files into the code for that survey.\n\nShiny?\nShiny is a convenient package for building this framework as it already comes with all of the widgets needed for most types of survey questions. It‚Äôs also something that many R users (and a lot of academics who might make these surveys) already know. It has some simple and relatively streamlined approaches to hosting too, such as shinyapps.io. Finally, the ability to run code in the survey should also be relatively straightforward in Shiny.\nThe downside to working with shiny is that is isn‚Äôt really designed for collecting data as much as it is for displaying data. That said, one approach I have used in the past to store and manage data for a Shiny app is to hook it into a Google sheet. While it‚Äôs a little hacky, it might actually work okay for this context because surveys usually don‚Äôt require enormous sizes - the databases are often a few thousand rows at most and maybe tens to hundreds of columns (quite easily something a Google sheet could handle). I mean, Google uses sheets for Google forms, so why not? Airtable is another similar option here.\nSo Shiny is an option, and we could build upon / modify the {shinysurveys} package as a starting point. But a key question would be about the best way to integrate a database backend for managing responses.\n\n\nSurveyJS?\nI haven‚Äôt used it, but SurveyJS looks really nice. I imagine it wouldn‚Äôt be too difficult to write some R functions that convert markdown inputs into a SurveyJS survey. It looks like it may be more flexible than Shiny, and it seems to have lovely database backend integrations, but there would be a much larger learning curve to build it (at least for me‚Ä¶maybe a JS expert out there wants to take the lead?). It‚Äôs certainly doable. After all, {xaringan} uses reactjs, and Quarto surveys use revealjs‚Ä¶maybe {surveydown} should use SurveyJS?\nOne challenge it poses though is the ability to run code in the background. I don‚Äôt yet see a clear way to do something like run code chunks, so this feature may need to be cut to make it work.\n\n\nQualtrics? SurveyMonkey?\nThe survey gorillas like Qualtrics and SurveyMonkey are solid survey providers with loads of other features. Why reinvent the wheel? So another option is to build a package that does the translation of converting markdown files into something that is uploadable to one of these sites. I am not a big user of them, so I don‚Äôt even know if this is possible, but if it is then it would solve a lot of issues.\nSo in this case a {surveydown} package would really be a markdown-based framework to design and preview the survey UI. Once the user is happy with it, they would upload it to Qualtrics, SurveyMonkey, etc. and field their survey.\nAn obvious downside is that it‚Äôs not open source (though I don‚Äôt think the entire toolchain needs to be for this to still be useful). Also, again the ability to run code in the survey may be lost, so that too is a considerable downside to this approach.\n\n\n\nPlease help!üôè\nIf you like this idea and want to contribute, I started a repo here: https://github.com/jhelvy/surveydown\nI include my basic Shiny example in the shiny-example folder. I‚Äôm not committed to using Shiny as the underlying platform, though I can at least envision how it might work.\nIf you have any thoughts on this, please do leave comments here or open an issue. I would love to see this framework built, and I think it could really improve and simplify the survey design process for many researchers.\nThanks for reading, and hopefully we‚Äôll get this built one day!\n\n\nUpdate 1 (2023-06-15)\nAfter playing around with different versions of a UI, I‚Äôve converged on a rather different approach to defining survey content. When using the UI originally described in this post, everything just felt too disaggregated. It lacked the cohesiveness that I love when, for example, making a presenting using {xaringan}. I missed having everything in a single RMarkdown file where the UI was much closer to literate programming.\nSo I‚Äôve come up with a simpler UI. In this UI, you have a single survey.Rmd file (might also consider a .qmd Quarto file) where the survey theme and control logic is defined in a YAML at the top and all of the survey content is defined in the body. An example YAML might look like this:\n---\nname: \"surveydown demo\"\nauthor: \"John Paul Helveston\"\noutput:\n  surveydown::survey:\n    css:\n      - default\n    lib_dir: libs\n    control:\n      skip:\n        condition: color == \"Blue\"\n        destination: end_screenout\n      stop: end\n      stop: end_screenout\n---\nHere the surveydown::survey: section is where we could define all global options to the survey. I‚Äôve added a control section to define flow logic. I could also imagine including a link to a database, etc.\nThen the body of the survey would feel just like a normal RMarkdown file. You could add any general markdown you want and insert questions using a code chunk with a question() function, something like this:\n```{r}\nquestion(\n  name     = 'color',\n  type     = 'mc',\n  required = TRUE,\n  label    = \"Do you want to take the red pill or the blue pill?\",\n  option   = c('Red', 'Blue')\n)\n```\nThe survey could be rendered into a view only mode with a simple function, like surveydown::render_survey(file = 'survey.Rmd'). Then to make the survey go live, it could be hosted on shinyapps.io (or a different server) with another function, maybe:\n\nsurveydown::host_survey(\n  folder = 'survey',\n  data_url = 'path_to_googlesheet',\n  api_key = 'api_key'\n)\n\nThis UI overall is much more simplified and allows for more complexity in how questions are defined. For example, you can write R code to define the options in a question, or you could read in a set of options from an external file.\nObviously a lot of work needs to be done to make something like this a reality, but it at least provides a goal.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "blog/2021-09-18-choice-based-conjoint-surveys-in-r-with-formr/index.html",
    "href": "blog/2021-09-18-choice-based-conjoint-surveys-in-r-with-formr/index.html",
    "title": "Choice-based conjoint surveys in R with formr",
    "section": "",
    "text": "formr.org is a flexible platform for making surveys using . In this post, I‚Äôm going to show you one approach for using formr to create a choice-based conjoint survey (I‚Äôm going to assume that you know what conjoint surveys are, but if not take a look at this quick introduction).\nThroughout this post, I will use a demo survey about people‚Äôs preferences for apples with three attributes: type, price, and freshness.1\nYou can view the live demo survey here, and all files used to create the survey are on this GitHub repo."
  },
  {
    "objectID": "blog/2021-09-18-choice-based-conjoint-surveys-in-r-with-formr/index.html#footnotes",
    "href": "blog/2021-09-18-choice-based-conjoint-surveys-in-r-with-formr/index.html#footnotes",
    "title": "Choice-based conjoint surveys in R with formr",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nYes, people have actually done conjoint surveys on fruit before.‚Ü©Ô∏é"
  },
  {
    "objectID": "talks/2020-10-09-confucius-institute-fall-seminar/index.html",
    "href": "talks/2020-10-09-confucius-institute-fall-seminar/index.html",
    "title": "U. Albany Confucius Institute Fall 2020 Seminar on US-China Relations in the 21st Century",
    "section": "",
    "text": "Barry Naughton (Sokwanlok Chair of Chinese International Affairs at the School of Global Policy and Strategy, UCSD) and I kicked off the U. of Albany Confucius Institute Fall 2020 Seminar Series on ‚ÄúUS-China Relations in the 21st Century‚Äù with a discussion about industrial policy and low-carbon energy technologies in China. In his presentation titled, ‚ÄúChina‚Äôs Industrial Policy: New Technological Revolution or Old-fashioned Protectionism?‚Äù, Professor Naughton highlighted some of the recent major technology and industrial policy changes under President Xi and the implications for the U.S. In my talk titled, ‚ÄúChina‚Äôs key role in scaling low carbon energy technologies,‚Äù I discussed the critical role China has played in scaling up the mass production of low-carbon energy technologies, such as solar photovoltaic cells and lithium-ion batteries, highlighting key points from my related paper in Science with Jonas Nahm.\n\n\n Slides as PDF\n\n\n Science Paper\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "talks/2022-05-06-sawtooth-conf-cbctools/index.html",
    "href": "talks/2022-05-06-sawtooth-conf-cbctools/index.html",
    "title": "The cbcTools Package: Tools for Designing and Testing Choice-Based Conjoint Surveys in R",
    "section": "",
    "text": "I gave a talk at the Sawtooth Software Conference in Orlando, FL, on May 06, 2022. The talk is titled, ‚ÄúThe {cbcTools} Package: Tools for Designing and Testing Choice-Based Conjoint Surveys in R‚Äù.\nLearn more about the {cbcTools} package here: https://jhelvy.github.io/cbcTools/\n\nTalk\n\n\n\n\nSlides\nMy slides were built using the {xaringan} R package. You can see the source code for the slides here.\n\n\n Full screen slides\n\n\n Slides as PDF\n\n\nKeyboard Shortcuts for Slides:\n\nUse ‚Üê and ‚Üí to navigate through the slides.\nUse f to toggle full screen.\nUse o to view an overview of all slides.\nUse h to see a list of other shortcuts.\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "talks/2021-04-20-sawtooth-conf-logitr/index.html",
    "href": "talks/2021-04-20-sawtooth-conf-logitr/index.html",
    "title": "Obtaining Willingness to Pay Estimates from Preference Space and Willingness to Pay Space Utility Models",
    "section": "",
    "text": "I gave a talk at the Sawtooth Software Conference Turbo Choice Modeling Seminar in San Antonio, Texas, April 19-23, 2021 (I pre-recorded my talk as I did not attend in-person). The talk is titled, ‚ÄúThe {logitr} R Package: Obtaining Willingness to Pay Estimates from Preference Space and Willingness to Pay Space Utility Models‚Äù.\nLearn more about the {logitr} package here.\n\nTalk\n\n\n\n\nSlides\nMy slides were built using the {xaringan} R package. You can see the source code for the slides here.\n\n\n Full screen slides\n\n\n Slides as PDF\n\n\nKeyboard Shortcuts for Slides:\n\nUse ‚Üê and ‚Üí to navigate through the slides.\nUse f to toggle full screen.\nUse o to view an overview of all slides.\nUse h to see a list of other shortcuts.\n\n\n\n\n```\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "research/2024-environmental-research-letters/index.html",
    "href": "research/2024-environmental-research-letters/index.html",
    "title": "Battery-Powered Bargains? Assessing Electric Vehicle Resale Value in the United States",
    "section": "",
    "text": "Battery-Powered Bargains? Assessing Electric Vehicle Resale Value in the United States\n\n\n\n\nHaiku Summary\n\n\n\n\n\n\n Roberson, Laura A., *Pantha, S., & Helveston, J.P. (2024) ‚ÄúBattery-Powered Bargains? Assessing Electric Vehicle Resale Value in the United States‚Äù Environmental Research Letters.  DOI: 10.1088/1748-9326/ad3fce\n\n\n\n\n\n\n View PDF Code & Data Scholar\n\n\n  \n    \n      EVs lose value\n      ‚Ä¢\n      fast, but newer, longer-range\n      ‚Ä¢\n      ones do much better\n    \n  \n\n\n\n  Key Figure  \n\n\n\n\n\n\n\n\n\nAbstract:\nThe resale market will play a critical role in expanding plug-in electric vehicle (PEV) adoption to middle- and lower-income households. Understanding PEV depreciation trends in comparison to those of conventional gasoline vehicles (CVs) is critical for assessing PEV affordability and informing relevant policy, such as subsidies for used PEVs. We deliver comprehensive, high-resolution estimates of value retention rates at the make-model level in the United States for battery electric vehicles (BEVs), plug-in hybrid electric vehicles (PHEVs), hybrid electric vehicles (HEVs), and CVs using a database of 9 million used cars listed online between 2016 and 2022. While BEVs and PHEVs have depreciated at faster rates than CVs, this trend is changing, with newer model year BEVs and those with larger ranges have significantly higher retention rates than older model years with smaller ranges. Tesla BEVs are a notable exception following the opposite trend, with earlier model years holding their value better than newer model years. Subsidized BEVs in the new market are associated with lower prices for the same model in the resale market, with the $7,500 federal subsidy translating to a 3% lower resale price on average. Finally, disruptions from the COVID-19 pandemic have affected affordability across all vehicles, with mean listing prices rising 37% and 39% for CVs and BEVs, respectively, from January 2020 to March 2022 in inflation-adjusted 2019 dollars.\nBibtex:\n\n@article{roberson2024,\n    author={Roberson, Laura A. and Pantha, Saurav and Helveston, John Paul},\n    title={Battery-powered bargains? Assessing electric vehicle resale value in the United States},\n    journal={Environmental Research Letters},\n    url={http://iopscience.iop.org/article/10.1088/1748-9326/ad3fce},\n    year={2024}\n}\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "research/2023-systems-engineering/index.html",
    "href": "research/2023-systems-engineering/index.html",
    "title": "Using conjoint analysis to incorporate heterogeneous preferences into multimodal transit trip simulations",
    "section": "",
    "text": "Using conjoint analysis to incorporate heterogeneous preferences into multimodal transit trip simulations\n\n\n\n\nHaiku Summary\n\n\n\n\n\n\n Zhao, L., Szajnfarber, Z., Broniatowski, D.A., & Helveston, J.P. (2023) ‚ÄúUsing conjoint analysis to incorporate heterogeneous preferences into multimodal transit trip simulations‚Äù Systems Engineering.  DOI: 10.1002/sys.21670\n\n\n\n\n\n\n View PDF RG Scholar\n\n\n  \n    \n      DC commuters\n      ‚Ä¢\n      want fewer bus transfers and\n      ‚Ä¢\n      more metro access\n    \n  \n\n\n\n  Key Figure  \n\n\n\n\n\n\n\n\n\nAbstract:\nUrban transportation systems involve thousands of individuals making choices between routes with multiple modes and transfers. For transportation system simulations to produce realistic results, modelers need to incorporate these users and their choices. Choice-based conjoint surveys provide an attractive solution for obtaining flexible utility models that can be used to predict choices for a wide variety of trips. In this study, we demonstrate an example using conjoint survey data of commuter mode choice in the Washington, D.C. metro area (N = 1,651). We sample commuters who primarily drive and those that take transit. We examine preferences for different types of multi-modal trips, including those with intramodal and intermodel transfers. We find that trips involving a bus transfer are the least preferred while both drivers and transit users both value metro similarly to driving. We also find that walking during transit trips is an important barrier, with the travel time penalty for walking being 60% higher than that of time in a vehicle. Our findings highlight the significance of accounting for differences in modal transfer types in transportation system simulations. Reducing arrival time uncertainty was not a significant factor in commuter mode choice, and commuters‚Äô value of time was similar across all vehicle types, suggesting that increasing the relative speed of transit modes may only have a marginal effect on commuter substitution away from personal vehicles.\nBibtex:\n\n@article{zhao2023using,\n  title={Using conjoint analysis to incorporate heterogeneous preferences into multimodal transit trip simulations},\n  author={Zhao, Lujin and Szajnfarber, Zoe and Broniatowski, David and Helveston, John Paul},\n  journal={Systems Engineering},\n  year={2023},\n  publisher={Wiley Online Library}\n}\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "research/2023-joule/index.html",
    "href": "research/2023-joule/index.html",
    "title": "Quantifying electric vehicle mileage in the United States",
    "section": "",
    "text": "Quantifying electric vehicle mileage in the United States\n\n\n\n\nHaiku Summary\n\n\n\n\n\n\n Zhao, L., *Ottinger, E., Yip, A., & Helveston, J.P. (2023) ‚ÄúQuantifying electric vehicle mileage in the United States‚Äù Joule. 7, 1‚Äì15. DOI: 10.1016/j.joule.2023.09.015\n\n\n\n\n\n\n View PDF Code & Data Scholar\n\n\n  \n    \n      EVs are driven\n      ‚Ä¢\n      less than gas cars, but higher\n      ‚Ä¢\n      range closes the gap\n    \n  \n\n\n\n  Key Figure  \n\n\n\n\n\n\n\n\n\nAbstract:\nWe deliver comprehensive, high-resolution estimates of annual vehicle miles traveled (VMT) in the United States for battery electric vehicles (BEVs), plug-in hybrid electric vehicles (PHEVs), hybrid electric vehicles (HEVs), and conventional gasoline vehicles (CVs) using odometer readings from 12.5 million used cars and 11.4 million used sport utility vehicles (SUVs) listed between 2016 and 2022. Although CVs, HEVs, and PHEVs are driven similarly, BEV cars average 4,477 fewer miles annually. Teslas are driven more than other BEVs, yet still less than CVs. Similar differences in VMT across powertrains exist for SUVs, though SUVs are driven more than cars in all powertrains. Driving range has a non-linear relationship with VMT for BEV cars: every 10 additional miles of range equates to 631 additional annual miles for low-range BEVs (&lt;100 miles of range) but only 85 annual miles for high-range BEVs (&gt;200 miles of range). BEV cars also show less sensitivity in annual VMT to operating cost changes compared with CVs. Results provide an important context for modelers anticipating increased electricity consumption from PEV adoption.\nBibtex:\n\n@article{zhao2023joule,\ntitle = {Quantifying electric vehicle mileage in the United States},\njournal = {Joule},\nyear = {2023},\nissn = {2542-4351},\ndoi = {https://doi.org/10.1016/j.joule.2023.09.015},\nurl = {https://www.sciencedirect.com/science/article/pii/S254243512300404X},\nauthor = {Lujin Zhao and Elizabeth R. Ottinger and Arthur Hong Chun Yip and John Paul Helveston},\nkeywords = {electric vehicles, mileage, behavior, vehicle miles traveled, VMT, electric vehicle miles traveled, eVMT, odometer, vehicle listings, listings data, national PEV data}\n}\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "research/2022-environmental-research-letters/index.html",
    "href": "research/2022-environmental-research-letters/index.html",
    "title": "Not all subsidies are equal: Measuring preferences for electric vehicle financial incentives",
    "section": "",
    "text": "Not all subsidies are equal: Measuring preferences for electric vehicle financial incentives\n\n\n\n\nHaiku Summary\n\n\n\n\n\n\n Roberson, Laura A. & Helveston, John P. (2022) ‚ÄúNot all subsidies are equal: Measuring preferences for electric vehicle financial incentives‚Äù Environmental Research Letters. 17(084003). DOI: 10.1088/1748-9326/ac7df3\n\n\n\n\n\n\n View PDF Code & Data Scholar\n\n\n  \n    \n      EV subsidies\n      ‚Ä¢\n      should be instant cash rebates\n      ‚Ä¢\n      and not tax credits\n    \n  \n\n\n\n  Key Figure  \n\n\n\n\n\n\n\n\n\nAbstract:\nFinancial incentives, such as purchase subsidies, have been found to increase plug-in electric vehicle (PEV) adoption, but how these incentives are designed can impact their effectiveness as well as how equitably they are distributed. Using a national conjoint survey (N = 2,170 respondents), we quantify how U.S. vehicle buyers value different features of PEV financial incentives. Participants overwhelmingly prefer immediate rebates, on average valuing them by $580, $1,450, and $2,630 more than sales tax exemptions, tax credits, or tax deductions, respectively. These effects are significantly larger for lower-income households, used vehicle buyers, and buyers with lower budgets. We estimate that on average $2 billion could have been saved if the federal subsidy available between 2011 and 2019 were delivered as an immediate rebate instead of a tax credit, or $1,440 per PEV sold. Our results suggest that structuring incentives as immediate rebates would deliver a greater value to customers and would be more equitably distributed compared to the current tax credit scheme.\nBibtex:\n\n@article{roberson2022erl,\n    author={Roberson, Laura A. and Helveston, John Paul},\n    title={Not all subsidies are equal: Measuring preferences for electric vehicle financial incentives},\n    journal={Environmental Research Letters},\n    year={2022}, \n    volume={17},\n    number={8},\n    pages={084003},\n    doi = {10.1088/1748-9326/ac7df3}\n}\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "research/2020-marketing-letters/index.html",
    "href": "research/2020-marketing-letters/index.html",
    "title": "Choices in networks: a research framework",
    "section": "",
    "text": "Choices in networks: a research framework\n\n\n\n\nHaiku Summary\n\n\n\n\n\n\n Feinberg, F., Bruch, E., Braun, M., Hemenway Falk, B., Fefferman, N., Feit, E.M., Helveston, J.P., Larremore, D., McShane, B.B., Patania, A., & Small, M.L. (2020) ‚ÄúChoices in networks: a research framework‚Äù Marketing Letters. 31(4), 349-359. DOI: 10.1007/s11002-020-09541-9\n\n\n\n\n\n\n View PDF Scholar\n\n\n  \n    \n      We live in networks;\n      ‚Ä¢\n      choice modelers should include\n      ‚Ä¢\n      them in their models\n    \n  \n\n\n\n  Key Figure  \n\n\n\n\n\n\n\n\n\nAbstract:\nNetworks are ubiquitous in life, structuring options available for choice and influencing their relative attractiveness. In this article, we propose an integration of network science and choice theory beyond merely incorporating metrics from one area into models of the other. We posit a typology and framework for ‚Äúnetwork-choice models‚Äù that highlight the distinct ways choices occur in and influence networked environments, as well as two specific feedback processes that guide their mutual interaction, emergent valuation and contingent options. In so doing, we discuss examples, data sources, methodological challenges, anticipated benefits, and research pathways to fully interweave network and choice models.\nBibtex:\n\n@article{feinberg2020choices,\n  title={Choices in networks: a research framework},\n  author={Feinberg, Fred and Bruch, Elizabeth and Braun, Michael and Falk, Brett Hemenway and Fefferman, Nina and Feit, Elea McDonnell and Helveston, John and Larremore, Daniel and McShane, Blakeley B and Patania, Alice and others},\n  journal={Marketing Letters},\n  volume={31},\n  number={4},\n  pages={349--359},\n  year={2020},\n  publisher={Springer}\n}\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "research/2019-science/index.html",
    "href": "research/2019-science/index.html",
    "title": "China‚Äôs key role in scaling low-carbon energy technologies",
    "section": "",
    "text": "China‚Äôs key role in scaling low-carbon energy technologies\n\n\n\n\nHaiku Summary\n\n\n\n\n\n\n Helveston, John P. & Nahm, Jonas (2019) ‚ÄúChina‚Äôs key role in scaling low-carbon energy technologies‚Äù Science. 366(6467), pg. 794-796. DOI: 10.1126/science.aaz1014\n\n\n\n\n\n\n View PDF Scholar\n\n\n  \n    \n      To meet climate goals\n      ‚Ä¢\n      we must work with China to\n      ‚Ä¢\n      scale up more green tech\n    \n  \n\n\n\n  Key Figure  \n\n\n\n\n\n\n\n\n\nAbstract:\nMeeting the goals of the Paris Agreement will require net zero greenhouse emissions by 2050 and substantial reductions before then. It will also require collaboration with China, which has emerged as the global leader in the mass production of low-carbon energy technologies (LCETs). In part because of China‚Äôs investments in manufacturing, the LCETs required to meet climate targets have become increasingly cost-competitive with fossil fuel sources (1). But some attribute China‚Äôs rapid rise in LCET sectors to unfair industrial policies‚Äîsuch as forced technology transfer requirements, massive subsidies, and outright intellectual property (IP) theft‚Äîaimed at strategically dominating the next generation of energy technologies (2). Trade relations between China and the world are currently unsettled, especially with the United States, a leading producer of both LCET research and development (R&D) and greenhouse gas (GHG) emissions. Against this backdrop, we outline why engaging with China is the more promising path to accelerate the global deployment of LCETs and to rapidly bring new technologies to mass production.\nBibtex:\n\n@article{helveston2019china,\n  title={China's key role in scaling low-carbon energy technologies},\n  author={Helveston, John and Nahm, Jonas},\n  journal={Science},\n  volume={366},\n  number={6467},\n  pages={794--796},\n  year={2019},\n  publisher={American Association for the Advancement of Science}\n}\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "research/2019-environmental-research-letters/index.html",
    "href": "research/2019-environmental-research-letters/index.html",
    "title": "Choice at the Pump: Measuring Preferences for Lower-Carbon Combustion Fuels",
    "section": "",
    "text": "Choice at the Pump: Measuring Preferences for Lower-Carbon Combustion Fuels\n\n\n\n\nHaiku Summary\n\n\n\n\n\n\n Helveston, J.P., Seki, S., Min, J., Fairman, E., Boni, A.A., Michalek, J.J., & Azevedo, I. (2019) ‚ÄúChoice at the Pump: Measuring Preferences for Lower-Carbon Combustion Fuels‚Äù Environmental Research Letters. 14(8). DOI: 10.1088/1748-9326/ab2bd2\n\n\n\n\n\n\n View PDF Scholar\n\n\n  \n    \n      Drivers on average\n      ‚Ä¢\n      are willing to pay more for\n      ‚Ä¢\n      lower carbon fuels\n    \n  \n\n\n\n  Key Figure  \n\n\n\n\n\n\n\n\n\nAbstract:\nA decarbonized future will require a transition to lower carbon fuels for personal transportation. We study consumer preferences for combustion fuels including gasoline, diesel, natural gas, and E85 (85% ethanol and 15% gasoline) using consumer choice survey data from two settings: online (n = 331) and in-person at refueling stations (n = 127). Light-duty vehicle owners were asked in a series of choice tasks to choose among fuels that varied in type, price, CO2 emissions, and location of origin for a hypothetical vehicle that could accept all fuels. We find that the majority of gasoline and E85 users are willing to substitute towards other fuels at today‚Äôs prices and attributes, while diesel users have a strong preference for diesel fuel. We also find that respondents are willing to pay on average $150/ton CO2 avoided from fuel consumption‚Äîmore than most estimates of the social cost of carbon. Thus, communicating the climate benefits from alternative fuels may be an important strategy for decarbonizing the transportation sector.\nBibtex:\n\n@article{helveston2019choice,\n  title={Choice at the pump: measuring preferences for lower-carbon combustion fuels},\n  author={Helveston, John P and Seki, Stephanie M and Min, Jihoon and Fairman, Evelyn and Boni, Arthur A and Michalek, Jeremy J and Azevedo, In{\\^e}s ML},\n  journal={Environmental Research Letters},\n  volume={14},\n  number={8},\n  pages={084035},\n  year={2019},\n  publisher={IOP Publishing}\n}\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "research/2015-transportation-research-part-a-policy-and-practice/index.html",
    "href": "research/2015-transportation-research-part-a-policy-and-practice/index.html",
    "title": "Will subsidies drive electric vehicle adoption? Measuring consumer preferences in the U.S. and China",
    "section": "",
    "text": "Will subsidies drive electric vehicle adoption? Measuring consumer preferences in the U.S. and China\n\n\n\n\nHaiku Summary\n\n\n\n\n\n\n Helveston, J.P., Liu, Y., Feit, E.M., Fuchs, E.R.H., KlampÔ¨Ç, E., & Michalek, J.J. (2015) ‚ÄúWill subsidies drive electric vehicle adoption? Measuring consumer preferences in the U.S. and China‚Äù Transportation Research Part A: Policy and Practice. 73, 96‚Äì112. DOI: 10.1016/j.tra.2015.01.002\n\n\n\n\n\n\n View PDF Code & Data SI RG Scholar\n\n\n  \n    \n      Full electric cars:\n      ‚Ä¢\n      Chinese seem to like them more\n      ‚Ä¢\n      than Americans\n    \n  \n\n\n\n  Key Figure  \n\n\n\n\n\n\n\n\n\nAbstract:\nWe model consumer preferences for conventional, hybrid electric, plug-in hybrid electric (PHEV), and battery electric (BEV) vehicle technologies in China and the U.S. using data from choice-based conjoint surveys fielded in 2012‚Äì2013 in both countries. We find that with the combined bundle of attributes offered by vehicles available today, gasoline vehicles continue in both countries to be most attractive to consumers, and American respondents have significantly lower relative willingness-to-pay for BEV technology than Chinese respondents. While U.S. and Chinese subsidies are similar, favoring vehicles with larger battery packs, differences in consumer preferences lead to different outcomes. Our results suggest that with or without each country‚Äôs 2012‚Äì2013 subsidies, Chinese consumers are willing to adopt today‚Äôs BEVs and mid-range PHEVs at similar rates relative to their respective gasoline counterparts, whereas American consumers prefer low-range PHEVs despite subsidies. This implies potential for earlier BEV adoption in China, given adequate supply. While there are clear national security benefits for adoption of BEVs in China, the local and global social impact is unclear: With higher electricity generation emissions in China, a transition to BEVs may reduce oil consumption at the expense of increased air pollution and/or greenhouse gas emissions. On the other hand, demand from China could increase global incentives for electric vehicle technology development with the potential to reduce emissions in countries where electricity generation is associated with lower emissions.\nBibtex:\n\n@article{helveston2015will,\n  title={Will subsidies drive electric vehicle adoption? Measuring consumer preferences in the US and China},\n  author={Helveston, John Paul and Liu, Yimin and Feit, Elea McDonnell and Fuchs, Erica and Klampfl, Erica and Michalek, Jeremy J},\n  journal={Transportation Research Part A: Policy and Practice},\n  volume={73},\n  pages={96--112},\n  year={2015},\n  publisher={Elsevier}\n}\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "talks/2022-04-30-cgtn-full-frame-interview/index.html",
    "href": "talks/2022-04-30-cgtn-full-frame-interview/index.html",
    "title": "Interview with CGTN Full Frame: Going Green",
    "section": "",
    "text": "I was featured in a long-form interview on an episode of CGTN‚Äôs ‚ÄúFull Frame‚Äù. In the interview, I discuss some of the challenges and opportunities China faces in the race to decarbonize it‚Äôs energy systems. I also discuss the critical role China is playing in scaling up the mass production of low carbon energy technologies like solar panels, wind turbines, lithium-ion batteries, and electric vehicles. My interview starts at minute 30:45 in the show, which you can watch here.\n\n\n\n Back to top"
  },
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "Teaching",
    "section": "",
    "text": "Content for workshops I‚Äôve given can be found at workshops.jhelvy.com\n\n\n\n\n\nEMSE 4571: Programming for Analytics\nThis course provides a foundation in programming for analytics using the R programming language with a comparison to Python. Topics covered include fundamentals of programming (operators, data types, objects, functions, conditionals, loops, strings, testing, and debugging) as well as techniques for working with data sets in R and Python (file input/output, data structures, data wrangling, data visualization, external packages, and reproducible reporting). Emphasis will be on producing clear, robust, and reasonably efficient code using top-down design, informal analysis, and effective testing and debugging. Students will primarily work on individual programming assignments to develop skills in computational problem solving, writing code, and working with data. Students will be assessed through quizzes, homework assignments, and exams. Teaching will involve interactive lectures with plenty of time spent live coding and working on practice problems in class. This course assumes no prior programming experience and is an ideal preparation for higher level courses in data analytics.\nSemesters Taught:\n\nSpring 2024\nSpring 2023\nSpring 2022\nFall 2020\nFall 2019\n\n\n\n\n\n\n\n\nEMSE 4572: Exploratory Data Analysis\nThis course provides students with a foundation in exploring data using the R programming language. Students will learn how to source, manage, transform, and explore a wide variety of data types. Students will also master the fundamental concepts for visualizing and communicating information contained in raw data, including the human psychology of visual information processing. All analyses will be conducted to support reproducibility from raw data to results using RMarkdown. Teaching will involve interactive lectures with plenty of class time spent working on examples and coding. Students will be assessed through in-class quizzes, reading reflections, and exploratory projects. Throughout the semester, students will work on a research project of their own design to demonstrate mastery of the course‚Äôs topics. At the end of the semester, students will submit a final, reproducible report of their project along with a 10-minute video presentation of their findings.\n\n\nSemesters Taught:\n\nFall 2024\nFall 2023\nFall 2022\nSpring 2021\nSpring 2020\n\n\n\nProject Showcases\n\n\n\n\n\n\n\n\n\nEMSE 6035: Marketing of Technology\nThis course provides students with data analysis techniques to inform design decisions in an uncertain, competitive market; topics include consumer choice modeling, programming in the R programming language, survey design, conjoint analysis, optimization, market simulation, and professional communication skills. Over the course of the semester, students will learn and apply theory and methods to a team project to assess the market competitiveness of an emerging product / technology and use marketing analytics to generate design insights. At the end of the semester, students will submit a final, reproducible report of their project along with a 10-minute presentation of their findings. This course has a ‚Äúflipped‚Äù classroom structure. Students will spend the majority of class time working through guiding practice exercises or working on their projects. To prepare for class, students must complete weekly assignments that involve watching and reviewing recorded lecture materials and answering related practice questions.\n\n\nSemesters Taught:\n\nFall 2024\nFall 2023\nFall 2022\nFall 2021\nSpring 2019\n\n\n\nProject Showcases\n\n\n\n\n\n\n\n\n\nR for Analytics Primer\nA self-guided tutorial for developing a foundation in programming in R for data analysis, including data input/output, data wrangling, and data visualization using the Tidyverse.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Research",
    "section": "",
    "text": "Google Scholar ORCID Research Gate\n\nUnderline indicates advisee; * graduate student, **undergraduate student"
  },
  {
    "objectID": "research.html#refereed-peer-reviewed-journal-articles",
    "href": "research.html#refereed-peer-reviewed-journal-articles",
    "title": "Research",
    "section": "Refereed (Peer-Reviewed) Journal Articles",
    "text": "Refereed (Peer-Reviewed) Journal Articles\n    *Roberson, Laura A., *Pantha, S., & Helveston, J.P. (2024) ‚ÄúBattery-Powered Bargains? Assessing Electric Vehicle Resale Value in the United States‚Äù Environmental Research Letters.  DOI: 10.1088/1748-9326/ad3fce         Summary View PDF Code & Data RG Scholar         Haiku Summary                 EVs lose value       ‚Ä¢       fast, but newer, longer-range       ‚Ä¢       ones do much better             *Kaplan, Leah R. & Helveston, John P. (2023) ‚ÄúUndercutting Transit? Exploring potential competition between autonomous vehicles and public transportation in the U.S.‚Äù Transportation Research Record.  DOI: 10.1177/03611981231208976         Summary View PDF Code & Data RG Scholar                Robo-taxis won't       ‚Ä¢       (at the moment) take over       ‚Ä¢       transit ridership             *Zhao, L., **Ottinger, E., Yip, A., & Helveston, J.P. (2023) ‚ÄúQuantifying electric vehicle mileage in the United States‚Äù Joule. 7, 1‚Äì15. DOI: 10.1016/j.joule.2023.09.015         Summary View PDF Code & Data Scholar                EVs are driven       ‚Ä¢       less than gas cars, but higher       ‚Ä¢       range closes the gap             *Zhao, L., Szajnfarber, Z., Broniatowski, D.A., & Helveston, J.P. (2023) ‚ÄúUsing conjoint analysis to incorporate heterogeneous preferences into multimodal transit trip simulations‚Äù Systems Engineering.  DOI: 10.1002/sys.21670         Summary View PDF RG Scholar                DC commuters       ‚Ä¢       want fewer bus transfers and       ‚Ä¢       more metro access             Helveston, John P. (2023) ‚Äúlogitr: Fast Estimation of Multinomial and Mixed Logit Models with Preference Space and Willingness to Pay Space Utility Parameterizations‚Äù Journal of Statistical Software. 105(10), 1-37. DOI: 10.18637/jss.v105.i10         Summary View PDF Code & Data RG Scholar                Fast estimation       ‚Ä¢       of mixed logit models and       ‚Ä¢       WTP in R             Helveston, J.P., He, G., & Davidson, M.R. (2022) ‚ÄúQuantifying the cost savings of global solar photovoltaic supply chains‚Äù Nature. 612 (7938), pg. 83-87. DOI: 10.1038/s41586-022-05316-6         Summary View PDF Code & Data ‰∏≠Êñá RG Scholar                Global supply chains       ‚Ä¢       are important for reaching       ‚Ä¢       lower green tech costs             *Roberson, Laura A. & Helveston, John P. (2022) ‚ÄúNot all subsidies are equal: Measuring preferences for electric vehicle financial incentives‚Äù Environmental Research Letters. 17(084003). DOI: 10.1088/1748-9326/ac7df3         Summary View PDF Code & Data Scholar                EV subsidies       ‚Ä¢       should be instant cash rebates       ‚Ä¢       and not tax credits             Szajnfarber, Z., **Groover, J.A., Wei, Z., Broniatowski, D.A., Chernicoff, W., & Helveston, J.P. (2021) ‚ÄúEvolvability Analysis Framework: Adding Transition Path and Stakeholder Diversity to Infrastructure Investment Decisions‚Äù Systems Engineering. 25(1):35-50. DOI: 10.1002/sys.21600         Summary View PDF Scholar                Transition pathways       ‚Ä¢       are important for upgrades       ‚Ä¢       to infrastructure             Feinberg, F., Bruch, E., Braun, M., Hemenway Falk, B., Fefferman, N., Feit, E.M., Helveston, J.P., Larremore, D., McShane, B.B., Patania, A., & Small, M.L. (2020) ‚ÄúChoices in networks: a research framework‚Äù Marketing Letters. 31(4), 349-359. DOI: 10.1007/s11002-020-09541-9         Summary View PDF Scholar                We live in networks;       ‚Ä¢       choice modelers should include       ‚Ä¢       them in their models             *Roberson, Laura A. & Helveston, John P. (2020) ‚ÄúElectric vehicle adoption: can short experiences lead to big change?‚Äù Environmental Research Letters. 15(0940c3). DOI: 10.1088/1748-9326/aba715         Summary View PDF Code & Data Scholar                A five minute ride       ‚Ä¢       in an EV can increase       ‚Ä¢       the chance you'll buy one             Helveston, John P. & Nahm, Jonas (2019) ‚ÄúChina‚Äôs key role in scaling low-carbon energy technologies‚Äù Science. 366(6467), pg. 794-796. DOI: 10.1126/science.aaz1014         Summary View PDF Scholar                To meet climate goals       ‚Ä¢       we must work with China to       ‚Ä¢       scale up more green tech             Helveston, J.P., Seki, S., Min, J., **Fairman, E., Boni, A.A., Michalek, J.J., & Azevedo, I. (2019) ‚ÄúChoice at the Pump: Measuring Preferences for Lower-Carbon Combustion Fuels‚Äù Environmental Research Letters. 14(8). DOI: 10.1088/1748-9326/ab2bd2         Summary View PDF Scholar                Drivers on average       ‚Ä¢       are willing to pay more for       ‚Ä¢       lower carbon fuels             Helveston, J.P., Wang, Y., Karplus, V.J., & Fuchs, E.R.H. (2019) ‚ÄúInstitutional Complementarities: The Origins of Experimentation in China‚Äôs Plug-in Electric Vehicle Industry‚Äù Research Policy. 48(1), pg. 206-222. DOI: 10.1016/j.respol.2018.08.006         Summary View PDF Scholar                Institutions can       ‚Ä¢       dramatically affect how       ‚Ä¢       industries emerge             Helveston, J.P., Feit, E.M., & Michalek, J.J. (2018) ‚ÄúPooling Stated and Revealed Preference Data in the Presence of Endogeneity‚Äù Transportation Research Part B: Methodological. 109, pg. 70-89. DOI: 10.1016/j.trb.2018.01.010         Summary View PDF RG Scholar                RP data with       ‚Ä¢       endogeneity may       ‚Ä¢       make things worse when pooled             Helveston, J.P., Liu, Y., Feit, E.M., Fuchs, E.R.H., KlampÔ¨Ç, E., & Michalek, J.J. (2015) ‚ÄúWill subsidies drive electric vehicle adoption? Measuring consumer preferences in the U.S. and China‚Äù Transportation Research Part A: Policy and Practice. 73, 96‚Äì112. DOI: 10.1016/j.tra.2015.01.002         Summary View PDF Code & Data SI RG Scholar                Full electric cars:       ‚Ä¢       Chinese seem to like them more       ‚Ä¢       than Americans"
  },
  {
    "objectID": "research.html#refereed-articles-in-conference-proceedings",
    "href": "research.html#refereed-articles-in-conference-proceedings",
    "title": "Research",
    "section": "Refereed Articles in Conference Proceedings",
    "text": "Refereed Articles in Conference Proceedings\n    *Kaplan, Leah, Szajnfarber, Z., & Helveston, John P. (2023) ‚ÄúShifting, Not Shrinking? Exploring Labor Roles in Traditional and Automated Door-to-Door Transportation Service‚Äù Proceedings of the IISE Annual Conference & Expo 2023. New Orleans, LA, USA, May 20-23, 2023, 3125.         PDF Scholar         Haiku Summary                 AV taxis will       ‚Ä¢       transform labor, not remove       ‚Ä¢       it altogether             *Kaplan, Leah & Helveston, John P. (2023) ‚ÄúUndercutting Transit? Exploring potential competition between autonomous vehicles and public transportation in the U.S.‚Äù National Academies Transportation Research Board Annual Meeting. Washington, D.C. Jan. 09.         PDF                Robo-taxis won't       ‚Ä¢       (at the moment) take over       ‚Ä¢       transit ridership             Helveston, John P. (2022) ‚ÄúThe Rise of Chinese Leadership in the Plug-in Electric Vehicle Industry‚Äù Chinese Industrial Policy: Sectors and Resources. UCSD Institute on Global Conflict and Cooperation, San Diego, CA. Sep. 30.         PDF Scholar                Half the world's EVs       ‚Ä¢       are sold in China; how? Well...       ‚Ä¢       policy matters             Helveston, John P. (2022) ‚ÄúThe cbcTools Package: Tools for Designing and Testing Choice-Based Conjoint Surveys in R‚Äù Sawtooth Software Conference. Orlando, FL. May 6.         View PDF Code & Data                Make choice-based conjoint       ‚Ä¢       designs and test the sample       ‚Ä¢       size requirements             Helveston, John P. (2021) ‚ÄúObtaining Willingness to Pay Estimates from Preference Space and Willingness to Pay Space Utility Models‚Äù Sawtooth Software Conference. San Antonio, TX. Apr. 19.         View PDF Code & Data                Fast estimation       ‚Ä¢       of mixed logit models and       ‚Ä¢       WTP in R             Liang, Z., Li, D., Fu, X., Beltekian, D., Helveston, J.P. (2018) ‚ÄúWhy is Siemens establishing its robotics R&D centers in China? A case study on the Siemens industrial robot project‚Äù IEEE International Symposium on Innovation and Entrepreneurship (TEMS-ISIE). Beijing, PRC, pp. 1-9. DOI: 10.1109/TEMS-ISIE.2018.8478558         View PDF Scholar                MNE research       ‚Ä¢       and host country R&D       ‚Ä¢       systems co-evolve             Helveston, J.P., Wang, Y., Karplus, V.J., & Fuchs, E.R.H. (2016) ‚ÄúUp, Down, and Sideways: Innovation in China and the Case of Plug-in Electric Vehicles‚Äù Academy of Management Annual Meeting. Anaheim, CA. Aug. 5.         PDF SSRN                Institutions can       ‚Ä¢       dramatically affect how       ‚Ä¢       industries emerge             Helveston, J.P., Liu, Y., Feit, E.M., Fuchs, E.R.H., KlampÔ¨Ç, E., & Michalek, J.J. (2014) ‚ÄúWill subsidies drive electric vehicle adoption? Measuring consumer preferences in the U.S. and China‚Äù National Academies Transportation Research Board Annual Meeting. Washington, D.C. Jan. 13.         PDF                Full electric cars:       ‚Ä¢       Chinese seem to like them more       ‚Ä¢       than Americans"
  },
  {
    "objectID": "research.html#working-papers-papers-under-review",
    "href": "research.html#working-papers-papers-under-review",
    "title": "Research",
    "section": "Working Papers & Papers Under Review",
    "text": "Working Papers & Papers Under Review\n    *Kaplan, Leah, **Nurullaeva, L., & Helveston, J.P. (2024) ‚ÄúModeling the Operational and Labor Costs of Autonomous Robotaxi Services‚Äù Transport Policy.         PDF Code & Data         Haiku Summary                 AV taxis cost       ‚Ä¢       less than human taxis, though       ‚Ä¢       labor costs aren't nil             Hardman, S., Chakraborty, A., Hoogland, K., Sugihara, C., Helveston, J.P., Jensen, A.F., Jenn, A., Joche, P., Pl√∂tz, P., Sprei, F., Williams, B., Axsen, J., Figenbaum, E., Pontes, J., Tal, G., Refa, N. (2024) ‚ÄúDemand-side challenges and research needs on the road to 100% zero-emissions vehicle sales‚Äù Progress in Energy.         PDF                A lit review of       ‚Ä¢       demand-side issues towards       ‚Ä¢       increasing ZEV sales             Forsythe, Connor R., Arteaga, C., & Helveston, J.P. (2024) ‚ÄúThe Mixed Integrated Learning Logit (MILL) Model: A Machine Learning Approach to Modeling Unobserved Heterogeneity in Discrete Choice Analysis‚Äù Working paper.         View Code & Data Scholar                Flexible models       ‚Ä¢       of heterogeneous       ‚Ä¢       choice preferences             *Kaplan, Leah, Szajnfarber, Z., & Helveston, John P. (2024) ‚ÄúMapping the AI-Enabled Transformation of Labor in Autonomous Vehicle Taxi Services‚Äù Under review.             Jenn, A., Chakraborty, A., Hardman, S., Hoogland, K., Sugihara, C., Helveston, J.P., Rich, J., Jochem, P., Pl√∂tz, P., Sprei, F., Williams, B., Axsen, J., Figenbaum, E., Pontes, J., Refa, N. (2024) ‚ÄúSupply-side challenges and research needs on the road to 100% zero-emissions vehicle sales‚Äù Progress in Energy.                        A lit review of       ‚Ä¢       supply-side issues towards       ‚Ä¢       increasing ZEV sales             *Zhao, Lujin & Helveston, J.P. (2024) ‚ÄúSpatial Distributions of Plug-in Electric Vehicle Supply in the United States‚Äù Working paper.             *Hu, Pingfan, Tarroja, B., Dean, M., Forrest, K., Hittinger, E., Jenn, A. & Helveston, J.P. (2024) ‚ÄúMeasuring Consumer Willingness to Participate in BEV Smart Charging Programs‚Äù Working paper.             Murphree, M., Helveston, J.P., & Breznitz, D. (2024) ‚ÄúIntellectual Property as a Production Input: Expanding Theories of Institutional Change and Profiting from Innovation‚Äù Under review.                        Chinese producers       ‚Ä¢       make money by making stuff,       ‚Ä¢       not selling IP"
  },
  {
    "objectID": "research.html#magazine-publications",
    "href": "research.html#magazine-publications",
    "title": "Research",
    "section": "Magazine Publications",
    "text": "Magazine Publications\n    *Kaplan, Leah, Szajnfarber, Z., & Helveston, John P. (2023) ‚ÄúDriverless ‚Äì but not humanless ‚Äì vehicle systems‚Äù IISE Magazine. November.         PDF         Haiku Summary                 AV taxis will       ‚Ä¢       transform labor, not remove       ‚Ä¢       it altogether             Helveston, John P. (2021) ‚ÄúWhy the US Trails the World in Electric Vehicles‚Äù Issues in Science and Technology. 37, no. 2 (Winter 2021).         View PDF Scholar                US policies       ‚Ä¢       must be more aggressive to       ‚Ä¢       increase EV sales             Helveston, John P. (2017) ‚ÄúPerspective: Navigating an Uncertain Future for US Roads‚Äù Issues in Science and Technology. 34, no. 1 (Fall 2017).         View PDF Scholar                We should tax miles       ‚Ä¢       driven (not fuel consumed), or       ‚Ä¢       our roads will crumble"
  },
  {
    "objectID": "research.html#books-and-book-chapters",
    "href": "research.html#books-and-book-chapters",
    "title": "Research",
    "section": "Books and Book Chapters",
    "text": "Books and Book Chapters\n    Helveston, John P.  and **Lola Nurullaeva (2024) ‚ÄúYet Another R Dataviz (YARD) Book‚Äù         View Code & Data         Haiku Summary                 An open source book       ‚Ä¢       on good dataviz concepts       ‚Ä¢       in the R language             Helveston, John P. (2022) ‚ÄúProgramming for Analytics in R.‚Äù         View Code & Data                An open source book       ‚Ä¢       on programming in R and       ‚Ä¢       working with data             Ren, Justin Z. & Helveston, John P. (2019) ‚ÄúMeasuring Electric Vehicle Infrastructure Among Cities: A Multi-Dimensional Approach‚Äù Melting the ICE: Lessons from China and the West in the Transition from the Internal Combustion Engine to Electric Vehicles. Ed. Fox-Penner, P., Ren, Z.J., & Jermain, D.O.. Harvard University Press.         View PDF     Hatch, Jennifer & Helveston, J.P. (2019) ‚ÄúBrookline, MA: A Small Town seeking to lead in a Broader EV Charging Network‚Äù Melting the ICE: Lessons from China and the West in the Transition from the Internal Combustion Engine to Electric Vehicles. Ed. Fox-Penner, P., Ren, Z.J., & Jermain, D.O.. Harvard University Press.         View PDF"
  },
  {
    "objectID": "research.html#magazine-publications-1",
    "href": "research.html#magazine-publications-1",
    "title": "Research",
    "section": "Magazine Publications",
    "text": "Magazine Publications\n    *Kaplan, Leah, Szajnfarber, Z., & Helveston, John P. (2023) ‚ÄúDriverless ‚Äì but not humanless ‚Äì vehicle systems‚Äù IISE Magazine. November.         PDF         Haiku Summary                 AV taxis will       ‚Ä¢       transform labor, not remove       ‚Ä¢       it altogether             Helveston, John P. (2021) ‚ÄúWhy the US Trails the World in Electric Vehicles‚Äù Issues in Science and Technology. 37, no. 2 (Winter 2021).         View PDF Scholar                US policies       ‚Ä¢       must be more aggressive to       ‚Ä¢       increase EV sales             Helveston, John P. (2017) ‚ÄúPerspective: Navigating an Uncertain Future for US Roads‚Äù Issues in Science and Technology. 34, no. 1 (Fall 2017).         View PDF Scholar                We should tax miles       ‚Ä¢       driven (not fuel consumed), or       ‚Ä¢       our roads will crumble"
  },
  {
    "objectID": "research.html#opinion-editorials",
    "href": "research.html#opinion-editorials",
    "title": "Research",
    "section": "Opinion Editorials",
    "text": "Opinion Editorials\n    Helveston, John P., Triolo, P., & Nahm, J. (2024) ‚ÄúThe Problem With ‚ÄúOvercapacity‚Äù in China‚Äôs Automotive Industry‚Äù The Wire China.         View PDF     Helveston, John P. (2023) ‚ÄúElectric Vehicle Owners Are Not Driving Enough‚ÄîAnd That‚Äôs Bad‚Äù Scientific American.         View PDF     Helveston, J.P., He, G., & Davidson, M.R. (2022) ‚ÄúThe Cost of Going Solo in Solar‚Äù New Security Beat.         View PDF     Helveston, John P. (2022) ‚ÄúTo boost solar, the US should use more carrots and fewer sticks‚Äù The Hill.         View PDF     Helveston, John P. (2022) ‚ÄúTariffs won‚Äôt build a robust US solar industry‚Äù The Hill.         View PDF"
  },
  {
    "objectID": "research.html#other",
    "href": "research.html#other",
    "title": "Research",
    "section": "Other",
    "text": "Other\n    Helveston, John P. (2019) ‚ÄúPodcast: GWU Professor John Helveston on EVs in China‚Äù The Future Car: A Siemens Podcast. May 13, 2019.         Listen     Helveston, John P. (2019) ‚ÄúChina‚Äôs looser rules may usher in a new era for EV and AV companies‚Äù Axios. February 1, 2019.         View PDF     Hatch, Jennifer & Helveston, J.P. (2018) ‚ÄúWill Autonomous Vehicles be Electric?‚Äù Institute for Sustainable Energy Blog. August 8, 2018.         View PDF"
  },
  {
    "objectID": "research.html#theses",
    "href": "research.html#theses",
    "title": "Research",
    "section": "Theses",
    "text": "Theses\n    Helveston, John P. (2016) ‚ÄúDevelopment and Adoption of Plug-in Electric Vehicles in China: Markets, Policy, and Innovation‚Äù Ph.D. Dissertation. Carnegie Mellon University, Pittsburgh, PA.         View PDF CMU Repository RG"
  },
  {
    "objectID": "research.html#student-theses",
    "href": "research.html#student-theses",
    "title": "Research",
    "section": "Student Theses",
    "text": "Student Theses\n\nTheses by students advised by Helveston\n\n    Roberson, Laura A. (2024) ‚ÄúAccelerating Electric Vehicle Adoption in the United States: The Impact of Experience, Incentives, and Resale Value‚Äù Ph.D. Dissertation. The George Washington University, Washington, DC.         View PDF"
  },
  {
    "objectID": "research.html#software",
    "href": "research.html#software",
    "title": "Research",
    "section": "Software",
    "text": "Software\n    Helveston, John P. (aut, cre, cph), *Pingfan Hu (aut, cre), **Bogdan Bunea (aut, cre) (2024) ‚Äúsurveydown: Markdown-Based Surveys Using Quarto Shiny Documents‚Äù  R package.         Documentation         Haiku Summary                 Generate surveys       ‚Ä¢       with Quarto, shiny, and plain       ‚Ä¢       markdown text and code             Helveston, John P. (aut, cre, cph) (2021) ‚Äúlogitr: Fast Estimation of Multinomial and Mixed Logit Models with Preference Space and Willingness to Pay Space Utility Parameterizations‚Äù  R package.         PDF Documentation                Fast estimation       ‚Ä¢       of mixed logit models and       ‚Ä¢       WTP in R             Helveston, John P. (aut, cre, cph) & Aden-Buie, Garrick (aut) (2021) ‚Äúrenderthis: Render Slides To Different Formats‚Äù  R package.         Documentation                Render your slides to       ‚Ä¢       formats like PDF and       ‚Ä¢       PNG and more!             Helveston, John P. (aut, cre, cph) (2022) ‚ÄúcbcTools: Tools For Designing Choice-Based Conjoint Survey Experiments‚Äù  R package.         Documentation                Make designs for choice       ‚Ä¢       experiments in R and       ‚Ä¢       test them thoroughly"
  },
  {
    "objectID": "research.html#media-coverage",
    "href": "research.html#media-coverage",
    "title": "Research",
    "section": "Media Coverage",
    "text": "Media Coverage\n\nAug 13, 2024 - Politico: Quoted in article ‚ÄúYour next car might come with a battery passport‚Äù\nAug 08, 2024 - Voice of America: Quoted in article ‚ÄúChina reaches new EV milestone in July‚Äù\nJul 29, 2024 - New York Times: Study featured in article ‚ÄúElectric Cars Help the Climate. But Are They Good Value?‚Äù\nJul 01, 2024 - The World and stuff: Hour-long podcast interview: ‚ÄúChina, Trade, and Green Energy‚Äù\nJun 19, 2024 - Xataka: Quoted in article ‚ÄúThe EU and China have started a tariff war over Chinese electric cars. And Spain has a lot to lose‚Äù\nJun 18, 2024 - NPR Marketplace: Featured in radio segment on the US EV market\nJun 03, 2024 - Sustainability at the Frontier: Study featured and quoted in article ‚ÄúDo Electric Cars Depreciate Faster than Gas-Powered Cars?‚Äù\nMay 14, 2024 - Wired: Quoted in article ‚ÄúBiden Is Trying to Buy EVs Time With New Tariffs on China. It Might Not Work‚Äù\nMay 05, 2024 - Xataka: Quoted in article ‚ÄúXiaomi ha conseguido fabricar un coche masivamente en menos de tres a√±os. As√≠ es como lo ha conseguido‚Äù\nApr 27, 2024 - Washington Post: Study featured and quoted in article ‚ÄúYou can now get a $7,500 upfront discount for buying an EV‚Äù\nApr 19, 2024 - Climatewire: Study featured in article ‚ÄúWant a used EV? Prices are rising.‚Äù\nMar 28, 2024 - Issues in Science and Technology: Research referenced in article ‚ÄúLessons From a Decade of Philanthropy for Interdisciplinary Energy Research‚Äù\nMar 21, 2024 - Climatewire: Quoted in article ‚ÄúThe future of driving is electric. Sort of.‚Äù\nMar 19, 2024 - New York Times: Quoted in article ‚ÄúTesla‚Äôs Troubles Raise Questions About Its Invincibility‚Äù\nMar 18, 2024 - GW Engineering: PhD student Leah Kaplan wins first place in the 2024 3 Minute Thesis competition at GWU\nMar 04, 2024 - Vox: Quoted in article ‚ÄúWhy is Biden blocking the cheapest, most popular EVs in the world?‚Äù\nFeb 03, 2024 - Business Insider: Quoted in article ‚ÄúBattery swapping is taking off in China ‚Äî and it could help rescue the EV revolution in the US‚Äù\nJan 17, 2024 - New York Times: Study featured in article ‚ÄúAre You a Super Driver? Some States Want to Help You Go Electric.‚Äù\nDec 04, 2023 - CNN: Study featured in article ‚ÄúNew US rules on Chinese batteries could push up price of electric cars‚Äù\nNov 17, 2023 - GW Engineering: Study featured in GW Engineering post ‚ÄúSystems Engineering Team Reveals How Automated Vehicles Are Transforming Labor in Taxi Services‚Äù\nNov 13, 2023 - cleantechnica.com: Study featured in article ‚ÄúNew Study Finds Electric Vehicles Are Driven Less Than Gas Cars‚Äù\nNov 08, 2023 - GW Today: Study featured in article ‚ÄúNew Study Finds Electric Vehicles Are Driven Less Than Gas Cars‚Äù\nNov 07, 2023 - Scientific American: Study featured in article ‚ÄúElectric Vehicles Might Not Yet Have Replaced as Much Car Mileage as Hoped‚Äù\nNov 07, 2023 - Axios: Study featured in article ‚ÄúEVs are driven less than gas-powered models: study‚Äù\nNov 07, 2023 - Climatewire: Study featured in article ‚ÄúEVs are driven less than gas cars. That‚Äôs an issue for climate policy.‚Äù\nNov 06, 2023 - Watt‚Äôs Up With That: Study featured in article ‚ÄúStudy: EV‚Äôs are Cars for People Who Don‚Äôt Need to Drive (as much)‚Äù\nNov 06, 2023 - Politico: Study featured in article ‚ÄúThree questions for Gavin Newsom‚Äôs climate guru‚Äù\nOct 06, 2023 - Politico: Study featured in article ‚ÄúTreasury lays out rules for instant EV rebate‚Äù\nOct 06, 2023 - U.S. Dept of Treasury: Study featured in U.S. Department of the Treasury Press Release: ‚ÄúIRS Release Guidance to Expand Access to Clean Vehicle Tax Credits, Help Car Dealers Grow Businesses‚Äù\nOct 06, 2023 - CNN: Study featured in article ‚ÄúCar buyers can get their EV tax credits up front at the dealership starting in January‚Äù\nOct 06, 2023 - Forbes: Study featured in article ‚ÄúElectric Vehicle Buyers Can Soon Get Rebates At The Dealer‚Äù\nOct 06, 2023 - Politico: Study featured in article ‚ÄúWill an instant tax credit spark more EV sales?‚Äù\nOct 06, 2023 - E&E News: Study featured in article ‚ÄúTreasury lays out rules for instant EV rebate‚Äù\nSep 20, 2023 - Fox 5 DC: Helveston interviewed on Fox 5 DC TV story ‚ÄúDemand for charging stations rises across DMV as more EVs hit the road‚Äù\nApr 26, 2023 - Boston Globe: Quoted in article ‚ÄúWhy killing the Chevy Bolt was the right move for GM ‚Äî but it still hurts‚Äù\nApr 13, 2023 - Hearst TV: Helveston interviewed on Hearst TV on EPA‚Äôs new vehicle pollution standards.\nNov 11, 2022 - Chinese Academy of Sciences: Study featured in article ‚ÄúÂÖ®ÁêÉÂåñÁîü‰∫ßÊúâÊúõÈôç‰ΩéÂ§™Èò≥ËÉΩÊàêÊú¨‚Äù\nNov 07, 2022 - GW Hatchet: Study featured in article ‚ÄúSolar panel costs drop with global trading, SEAS professor finds‚Äù\nOct 27, 2022 - E&E News: Study featured in article ‚ÄúHow Biden‚Äôs made-in-America solar strategy may backfire‚Äù\nOct 26, 2022 - Bloomberg: Study featured in article ‚ÄúTariffs Threaten to Undermine Global Shift to Clean Energy‚Äù\nOct 26, 2022 - PV Magazine: Study featured in article ‚ÄúGlobalized supply chains saved $67 billion in solar panel production costs‚Äù\nOct 26, 2022 - Times of San Diego: Study featured in article ‚ÄúOpen Trade Saves Billions Worldwide on Solar Panels, Study Involving UCSD Finds‚Äù\nOct 26, 2022 - GW Today: Study featured in article ‚ÄúGlobal Collaboration Saved Countries $67 Billion in Solar Panel Production Costs‚Äù\nOct 26, 2022 - UCSD News: Study featured in article ‚ÄúOpen Trade Saves Countries Billions in Solar Panel Production‚Äù\nOct 26, 2022 - Stonybrook U News: Study featured in article ‚ÄúGlobal Collaboration is Key to Saving Billions for Solar Module Production‚Äù\nSep 12, 2022 - Nasdaq: Study featured in article ‚ÄúA ‚ÄòTale of Two Cities‚Äô and the Energy Crisis‚Äù\nAug 19, 2022 - NA: Study featured in article ‚ÄúInflation Reduction Act seeks to jumpstart electric vehicle market: Substantial tax credits and other incentives for renewable energy and EVs‚Äù\nAug 12, 2022 - Time: Quoted in ‚ÄúWhat Experts Say About How Valuable The Inflation Reduction Act‚Äôs Green Subsidies Will Be‚Äù\nAug 11, 2022 - NPR: Featured in ‚ÄúAll Things Considered‚Äù segment\nAug 11, 2022 - NPR: Quoted in article ‚Äú3 ways the Inflation Reduction Act would pay you to help fight climate change‚Äù\nJul 29, 2022 - Green Car Reports: Study featured in article ‚ÄúEV tax credit extension with $7,500 point-of-sale rebate, $4,000 for used EVs could pass Senate soon‚Äù\nJul 12, 2022 - Green Car Reports: Study feature article: ‚ÄúStudy: Point-of-sale EV rebates buyers prefer could have saved $2 billion vs.¬†tax credits‚Äù\nJul 14, 2022 - dotLA: Study featured in Electric Vehicle Tax Rebates Favor the Wealthy\nJul 11, 2022 - The Drive: Study featured in The Drive\nJul 07, 2022 - Politico: Quoted in The Manchin show: What‚Äôs in, what‚Äôs out?\nApr 29, 2022 - CGTN: Long form interview with CGTN Full Frame: Going Green\nApr 26, 2022 - GW Today: EMSE Student Eliese Ottinger highlighted in GW Today article on SEAS research showcase\nMar 25, 2022 - Reuters: Quoted in Inside China‚Äôs electric drive for swappable car batteries\nJan 26, 2022 - Intelligencer: Quoted in To Fight Climate Change, Bring Back State Planning\nOct 27, 2021 - RWeekly: Blog post on simulating the Squid Game bridge scene showcased on the RWeekly podcast.\nMay 30, 2021 - The Wire China: Quoted in ‚ÄúThe Competition Conundrum‚Äù\nApr 23, 2021 - CNN Climate Town Hall: Asked question to U.S. Secretary of State John Kerry (Watch)\nMar 21, 2021 - Market Scale: Interview: Can Geely Join the Ranks of Luxury EV Brands?\nMar 03, 2020 - Associated Press: TV interview: ‚ÄúChina‚Äôs emissions drop amid coronavirus outbreak.‚Äù\nJul 25, 2020 - Forbes: Quoted in ‚ÄúThis Is A Big Reason Electric Cars Still Aren‚Äôt Popular With Americans: Study‚Äù\nNov 21, 2019 - NPR Climate Cast: Quoted in ‚ÄúTrade dispute with China could slow transition to low-carbon power‚Äù\nNov 15, 2019 - Xinhua News: Quoted in ‚ÄúÁæéËÉΩÊ∫ê‰∏ìÂÆ∂ÂëºÂêÅÁæéÂä†Âº∫‰∏é‰∏≠ÂõΩÂêà‰Ωú‰ª•ÂÆûÁé∞ÂáèÊéíÁõÆÊ†á‚Äù\nNov 15, 2019 - GW Today: Interview, ‚ÄúCollaboration with China Is Critical to Achieving Climate Goals‚Äù\nOct 28, 2019 - Physics World: Interview, ‚ÄúUS motorists prepared to pay more for fuel to lower emissions‚Äù\nMay 19, 2015 - CMU Engineering: Interivew, ‚ÄúWhat do American and Chinese consumers want in an electric vehicle?‚Äù"
  },
  {
    "objectID": "lab.html",
    "href": "lab.html",
    "title": "Technology Change Lab",
    "section": "",
    "text": "The Technology Change Lab conducts interdisciplinary research that explores relationships between technological change and factors that shape it, such as consumer behavior, market dynamics, and policy. We apply a systems engineering perspective to better understand these relationships and to inform policy, with an emphasis on accelerating transitions to cleaner technologies."
  },
  {
    "objectID": "lab.html#faculty",
    "href": "lab.html#faculty",
    "title": "Technology Change Lab",
    "section": "Faculty",
    "text": "Faculty\n\n\n\nJohn Paul Helveston, Ph.D.\nJohn Paul Helveston is an Assistant Professor in the Department of Engineering Management and Systems Engineering at the George Washington University. He studies technological change, with a particular interest in accelerating the transition to environmentally sustainable and energy-saving technologies. His research centers around how consumer preferences, market dynamics, and policy affect the emergence of critical technologies, such as electric vehicles and solar energy. He is an expert on China‚Äôs rapidly emerging electric vehicle industry as well as the critical relationship between the US and China in developing and mass producing low carbon energy technologies. He applies an interdisciplinary approach to research, with expertise in discrete choice modeling and conjoint analysis as well as interview-based case studies. He has conducted extensive fieldwork in China, collaborating with colleagues at Beijing Normal University and China‚Äôs State Information Center on past projects. He is a fluent speaker of Mandarin Chinese and also an award-winning swing dancer. John holds a Ph.D.¬†and M.S. in Engineering and Public Policy from Carnegie Mellon University and a B.S. in Engineering Science and Mechanics from Virginia Tech."
  },
  {
    "objectID": "lab.html#ph.d.-students",
    "href": "lab.html#ph.d.-students",
    "title": "Technology Change Lab",
    "section": "Ph.D.¬†Students",
    "text": "Ph.D.¬†Students\n\n\n\nLujin Zhao (ËµµÈ≤ÅÊôã)\nLujin received a B.S. in Agricultural and Resources Economics from University of Maryland, a M.S. degree in Economics from Tufts University, and a M.S. degree in Data Analytics from the George Washington University. His interests are China‚Äôs EV subsidy policies, environmental impacts from the EV industry, and energy policy. For the past several years, he has been living in the DC area and he really enjoys the summertime here except for during June, July and August.\n\n\n\n\nPingfan Hu (ËÉ°Âπ≥Âá°)\nPingfan received a M.P.E. degree in Mechanical Engineering from Sydney University, and a B.S. degree in Industrial Engineering from Penn State University. Prior to joining GW, Pingfan had 4 years of work experience in supply chain and engineering management. His primary research interest is the adoption of PEV smart charging, with an expansion to V2G charging. He is currently working on a study using conjoint analysis to assess people‚Äôs willingness to participate in such programs.\n\n\n\n\nMichael Rossetti\nMichael Rossetti is a data scientist and software engineer. He has worked as a data analyst for a winning US Presidential campaign, an analytics director for a Silicon Valley startup, and a technology consultant for the US Government. He teaches courses in data science, computer science, and software development, and conducts research in applied machine learning.\n\n\n\n\nZain Hoda\nZain received his MS in Data Analytics from George Washington University. Prior to joining GW, Zain had roughly five years of experience in Data Mining and ETL. Zain‚Äôs research area is the adoption of electric vehicles in Disadvantaged communities. He is currently working on a study using conjoint analysis to examine the feasibility of EV adoption in DACs within the context of financial constraints and EV availability in these communities."
  },
  {
    "objectID": "lab.html#undergraduate-students",
    "href": "lab.html#undergraduate-students",
    "title": "Technology Change Lab",
    "section": "Undergraduate Students",
    "text": "Undergraduate Students\n\n\n\nBogdan Bunea\nBogdan is an undergraduate student majoring in Systems Engineering and minoring in Computer Science. In his time at GWU, Bogdan has worked in multiple labs (EMSE & MAE) as well as participated in multiple clubs such as GWU-Rocket and GWU-Sat. In Dr.¬†Helveston‚Äôs lab, Bogdan helped create a databasing system for the surveydown, an open source survey project. Bogdan also helped with data wrangling and scraping data about all available cars on the market.\n\n\n\n\nLola Nurullaeva\nLola is an undergraduate student in Systems Engineering at The George Washington University (class of 2025). In Dr.¬†Helveston‚Äôs lab, she supported a project led by Ph.D.¬†student Leah Kaplan modeling the cost to operate an autonomous vehicle taxi service."
  },
  {
    "objectID": "lab.html#alumni",
    "href": "lab.html#alumni",
    "title": "Technology Change Lab",
    "section": "Alumni",
    "text": "Alumni\n\n\n\nLaura Roberson\n\nPhD Systems Engineering, 2024\nLaura dissertation focused on consumer acceptance and interaction with innovative technologies, especially in the transportation industry. Her research interests include electric vehicle adoption, innovation developments and policies that promote innovations. She also has 10+ years working for a global automotive manufacturer, giving her a balance of academic and industry knowledge and experience. Laura received her BS in Industrial and Systems Engineering from Virginia Tech and her MS in Systems Engineering from the great GWU EMSE department. She defended her dissertation in February 2024.\n\n\n\n\n\nLeah Kaplan\n\nPhD Systems Engineering, 2024\nLeah pursued her PhD in Systems Engineering as a National Science Foundation Graduate Research Fellow. Leah graduated summa cum laude with her Bachelor‚Äôs in chemical engineering from the University of Arizona before moving to DC to pursue an interest in science policy. Leah interned with the House Committee on Science, Space, and Technology and worked for the Arizona State University Consortium for Science, Policy & Outcomes. Leah‚Äôs primary research interest is decision-making under uncertainty related to emerging technologies, with a focus on transportation. Her dissertation focused on understanding how we can leverage technologies for the benefit of, rather than detriment to, society. She defended her dissertation in August 2024.\n\n\n\n\n\nEliese Ottinger\n\nMS Systems Engineering, 2024BS Systems Engineering, 2023\nEliese worked with Professor Helveston as both an undergraduate and masters student in Systems Engineering at George Washington University. She graduated with her Bachelors degree in Systems Engineering in 2023 with minors in Sustainability and Mathematics, and will graduate with her MS degree in 2024. In Dr.¬†Helveston‚Äôs lab, she analyzed differences in how people drive gas vehicles and electric vehicles and is an author on a resulting publication.\n\n\n\n\n\nSaurav Pantha\n\nMS Systems Engineering, 2021\nSaurav worked with Professor Helveston as a masters student in Systems Engineering at George Washington University. Originally from Kathmandu, Nepal, he graduated with he MS degree in Systems Engineering in 2021. Before GW, he worked at a business consulting firm based out of Bangalore, India, helping multiple automotive & banking clients to solve business problems through data analytics solutions. Within Dr.¬†Helveston‚Äôs lab, he supported multiple research projects by setting up a pipeline for a MySQL database, writing R scripts to clean & wrangle data, and conducting literature surveys. In his free time, he loves to go on treks and watch Manchester United‚Äôs soccer games live.\n\n\n\n\n\nKazi Asifa Ashrafi\n\nBS Systems Engineering, 2022\nKazi worked with Professor Helveston as a sophomore undergraduate student in Systems Engineering at George Washington University. Originally from Bangladesh, she graduated with her Bachelors degree in Systems Engineering in 2022 with a minor in Statistics. She has always been enthusiastic about advocating for social causes and was previously involved in research projects at Penn State that aimed to enhance skills of preschoolers in the area of social-emotional development. She recently interned at a non-profit focusing on issues surrounding diaspora communities in regards to climate change. In Dr.¬†Helveston‚Äôs lab, she explored the geo-spatial distribution of electric vehicles (EVs) across the U.S.\n\n\n\n\n\nHelena Rowe\n\nBS Systems Engineering, 2022\nHelena worked with Professor Helveston as a sophomore undergraduate student in Systems Engineering at George Washington University. Originally from Marblehead, Massachusetts, she graduated with her Bachelors degree in Systems Engineering in 2022 with a minor in Sustainability. In previous roles, she has worked for a small consulting firm, analyzed market research for a building materials start-up, and researched with a professor about climate change risks in the investment industry. Within Dr.¬†Helveston‚Äôs lab, she worked on electric vehicle (EV) sales forecasting over time from different organizations.\n\n\n\n\n\nAmelia Jacquat\n\nBS Systems Engineering, 2023\nAmelia worked with Professor Helveston as a sophomore undergraduate student in Systems Engineering at George Washington University. Originally from New Orleans, LA, she graduated with her Bachelors degree in Systems Engineering in 2023 with minors in Computer Science and Theatre. Within Dr.¬†Helveston‚Äôs lab, she worked on electric vehicle (EV) sales forecasting over time from different organizations."
  },
  {
    "objectID": "lab.html#current-opportunities",
    "href": "lab.html#current-opportunities",
    "title": "Technology Change Lab",
    "section": "Current Opportunities",
    "text": "Current Opportunities\nWhile I am not currently seeking new Ph.D.¬†students, I am always happy to hear from motivated potential students who are considering a Ph.D.¬†through the Engineering Management & Systems Engineering Department at GWU. If you are interested in working with me as your advisor, please send me an email with the following attachments:\n\nYour CV.\nA written statement describing specific research topics you are interested in and why (at least one page).\nA summary of your prior research experience and skills."
  },
  {
    "objectID": "lab.html#graduate-research-assistants",
    "href": "lab.html#graduate-research-assistants",
    "title": "Technology Change Lab",
    "section": "Graduate Research Assistants",
    "text": "Graduate Research Assistants\nAlthough currently I am not seeking a GRA for ongoing research projects, there is a good chance that I may have opportunities in the near future. If you are a masters student and would like to gain some research experience in my lab, please send me an email with the following information:\n\nYour CV.\nA brief statement of your research interests.\nA brief summary of your prior research experience and skills.\n\nCandidates with the following skills / experience are particularly encouraged: webscraping, data cleaning, exploratory data analysis, life cycle assessment, simulation."
  },
  {
    "objectID": "lab.html#undergraduate-research-assistants",
    "href": "lab.html#undergraduate-research-assistants",
    "title": "Technology Change Lab",
    "section": "Undergraduate Research Assistants",
    "text": "Undergraduate Research Assistants\nIf you are an undergraduate student and would like to gain some research experience in my lab, don‚Äôt hesitate to send me an email. I frequently have specific research tasks that make for great undergraduate research projects. If you are interested, please send me an email with the following information:\n\nYour CV.\nA brief statement describing specific research topics you are interested in and why."
  },
  {
    "objectID": "lab.html#visitors",
    "href": "lab.html#visitors",
    "title": "Technology Change Lab",
    "section": "Visitors",
    "text": "Visitors\nI am happy to welcome visiting scholars and students to my lab. Although I do not have funding at the moment to sponsor visitors, I would be happy to host you if you can be funded by your own institutions or other sources. Please email me your CV and research plan for further discussions."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "John Paul Helveston",
    "section": "",
    "text": "Welcome to my personal website!\nI am a researcher, engineer, choice modeler,  developer, musician, swing dancer, and an Assistant Professor at George Washington University in the Department of Engineering Management and Systems Engineering. I study technological change with a focus on accelerating the transition to low-carbon technologies like electric vehicles and renewable energy technologies.\n\n\n\n Back to top"
  },
  {
    "objectID": "research/index.html",
    "href": "research/index.html",
    "title": "Research paper summaries",
    "section": "",
    "text": "No matching items\n\n\n  \n\n Back to top"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "Introducing {surveydown}: A markdown-based framework for generating surveys with Quarto and shiny (that now exists!!!)\n\n\n\n\n\nA quick overview of the {surveydown} R package for making markdown-based surveys with open-source technologies: Quarto, shiny, and supabase. \n\n\n\n\n\n2024-08-10\n\n\nJohn Paul Helveston\n\n\n\n\n\n\n\n\n\n\n\n\n{surveydown}: An open source, markdown-based survey framework (that doesn‚Äôt exist yet)\n\n\n\n\n\nLet‚Äôs build this, who‚Äôs with me? \n\n\n\n\n\n2023-04-06\n\n\nJohn Paul Helveston\n\n\n\n\n\n\n\n\n\n\n\n\nRender parameterized reports with Quarto\n\n\n\n\n\nA quick how-to guide for making reports in Quarto with custom parameters, and a couple fixes for some current limitations. \n\n\n\n\n\n2023-02-28\n\n\nJohn Paul Helveston\n\n\n\n\n\n\n\n\n\n\n\n\nWhy chess is a better game than golf\n\n\n\n\n\nI asked ChatGPT to write this blog post. Here‚Äôs what it came up with. \n\n\n\n\n\n2022-12-26\n\n\nJohn Paul Helveston\n\n\n\n\n\n\n\n\n\n\n\n\nIntroducing the {renderthis} package\n\n\n\n\n\nA brief introduction to the {renderthis} package for rendering {xaringan} slides to different output types (previously called {xaringanBuilder}) \n\n\n\n\n\n2022-06-28\n\n\nJohn Paul Helveston\n\n\n\n\n\n\n\n\n\n\n\n\nSimulating the Squid Game bridge scene in R\n\n\n\n\n\nA simple monte carlo simulation of the expected number of survivors from the Squid Game bridge scene Contains Spoilers \n\n\n\n\n\n2021-10-19\n\n\nJohn Paul Helveston\n\n\n\n\n\n\n\n\n\n\n\n\nChoice-based conjoint surveys in R with formr\n\n\n\n\n\nA how-to guide for using R to design and implement choice-based conjoint surveys using formr.org \n\n\n\n\n\n2021-09-18\n\n\nJohn Paul Helveston\n\n\n\n\n\n\n\n\n\n\n\n\nIn search of keyboard nirvana\n\n\n\n\n\nMy journey to find a more ergonomic (and useful) keyboard \n\n\n\n\n\n2021-07-03\n\n\nJohn Paul Helveston\n\n\n\n\n\n\n\n\n\n\n\n\nExpand your productivity with espanso\n\n\n\n\n\nCustom text snippets with espanso: a text expander written in Rust \n\n\n\n\n\n2021-05-04\n\n\nJohn Paul Helveston\n\n\n\n\n\n\n\n\n\n\n\n\nCustomizing distill with {htmltools} and CSS\n\n\n\n\n\nHow I added lots of little features to my distill site with the {htmltools} package, CSS, and a handful of little R functions. \n\n\n\n\n\n2021-03-25\n\n\nJohn Paul Helveston\n\n\n\n\n\n\nNo matching items\n\n\n  \n\n Back to top"
  },
  {
    "objectID": "talks/index.html",
    "href": "talks/index.html",
    "title": "Talks",
    "section": "",
    "text": "The cbcTools Package: Tools for Designing and Testing Choice-Based Conjoint Surveys in R\n\n\n\n\n\nMy talk for the 2022 Sawtooth Software Conference \n\n\n\n\n\n2022-05-06\n\n\nJohn Paul Helveston\n\n\n\n\n\n\n\n\n\n\n\n\nInterview with CGTN Full Frame: Going Green\n\n\n\n\n\nI was featured in a long-form interview with CGTN discussing the challenges and opportunities China faces in the race to decarbonize it‚Äôs energy systems. \n\n\n\n\n\n2022-04-30\n\n\nJohn Paul Helveston\n\n\n\n\n\n\n\n\n\n\n\n\nISA Industrial Policy Webinar Series: Taking Charge\n\n\n\n\n\nI moderated the ISA Webinar on ‚ÄúBatteries for Electric Vehicles and the Transformation of the Automotive Supply Chain‚Äù \n\n\n\n\n\n2021-12-01\n\n\nJohn Paul Helveston\n\n\n\n\n\n\n\n\n\n\n\n\nHealthier ‚ù§Ô∏è & Happier üòÑ Hands üôå\n\n\n\n\n\nMy talk on Software and Hardware Solutions for More Ergonomic Typing for the 2021 useR! Conference \n\n\n\n\n\n2021-07-06\n\n\nJohn Paul Helveston\n\n\n\n\n\n\n\n\n\n\n\n\nObtaining Willingness to Pay Estimates from Preference Space and Willingness to Pay Space Utility Models\n\n\n\n\n\nMy talk for the 2021 Sawtooth Conference Turbo Choice Modeling Panel \n\n\n\n\n\n2021-04-20\n\n\nJohn Paul Helveston\n\n\n\n\n\n\n\n\n\n\n\n\nUsing formr to create R-powered surveys with individualized feedback\n\n\n\n\n\nMy rstudio::conf 2021 lightning talk on creating R-powered surveys using {formr}‚Äù \n\n\n\n\n\n2021-01-21\n\n\nJohn Paul Helveston\n\n\n\n\n\n\n\n\n\n\n\n\nU. Albany Confucius Institute Fall 2020 Seminar on US-China Relations in the 21st Century\n\n\n\n\n\nMy discussion with Barry Naughton (UCSD) about industrial policy and low-carbon energy technologies in China \n\n\n\n\n\n2020-10-09\n\n\nJohn Paul Helveston\n\n\n\n\n\n\nNo matching items\n\n\n  \n\n Back to top"
  },
  {
    "objectID": "blog/2022-12-26-why-chess-is-better-than-golf/index.html",
    "href": "blog/2022-12-26-why-chess-is-better-than-golf/index.html",
    "title": "Why chess is a better game than golf",
    "section": "",
    "text": "Image source: https://theawesomer.com/golf-chess-set/132440/\n\nIf you‚Äôve been paying attention to AI progress in 2022, you almost certainly have heard of ChatGPT, an AI engine made by Open AI, that can generate remarkably detailed text and code to prompts. Like many, I wanted to test it out to see what it could come up with. This post summarizes the results of that experiment.\nThis initial post is based on the very first publicly available chat engine, ChatGPT, which is based on GPT3. In the future, I plan to update this post with responses from increasingly performant chat AIs to the exact same prompts.\n\nRound 1\nMy starting prompt for this post was quite simple:\n\nWrite a blog post arguing why chess is a much better game for people to adopt than golf.\n\nI chose this prompt for several reasons. First, it asks for an argumentative blog post, and I wanted to see how well the chat AI would do at coming up with some arguments for this topic. Second, I wanted to see what the AI would write on a topic that I haven‚Äôt seen someone else write about before. I tried to think of something relatively obscure, but specific enough that there might be some clear, logical arguments.\nBut most importantly, I wanted to see what specific arguments the AI would use. There are some rather obvious social and environmental aspects to this topic, such as the difference in resource requirements to play each game (golf, for example, requires a lot more land). Both games are also social activities, and both can be played across just about all ages. There are also mental and health benefits to each game. I was curious what arguments the AI would use with no further prompting.\nHere is what it produced based on the first prompt:\n\nChess and golf are both popular leisure activities that require strategy, skill, and mental focus. However, there are several reasons why chess is a much better game for people to adopt than golf.\nFirst, chess is a much more accessible and affordable game than golf. While golf requires expensive equipment and exclusive membership to a club or course, all you need to play chess is a chessboard and pieces, which can be purchased for a relatively low cost. Additionally, chess can be played anywhere, whether it‚Äôs at home, in a park, or online, while golf requires a dedicated course.\nSecond, chess is a more inclusive game than golf. Golf has a reputation for being a primarily wealthy and white-dominated sport, while chess has a more diverse player base and is more accessible to people of different socio-economic backgrounds.\nThird, chess has a range of benefits for the mind and body. Studies have shown that playing chess can improve problem-solving skills, critical thinking, and memory, as well as reduce the risk of developing conditions such as dementia and Alzheimer‚Äôs disease. Golf, on the other hand, has fewer cognitive benefits and requires more physical exertion, making it less suitable for those with mobility issues or disabilities.\nFinally, chess is a more universal and timeless game than golf. While golf is primarily popular in certain parts of the world and has a somewhat limited appeal, chess is played and enjoyed by people all over the globe, and its popularity has endured for centuries.\nIn conclusion, chess is a superior game to golf for several reasons. It is more accessible, inclusive, beneficial for the mind, and universal in its appeal. If you‚Äôre looking for a strategic and mentally stimulating activity, chess is the clear choice.\n\nOverall, not too shabby for a single-line prompt. But the post itself was rather simple and robotic. The writing structure is about as basic as you could get, and the arguments are all pretty obvious. For a grade school writing assignment, this would pass, but it‚Äôs nothing I would be excited about reading.\nThat said, I found it impressive that I didn‚Äôt even need to prompt it about including social aspects around this topic. The response highlighted the exclusivity of golf, and it also mentioned something about health benefits from chess.\nBut the biggest flaw I saw was the lack of any references to some of the claims in the post. In particular, the AI wrote a sentence stating that ‚Äústudies have shown that playing chess can‚Ä¶reduce the risk of developing conditions such as dementia and Alzheimer‚Äôs disease.‚Äù Any post that includes a line like that better have some references to those ‚Äústudies.‚Äù So I updated my prompt asking explicitly for references. I also asked the AI to include details about the environmental impacts of golf as that is a well-known issue with the game.\n\n\nRound 2\nMy second prompt read:\n\nI want you to write me a blog post. This post should include technical details to support any arguments provided to it. The topic of the post is to argue why chess is a much better game for people to adopt than golf. Include details about the environmental damages from golf as well as information about the social dynamic of golf, such as networking benefits.\n\nHere is the response I got:\n\nCertainly, here is a blog post arguing why chess is a better game than golf:\nWhy Chess is a Better Game than Golf\nGolf is a popular leisure activity enjoyed by millions of people around the world, but it is not without its drawbacks. In contrast, chess is a game that offers numerous benefits and is a superior choice for those looking for a challenging and rewarding pastime.\nOne of the main criticisms of golf is its environmental impact, particularly with regard to land use. Golf courses require a significant amount of land to be developed and maintained, and this land is often taken from natural habitats. According to a study published in the Journal of Environmental Management, the average golf course in the United States occupies approximately 120 acres (48.5 hectares) of land (Karecha, Jorgensen, & Madsen, 2002). This land is often not available for other uses, such as agriculture or housing, leading to a loss of ecosystem services and biodiversity (Karecha et al., 2002). In addition, the chemicals used to keep the greens and fairways in pristine condition can have negative impacts on local ecosystems (Karecha et al., 2002). In contrast, chess requires no physical space or resources beyond a board and pieces, making it a more environmentally friendly option.\nGolf can also be a divisive and exclusive activity. Golf courses and club memberships are often expensive, making them out of reach for many people. This exclusivity can create a social hierarchy and foster a culture of elitism. In contrast, chess is a game that can be enjoyed by people of all ages, backgrounds, and skill levels. It requires no special equipment or facilities, making it accessible to everyone.\nBut while golf may be traditionally seen as a game for social networking, chess can offer similar opportunities for social interaction and networking. Many chess clubs and organizations exist worldwide, providing a platform for people with a shared interest in the game to come together and socialize. These clubs often host tournaments and other events, providing opportunities for players to compete and meet new people. In addition, the internet has made it possible for chess players to connect and play with others online, further expanding the potential for social interaction and networking.\nPerhaps the most compelling reason to choose chess over golf is the cognitive benefits of the game. Chess is a highly strategic and challenging game that requires deep concentration and problem-solving skills. It has been shown to improve brain function, including memory, critical thinking, and decision-making skills (Gauthier, Tardif, & Belleville, 2010). In contrast, golf is often viewed as a leisurely activity that does not offer the same level of mental stimulation.\nIn conclusion, chess is a superior game to golf for a variety of reasons. It is environmentally friendly, particularly with regard to land use and chemical use, accessible to all, and offers significant cognitive benefits. It can also provide opportunities for social interaction and networking. If you‚Äôre looking for a challenging and rewarding pastime, consider giving chess a try. You might be surprised at how much you enjoy it.\nReferences:\nGauthier, S., Tardif, C., & Belleville, S. (2010). The benefits of chess for children‚Äôs cognitive and social development: A systematic review. Frontiers in Psychology, 1, 186. https://doi.org/10.3389/fpsyg.2010.00186\nKarecha, J., Jorgensen, B. E., & Madsen, J. (2002). The environmental impacts of golf courses: A review. Journal of Environmental Management, 66(3), 319-334. https://doi.org/10.1006/jema.2002.0490\n\nThese additions felt a lot more impactful than the original post in terms of writing a persuasive argument. I appreciated the inclusion of ‚Äúfacts‚Äù like the amount of land used for an average golf course, as well as references to support those ‚Äúfacts.‚Äù\nThe problem is these ‚Äúfacts‚Äù are fake. The references included look real, but they are both completely fabricated. The DOI links included are actually real DOIs, but they link to totally different and unrelated papers. So after reading this, I actually have no idea whether the average golf course in the U.S. is 120 acres, or whether golf courses lead to a ‚Äúloss of ecosystem services and biodiversity.‚Äù The only way I can think to find out about whether these statements are true is to use an actual search engine like Google to search for real sources.\nI found this outcome deeply troubling. The overall writing was much better in this second round with a more detailed prompt, but the arguments are based on potentially false results with fabricated references.\nWhere this goes next is going to get really interesting. Will the next chat AI be able to include references to real research papers? Will the arguments become more nuanced? Will the output include more quantitative arguments, such as quantifying the reduction in biodiversity from golf courses (if that‚Äôs even true)? Given how quickly these models are developing I would not be surprised if the answer to all of the above is ‚Äúyes‚Äù. Time will tell, and I will update this post when the next chat AI is made publicly available.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "da-faq.html",
    "href": "da-faq.html",
    "title": "Data Analytics MS FAQ",
    "section": "",
    "text": "This page contains information for students in the Master of Science in Data Analytics program at George Washington University."
  },
  {
    "objectID": "da-faq.html#frequently-asked-questions",
    "href": "da-faq.html#frequently-asked-questions",
    "title": "Data Analytics MS FAQ",
    "section": "Frequently Asked Questions",
    "text": "Frequently Asked Questions\n\nWhat is the recommended sequence for full-time students?\n\nSemester 1:\n\nCSCI 6444 Introduction to Big Data and Analytics\nEMSE 6765 Data Analysis for Engineers and Scientists\nEMSE 6574 Programming for Analytics\n\nSemester 2:\n\nEMSE 6586 Data Management Systems for Data Analytics\nFirst Required Track Course\n\nCS Track: CSCI 6212 Design and Analysis of Algorithms\nEMSE Track: EMSE 6575 Applied Machine Learning for Analytics\nElective\n\n\nSemester 3:\n\nSecond Required Track Course\n\nCS Track: CSCI 6364 Machine Learning\nEMSE Track: EMSE 6577 Data-Driven Policy\n\nElective\nElective\n\nSemester 4:\n\nSEAS 6402 Data Analytics Capstone\n\n\nThis leaves your final semester light on course work, which many students find helpful as they apply for jobs and can focus their time on interview preparation.\nNOTE: The above schedule is optimized for students starting in a fall semester. If you begin in spring, EMSE 6574 is usually not offered. If you are in the CS track, we recommend taking CSCI 6212 instead, or if you are in the EMSE track you can pick an EMSE course without prerequisites to take as an elective.\n\n\nWhat is the recommended sequence for part-time students taking 6 credits a semester?\n\nSemester 1:\n\nCSCI 6444 Introduction to Big Data and Analytics\nEMSE 6574 Programming for Analytics\n\nSemester 2:\n\nEMSE 6765 Data Analysis for Engineers and Scientists\nEMSE 6586 Data Management Systems for Data Analytics\n\nSemester 3:\n\nFirst Required Track Course (CSCI 6212 or EMSE 6575)\nElective\n\nSemester 4:\n\nSecond Required Track Course (CSCI 6364 or EMSE 6577)\nElective\n\nSemester 5:\n\nElective\nSEAS 6402 Data Analytics Capstone\n\n\n\n\nCan you help me understand the overall degree requirements?\nThe full requirements in the Bulletin are:\n\nComplete the five Required Courses\nComplete two Required Track courses for your focus area (CSCI 6212 and CSCI 6364 or EMSE 6575 and EMSE 6577)\nComplete one more Elective course in your track‚Äôs department at the 6000+ level\nComplete two additional electives. These can be 6000+ courses from any department, but if they are outside of CS or EMSE, then you need to get approval from your advisor first.\n\n\n\nDo I need to take CSCI 6362 Probability for Computer Science as a Prerequisite for CSCI 6364 Machine Learning?\nNo.¬†This is not required as long as you have a statistics/probability course at the undergraduate level. Taking EMSE 6765 Data Analysis for Engineers and Scientists will also meet this need.\n\n\nCan you help me choose electives?\nIn general, any 6000 level course should generally be able to be counted for one of your two unrestricted electives. To find courses you may be interested in, check these resources:\n\nView the schedule of classes to see what will actually be offered in the semester you are interested in. Not all courses are offered every semester, and this is the best way to know what will actually be offered.\nView this Google sheet of common electives. While this list is not a comprehensive list of all electives, it does represent courses that DA students have taken in the past. It is a good list to start with when searching for electives, and it is continuously updated.\n\n\n\nHow many courses do I need in my focus area (CS or EMSE)?\nYou must take at least 3 courses in the track you have selected ‚Äì two are required and the third is any of your choice from that department.\n\n\nCan I take course X which is not listed in the degree requirements?\nIf it is a 6000 level course, then generally yes it can be one of your two unrestricted electives. You should contact your advisor for approval first.\nYes, but you will need to fill out the CS Department‚Äôs Registration help form. Contact your advisor or cs@gwu.edu for more information.\n\n\nCan the SEAS 6402 DA Capstone course only be taken in Spring semesters?\nThe course is typically only offered in the spring, though some years we also offer a smaller fall section. You should not take 6402 until you have completed the other four required courses. If you start the program in Spring, then we recommend taking it in your 3rd semester (i.e., your second spring, a semester before graduation). If you are not able to take the course at the normal time, you should consult with your advisor before your last semester about completing the capstone as an independent project.\n\n\nI want to register for a 6000 level course, but I‚Äôm restricted, how do I register?\nSome courses have restrictions on who can register for a variety of reasons. Often times the restriction is due to missing prerequisite courses or the course is only offered to majors in that field (e.g.¬†most courses in DATS are restricted to DATS majors). The best course of action depends on the specific situation. Here is some guidance:\n\nFor EMSE courses: Fill out an RTF and send it to Professor Helveston for approval.\nFor CSCI courses: Go to the CS Department‚Äôs Registration help form and fill out the request form.\nFor DATS courses: Fill out the Data Science Course Registration Request Form. If you‚Äôre unsure, you can also email DATS.\nFor any other course: Fill out an RTF and send it to the course instructor for approval. In these cases (especially if it‚Äôs a course outside of SEAS), also include a message as to why you want to enroll in the course.\n\nIn general, if there are prerequisite issues preventing you from registering, also explain in your email why you should be exempt from the prerequisite (e.g.¬†you have prior experience or have taken a similar course, etc.). There are no guarantees that you will be allowed to enroll in the course, but following these steps is the best approach.\n\n\nI‚Äôm interested in becoming a Teaching Assistant or Research Assistant, how can I apply for one of these positions?\nGTA (teaching assistantship) positions are limited and typically offered to students later in the program (e.g.¬†year 2) to GTA for a course they‚Äôve already taken in their first year. There are not many of these available, and many are prioritized for PhD students over MS students since PhDs have longer tenures in SEAS (4-5 years) and because many will be in academic settings in their careers and therefore need more teaching experience. The best advice for these positions is to do an excellent job in the classroom and discuss with each faculty member you take a course with that has a GTA to see if you could take on a GTA position in the future. Directly expressing your interest to the faculty is the best thing you can do.\nGRA (research assistantship) positions are typically arranged on a faculty-by-faculty basis and usually supported by external research funding. The best way to find opportunities is to reach out to individual faculty and ask if there are potential GRA positions in their lab. It is also best to read up on the faculty member you are reaching out to to make sure their lab focuses on a topic that you are interested in and have something to offer. This isn‚Äôt limited to SEAS - you could be a GRA for a professor in a different school, and it is not strange for a DA student to use their skills in other domains, such as public health, the Elliott School, etc. Again, directly reaching out to faculty members is the best advise for obtaining one of these positions.\n\n\nI am looking for an internship or job in Data Analytics / Data Science, what should I do?\nFirst, reaching out to SEAS career services is a good idea. And it is also a good idea to get on Linkedin and get your CV / Resume setup so employers can find you.\nMeet ups: Beyond these channels, you can also significantly improve your chances of getting a position by networking with people in the DC area. For example, attend some of the Data Science DC meetups. Many of the participants are data professionals in the greater DC area and may know of a company hiring.\nOnline: You can also network online. Linkedin sometimes works, but joining Slack communities can also be a helpful way to connect with people. The Data Science Learning Community community, for example, has a very active Slack that you can join that is open to the public. The group was originally an R-focused group, but it is increasingly more diverse and has many resources on multiple languages, and they often post general jobs that are not language-specific.\nFinally, I would also recommend reading the book Build a Career in Data Science. The authors have many great suggestions and answer a lot of important questions about searching for and successfully finding a job in this field."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Welcome! I am a researcher, engineer, choice modeler,  developer, musician, swing dancer, and an Assistant Professor in the Department of Engineering Management and Systems Engineering at The George Washington University. See my CV for more details.\n\nShort Bio\nJohn Paul (JP) is an Assistant Professor at George Washington University in the Department of Engineering Management and Systems Engineering. His research focuses on understanding how consumer preferences, market dynamics, and policy affect the emergence and adoption of low-carbon technologies, such as electric vehicles and renewable energy technologies. He also studies the critical relationship between the US and China in developing and mass producing these technologies. He has expertise in discrete choice modeling, conjoint analysis, survey design, exploratory data analysis, interview-based research methods, the R programming language, China, and the global electric vehicle industry. He speaks fluent Mandarin Chinese and has conducted extensive fieldwork in China. John holds a Ph.D.¬†and M.S. in Engineering and Public Policy from Carnegie Mellon University and a B.S. in Engineering Science and Mechanics (ESM) from Virginia Tech.\n\n\nBrief Summary on My Research\nMy research focuses on understanding the factors influencing the development and adoption of emerging low-carbon technologies, particularly electric vehicles and solar PV panels.\nInternationally, I have highlighted China‚Äôs crucial role as the leading global supplier of these technologies, as detailed in our 2019 publication in Science. In a subsequent paper published in 2022 in Nature, we used two-factor engineering learning curve models to quantify billions of dollars in cost savings from rapid cost declines associated with high learning rates from a globalized solar PV supply chain, which is the reason solar is now the cheapest source of electricity in most parts of the world. This issue is central to informing ongoing international trade disputes and addressing climate change.\nI have also extensively studied the EV industry, both in China and the U.S. In a paper published in Research Policy, I analyzed how China‚Äôs national and local institutions have interacted with industrial policy to foster a highly competitive environment for EV innovation, leading to the success of indigenous companies like BYD and Geely. In the U.S., my students and I leveraged tens of millions of online vehicle listings scraped from the web to quantify significant EV market trends, such as how EVs are being used and how they are depreciating. I have also studied factors that affect people‚Äôs willingness to buy an EV. In a paper published in Environmental Research Letters, we found that direct experiences with EVs positively impact purchase intentions. In a subsequent paper, we found that U.S. vehicle buyers overwhelmingly prefer immediate rebates at the point of sale, with this preference being particularly strong among lower-income households and used vehicle buyers. Our study was referenced by the White House and the U.S. Department of Treasury as justification to support restructuring EV incentives to be applied at the point of sale, which was implemented in the 2022 Inflation Reduction Act.\nYou can see more about my research on my Research Page.\n\n\nOpen Source Software & \n\n\n\n\nHex stickers for R packages and courses I‚Äôve developed\n\n\n\nI use and contribute to  in most of my research and teaching. One specific category of research is choice modeling. I use choice-based conjoint surveys to measure people‚Äôs preferences for a variety of technologies and policies. I have developed several packages for implementing conjoint in , including {logitr} for estimating multinomial and mixed logit models with preference space and ‚Äúwillingness-to-pay‚Äù space utility parameterizations, and {cbcTools} for designing and conducting power analyses for choice-based conjoint surveys. I also developed the {surveydown} package along with Pingfan Hu and Bogdan Bunea for making markdown-based surveys with Quarto shiny documents. I also co-authored the {renderthis} package with Garrick Aden-Buie for rendering media (e.g., xaringan slides) into multiple different formats. Finally , I also teach multiple programming and data analytics courses in , and all of my course materials are built using , including course websites and slides.\nYou can see more of my  projects and source code on my GitHub page: https://github.com/jhelvy/\n\n\nChina & ‰∏≠Êñá\n\n\n\n\nJohn standing next to a Beijing roast duck mascot in Beijing in 2014\n\n\n\nI began studying Chinese during my second year as an undergraduate engineering student at Virginia Tech in the fall of 2006. The next spring, I received the Horton Scholarship, which provided a unique opportunity to travel to China and complete an educational project of my own design. I traveled to Dalian in the summer of 2008 to study language and culture at Liaoning Normal University, then I moved to Shanghai in the fall to gain international engineering experience as an intern in General Electric‚Äôs Advanced Wind Turbine Operations division. The project opened my eyes to the many forces that shape the adoption of emerging technologies, in particular the importance of policy and economics. After returning to the U.S., I was awarded a Critical Language Scholarship by the U.S. Department of State to study Chinese in Harbin, China during the summer of 2009, and I have since returned to China numerous times for work or research, including an internship at the Innovation Center for Energy and Transportation (iCET) and as a 2014 East Asia Pacific Summer Institutes (EAPSI) Fellow supported by the U.S. National Science Foundation. Today, I continue to use my language skills and experience in China while conducting interdisciplinary research in China.\n\n\nSwing Dancing\n\n\n\n\nJohn swing dancing in Beijing in 2016\n\n\n\nMany of my closest friends know me first and foremost as a dancer. In the fall of 2006, I attended my first swing dance hosted by the Virginia Tech Swing Club Soley Swing, and swing dancing quickly became a major part of my life. I dance Lindy Hop, Balboa, Blues, and Charleston, and my dancing adventures have brought me to cities all over the world, including New York, Montreal, Boston, Washington D.C., Hong Kong, Beijing, Shanghai, Seoul, Pusan, Osaka, Taipei, and even on the Great Wall of China. Sharing the joy of swing dancing with friends and strangers all over the world is one of my greatest passions. I have competed internationally as a dancer, and my most accomplished achievement is winning 1st place in the Open Strictly Lindy Hop competition with my good friend Annabel Truesdell Quisao at the 2011 International Lindy Hop Championship in Washington, D.C.\n\n\nMusic\n\n\n\n\nJohn with his partner and violin after a concert at CMU in 2016\n\n\n\nMusic was my earliest passion. I grew up playing piano, violin, and mandolin, and I have had the privilege of studying and performing with some incredible musicians. In high school I had the honor of studying violins with the legendary Dora Marshall Mullins of Virginia Beach, VA, and I have played in multiple ensembles, including the Virginia Beach Symphony Orchestra (now ‚ÄúSymphonicity‚Äù), the New River Valley Symphony at Virginia Tech, the National Taiwan Normal University Symphony, and the All University Orchestra at Carnegie Mellon University. I am also a self-taught mandolinist and guitarist and enjoy playing jazz and bluegrass. I have fortunately had many opportunities to play with some wonderful jazz friends, including the Muddy Basin Ramblers (a New Orleans-style jazz band in Taipei) and the Hot Club of Beijing (a gypsy swing band based in China‚Äôs capital).\nThanks for visiting my site, and I am grateful for any feedback you may have!\nCheers,\nJohn (Á´†‰πêÊ±â)\n\n\n\n\n Back to top"
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "Source code to generate CV available on GitHub \n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Miscellaneous Projects",
    "section": "",
    "text": "logitr\n\nR package for fast estimation of multinomial and mixed logit models with preference space and willingness to pay space utility parameterizations.\n\n\n\n\n\n\n\n\ncbcTools\n\nR package with tools for designing choice based conjoint (cbc) survey experiments and conducting power analyses.\n\n\n\n\n\n\n\n\nsurveydown\n\nR package for generating markdown-based surveys using Quarto shiny documents.\n\n\n\n\n\n\n\n\nWireless Corne\n\nBuild log and gallery of how I built my wireless Corne keyboard.\n\n\n\n\n\n\n\n\nThe Distillery\n\nDistill website showcasing other distill websites and blogs.\n\n\n\n\n\n\n\n\noica\n\nR data package with tidy formatted data on vehicle production and sales from the International Organization of Motor Vehicle Manufacturers.\n\n\n\n\n\n\n\n\nrenderthis\n\nR package for rendering slides and other media into different formats, including html, pdf, png, gif, pptx, and mp4.\n\n\n\n\n\n\n\n\ncharts\n\nBunch of reproducible charts. All data and source code are available at https://github.com/jhelvy/charts\n\n\n\n\n\n\n\n\nGW Coders\n\nStudy group that brings together students and faculty to apply computational and data analytics skills in research.\n\n\n\n\n\n\n\n\nsplitKbCompare\n\nInteractive R Shiny app for comparing layouts of different split mechanical keyboards. Built for the ergonomic keyboard community r/ErgoMechKeyboards.\n\n\n\n\n\n\n\n\nŒªŒ≠ŒæŒπœÇ (lexis)\n\nTheme for xaringan slides with a light gray background, \"Fira Sans Condensed\" for headers, ‚ÄúRoboto‚Äù for body text.\n\n\n\n\n\n\n\n\nProgramming for Analytics in R\n\nOpen source text book on the fundamentals of programming and working with data in R.\n\n\n\n\n\n\n\n\nformr4conjoint\n\nTemplate for how to create a choice-based conjoint survey using the formr survey platform.\n\n\n\n\n\n\n\n\nIris Rev 2\n\nBuild log and gallery of how I built my Iris Rev 2 keyboard.\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "talks/2021-12-01-isa-battery-webinar/index.html",
    "href": "talks/2021-12-01-isa-battery-webinar/index.html",
    "title": "ISA Industrial Policy Webinar Series: Taking Charge",
    "section": "",
    "text": "On December 1, 2021, I had the honor of moderating the Industry Studies Association (ISA) webinar on the future of batteries for electric vehicles, as part of its ongoing webinar series on industrial policy. You can watch the recording below.\nAbout the webinar:\nThe auto industry is on the cusp of its greatest transformation in more than a century, shifting from internal combustion engines to electric motors powered by lithium-ion batteries. China, which already plays an important role in global auto supply chains, has been the first mover in this transformation, sparking concerns in the United States and elsewhere. This session will explore the United States‚Äô proposed response to this challenge and its profound links to both long-run economic prosperity and the future of the planet.\nModerator: John Paul Helveston, Assistant Professor, Engineering Management & Systems Engineering, George Washington University\nAdministration Presenter: Susan Helper, Senior Economist, White House Council of Economic Advisers\nDiscussants:\n\nGeorge W. Crabtree, Director, Joint Center for Energy Storage Research, Argonne National Laboratory\nKristin Dziczek, Senior Vice President ‚Äì Research, Center for Automotive Research\nJohn Paul MacDuffie, President, Industry Studies Association, and Professor of Management, University of Pennsylvania\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "blog/2022-06-28-introducing-renderthis/index.html",
    "href": "blog/2022-06-28-introducing-renderthis/index.html",
    "title": "Introducing the {renderthis} package",
    "section": "",
    "text": "This post introduces the {renderthis}  package (originally named {xaringanBuilder}). The package contains functions for rendering xaringan slides to different formats. Rather than use this post to demo all the package features, I decided to write a brief overview of it‚Äôs primary functionality and then focus the rest of this post on the package‚Äôs development history. The image above shows the different versions of the package hex sticker, the first one being in the running for the ugliest hex sticker of all time.\n\nWhat can it do?\nThe {renderthis} package contains functions for rendering xaringan slides (Quarto support coming!) to different formats, including html, pdf, png, gif, pptx, and mp4, as well as a ‚Äòsocial‚Äô output, a png of the first slide re-sized for sharing on social media.\nThe package follows the following render hierarchy:\nRmd\n |\n |--&gt; social (png)\n |\n |--&gt; html\n       |\n       |--&gt; pdf\n             |\n             |--&gt; png\n                   |\n                   |--&gt; gif\n                   |\n                   |--&gt; mp4\n                   |\n                   |--&gt; pptx\nAll of the package functions follow a common pattern:\n\nAll functions start with to_*() to render slides to a desired format (e.g., to_pdf()).\nAll functions have a required from argument which should be set to the full or local path to the input file.\nAll functions have an optional to argument. If provided, it can be a full or local path to the output file, and it must end in an appropriate extension (e.g.¬†slides.gif for to_gif()). If it is not provided, the output file name will be determined based on the from argument.\n\nWhile it is designed for rendering {xaringan} slides, other html slides are also supported. For example, if you have a Quarto presentation rendered as an html file, you can use any of the to_*() functions to render those slides to a pdf, png, gif, pptx, or mp4 file.\nThat‚Äôs the gist of what the package does, and the package documentation has many more details about the package features. Now, follow me back to 2020 where this journey began.\n\n\nIn the beginning, there was pagedown::chrome_print()\nThe {renderthis} package began in the fall of 2020 as a solution to a simple problem: converting {xaringan} slides to a pdf. I love {xaringan} slides, but the html format is clunky for sharing, especially as an email attachment, so I wanted a way to convert them to a pdf. Before making the package, my solution was to simply use pagedown::chrome_print() to ‚Äúprint‚Äù my rendered html file of {xaringan} slides to a pdf. For the most part, it worked just fine, and it still does! If all you need is a quick pdf of some simple slides, then pagedown::chrome_print() is probably sufficient.\nBut being the lazy programmer I am, I wanted a single function that rendered the html and pdf files from the Rmd source file. So I wrote a quick function I called build_pdf() that was essentially a wrapper around pagedown::chrome_print(). It checked if the input file was an Rmd file, and if so it first rendered the html and then rendered the pdf. It was a pretty simple solution, and I found it easier to remember the function build_pdf() over chrome_print(). With that function written, I decided to name the package {xaringanBuilder} as an homage to Garrick Aden-Buie‚Äôs incredible {xaringanExtra} package.\n\n\nBuild all the things!\n\n\n\n\n\n\nImage source\n\nWith build_pdf() working, I realized that I could use the rendered pdf to convert my slides into other format types without too much more effort. For example, I wrote a build_thumbnail() function (a wrapper around pagedown::chrome_print(format = \"png\")) to convert the title slide of the pdf deck to a png image. This was handy for making thumbnail images for youtube recordings of my class lectures (hence the name build_thumbnail()).\nBut then I realized I could also render all the slides to png images, and with the help of the {magick} package I could use magick::image_join() and magick::image_animate() to compile those pngs into an animated gif of my whole presentation! This provided a handy way to share my slides, like posting them on Twitter.\n\n\nEnter stage left: gadenbuie\nJust a couple months after starting the package, Garrick wrote an awesome blog post on using the {chromote} package to print slides to a pdf in a way to allows incremental animations to be rendered on separate slides as well as separate slides for each panel in a panelset (the pagedown::chrome_print() solution would only render these as a single slide).\n\n\n\nJust posted: Do you have complicated {xaringan} #rstats slides or use panelsets from {xaringanExtra}? Do you need a PDF version of your slides? I've got a little function for you:https://t.co/UXwW2KtvOw\n\n‚Äî Garrick Aden-Buie (@grrrck) January 25, 2021\n\n\n\nAfter connecting on Twitter, I quickly added Garrick as a contributor and we started working on integrating this function into {xaringanBuilder}.\n\nFolks, at this point I need to tell you about a little-known package development secret: If you want your package to be awesome, ask Garrick to join the project.\n\nI cannot emphasize enough just how much better this package became once Garrick started working on it. Garrick has an excellent eye for making packages user-friendly, and he is an absolute Git / GitHub wizard (read on to the bit about changing the package name to see some of this). Here are a few things he quickly added:\n\nHe made lots of quick changes to make all the functions more robust for different use cases.\nHe integrated the {cli} package to make beautiful status messages so the user can see the progress of the output being built.\nHe introduced the {fs} package to simplify how file paths were being handled (which were getting rather tricky with all the different output types involved).\nHe introduced multiple tests and integrated it with Github Actions so that the tests would run and the {pkgdown} site would render on every commit.\n\nWithout a doubt, Garrick‚Äôs additions transformed the package from a handful of convenient functions to a feature-packed, user-friendly tool for rendering slides.\n\n\nOutside influences\nAt this stage, the package had already become quite a useful tool, and many users were filing issues catching little bugs here and there. The package had also grabbed the attention of several people who helped add more features. Bryan Shalloway added the initial support for rendering slides into a powerpoint deck, and Gina Reynolds‚Äôs {flipbookr} package provided some inspiration for adding support for rendering slides to mp4 videos.\nMany other people added in small ways to the package over the following year. Some found bugs and posted issues, others sent pull requests with fixes. Over the summer of 2021 Garrick did an overhaul of how paths were handled in the package, after which the package remained relatively stable for about a year.\n\n\nChanging the name\nIn the spring of 2022, Quarto started to catch fire. Alison Hill‚Äôs ‚ÄúWe don‚Äôt talk about Quarto‚Äù post (among others) inspired me to check out Quarto presentations, which are quite similar to {xaringan} slides.\n\n\n\nWoah, okay #rstats world I may have to just make the .Rmd -&gt; .qmd switch‚Ä¶@quarto_dev is looking amazing. Exhibit A: Figures and tables in the margins! ü§Ø pic.twitter.com/BDEHvxhd6e\n\n‚Äî John Paul Helveston (@JohnHelveston) March 30, 2022\n\n\n\nThe revelation of Quarto presentations made me realize that the {xaringanBuilder} package could actually be used to render a wider variety of inputs other than just {xaringan} slides. In fact, I myself had already used it for other purposes, such as converting the first page of a pdf paper I wrote into a png image This prompted me to consider changing the package name.\nAfter a little back and forth, Garrick and I decided to call it {renderthis} as an homage to the phenomenal {usethis} package. We also wanted to maintain the strategy of having every function begin with the same word (previously build_*()), and we chose to_*() so that the package and function names would work together to form a kind of sentence, like renderthis::to_pdf().\nOnce we came up with a new name, implementing that name was daunting. I really had no idea where to begin, so I just created an entirely new repo under jhelvy/renderthis and started editing the source code accordingly. This proved to be a useful exercise as it allowed us to see how the new package would look and feel without touching the older one. In retrospect, I probably should have just opened up a new branch under the {xaringanBuilder} repo to do this, but the nice thing about working from a totally new repo is that I could also preview the documentation with full links, etc. Once we were happy with the way it looked, we actually went back to the {xaringanBuilder} repo and changed the name there.\nThis is where things got a little tricky. Since I already had a repo under jhelvy/renderthis, I couldn‚Äôt just change the name of jhelvy/xaringanBuilder to it. So I first changed jhelvy/renderthis to jhelvy/renderthistemp, then changed jhelvy/xaringanBuilder to jhelvy/renderthis. GitHub automagically handles redirects so that any user that navigates to https://github.com/jhelvy/xaringanBuilder gets redirected to https://github.com/jhelvy/renderthis.\nOnce again, shout out to Garrick for using some serious GitHub wizardry here. He was able to salvage most of my edits in the jhelvy/renderthistemp repo and merge them into the new jhelvy/renderthis repo (I still have no idea how he managed this). Garrick guided the way through the messy process of changing a package name without losing any of the commit history on GitHub. With a few more small changes to clean up the package documentation and pkgdown site, {renderthis} was ready to be introduced to the world.\n\n\nGoing to CRAN!\nThe {chromote} and {webshot2} packages (which {renderthis} depends on) were both conveniently released on CRAN in May of 2022. With these additions, we now had every dependency on CRAN, so that gave us the motivation to get {renderthis} on CRAN as well.\nThis too was a bit tricky given what this package does. In particular, the function examples we wrote had code that if executed would error, e.g., renderthis::to_pdf(\"slides.Rmd\"). Even though we wrapped these in \\dontrun{}, CRAN still ran these examples on the first submission. After a little more back and forth on how to address this, Garrick came up with a handy solution by making a new with_example() function which allows the examples to be run in a temp directory, which we use in each function example.\nWith that fix, version 0.1.0 of {renderthis} was published on CRAN üéâ!\n\n\nWhat‚Äôs next?\nOne of the complaints I had early on with {xaringan} is that there was no way to print out ‚Äúhandouts‚Äù. I can‚Äôt stand Powerpoint, but the ability to print out a pdf with small thumbnails of each slide with space for notes was a convenient feature I used often, and to date nothing like it exists for the {xaringan} ecosystem.\nFor this reason, we are working on a to_handout() function that will be introduced in the next version of {renderthis}. Below is an example of a set of demo slides.\n\n\n\nWe‚Äôre also planning on supporting rendering Quarto slides, which again was one of the motivations to change the package name to a more general one.\nIf you made it to the end of this post, thanks for reading! And if you give {renderthis} a shot and have feedback or thoughts on it, please let us know by filing an issue.\nAnd if you love the package and just want to let us know about that, drop us a note on the ‚Äúpraise‚Äù issue üòä.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "research/2018-transportation-research-part-b-methodological/index.html",
    "href": "research/2018-transportation-research-part-b-methodological/index.html",
    "title": "Pooling Stated and Revealed Preference Data in the Presence of Endogeneity",
    "section": "",
    "text": "Pooling Stated and Revealed Preference Data in the Presence of Endogeneity\n\n\n\n\nHaiku Summary\n\n\n\n\n\n\n Helveston, J.P., Feit, E.M., & Michalek, J.J. (2018) ‚ÄúPooling Stated and Revealed Preference Data in the Presence of Endogeneity‚Äù Transportation Research Part B: Methodological. 109, pg. 70-89. DOI: 10.1016/j.trb.2018.01.010\n\n\n\n\n\n\n View PDF RG Scholar\n\n\n  \n    \n      RP data with\n      ‚Ä¢\n      endogeneity may\n      ‚Ä¢\n      make things worse when pooled\n    \n  \n\n\n\n  Key Figure  \n\n\n\n\n\n\n\n\n\nAbstract:\nPooled discrete choice models combine revealed preference (RP) data and stated preference (SP) data to exploit advantages of each. SP data is often treated with suspicion because consumers may respond differently in a hypothetical survey context than they do in the marketplace. However, models built on RP data can suffer from endogeneity bias when attributes that drive consumer choices are unobserved by the modeler and correlated with observed variables. Using a synthetic data experiment, we test the performance of pooled RP‚ÄìSP models in recovering the preference parameters that generated the market data under conditions that choice modelers are likely to face, including (1) when there is potential for endogeneity problems in the RP data, such as omitted variable bias, and (2) when consumer willingness to pay for attributes may differ from the survey context to the market context. We identify situations where pooling RP and SP data does and does not mitigate each data source‚Äôs respective weaknesses. We also show that the likelihood ratio test, which has been widely used to determine whether pooling is statistically justifiable, (1) can fail to identify the case where SP context preference differences and RP endogeneity bias shift the parameter estimates of both models in the same direction and magnitude and (2) is unreliable when the product attributes are fixed within a small number of choice sets, which is typical of automotive RP data. Our findings offer new insights into when pooling data sources may or may not be advisable for accurately estimating market preference parameters, including consideration of the conditions and context under which the data were generated as well as the relative balance of information between data sources.\nBibtex:\n\n@article{helveston2018pooling,\n  title={Pooling stated and revealed preference data in the presence of RP endogeneity},\n  author={Helveston, John Paul and Feit, Elea McDonnell and Michalek, Jeremy J},\n  journal={Transportation Research Part B: Methodological},\n  volume={109},\n  pages={70--89},\n  year={2018},\n  publisher={Elsevier}\n}\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "research/2019-research-policy/index.html",
    "href": "research/2019-research-policy/index.html",
    "title": "Institutional Complementarities: The Origins of Experimentation in China‚Äôs Plug-in Electric Vehicle Industry",
    "section": "",
    "text": "Institutional Complementarities: The Origins of Experimentation in China‚Äôs Plug-in Electric Vehicle Industry\n\n\n\n\nHaiku Summary\n\n\n\n\n\n\n Helveston, J.P., Wang, Y., Karplus, V.J., & Fuchs, E.R.H. (2019) ‚ÄúInstitutional Complementarities: The Origins of Experimentation in China‚Äôs Plug-in Electric Vehicle Industry‚Äù Research Policy. 48(1), pg. 206-222. DOI: 10.1016/j.respol.2018.08.006\n\n\n\n\n\n\n View PDF Scholar\n\n\n  \n    \n      Institutions can\n      ‚Ä¢\n      dramatically affect how\n      ‚Ä¢\n      industries emerge\n    \n  \n\n\n\n  Key Figure  \n\n\n\n\n\n\n\n\n\nAbstract:\nA vast literature on technology transitions within industries suggests that early phases of new technologies are marked by periods of intense experimentation, but we know little about the conditions under which these periods emerge. We apply inductive, grounded theory-building techniques to examine what prompts firms to experiment across one emerging technology platform‚Äîplug-in electric vehicles (PEVs)‚Äîin China. Triangulating annual vehicle make and model sales data from 2003 to 2016 (plus monthly data from 2010 to 2016); 112 English and Mandarin archival documents from industry, academic, and news outlets; and 51 semi-structured interviews with industry, government, and academic stakeholders, we develop four in-depth case studies. We find that in contrast to the innovation trajectories of multinational and Chinese arms of joint venture (JV) firms, independent domestic Chinese firms (those with no history of international JV partnerships) are undertaking significant experimentation across multiple levels‚Äîinfrastructure, core system, subsystem, and component‚Äîof the emerging PEV technology platform. We propose the concept of ‚Äúinstitutional complementarities‚Äù to describe how interactions among institutions‚Äîhere the national JV regulation and local market support and subsidies‚Äîmay have turned regional markets into protected laboratories, extending the incubation periods for independent domestic firm experimentation. While this diverse experimentation may be an important antecedent of technology transition, consolidation induced by national policy standardization or competitive pressure may be required for PEV innovations to scale beyond their early, protected regional markets.\nBibtex:\n\n@article{helveston2019institutional,\n  title={Institutional complementarities: The origins of experimentation in China‚Äôs plug-in electric vehicle industry},\n  author={Helveston, John P and Wang, Yanmin and Karplus, Valerie J and Fuchs, Erica RH},\n  journal={Research Policy},\n  volume={48},\n  number={1},\n  pages={206--222},\n  year={2019},\n  publisher={Elsevier}\n}\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "research/2020-environmental-research-letters/index.html",
    "href": "research/2020-environmental-research-letters/index.html",
    "title": "Electric vehicle adoption: can short experiences lead to big change?",
    "section": "",
    "text": "Electric vehicle adoption: can short experiences lead to big change?\n\n\n\n\nHaiku Summary\n\n\n\n\n\n\n Roberson, Laura A. & Helveston, John P. (2020) ‚ÄúElectric vehicle adoption: can short experiences lead to big change?‚Äù Environmental Research Letters. 15(0940c3). DOI: 10.1088/1748-9326/aba715\n\n\n\n\n\n\n View PDF Code & Data Scholar\n\n\n  \n    \n      A five minute ride\n      ‚Ä¢\n      in an EV can increase\n      ‚Ä¢\n      the chance you'll buy one\n    \n  \n\n\n\n  Key Figure  \n\n\n\n\n\n\n\n\n\nAbstract:\nPlug-in electric vehicles (PEVs) offer a promising pathway to decarbonizing the personal transportation sector, but PEV sales remains low. Prior research has found that direct experience with PEVs increases consumers‚Äô stated purchase consideration, but these studies have used relatively long exposure times (days to months) with a PEV. To assess the effect of shorter exposure times (e.g.¬†minutes) on stated purchase consideration, we conducted an experiment at the 2019 Washington D.C. Auto Show. Participants (n = 6518) were asked to rate their level of consideration to adopt a PEV before and after riding in one of four different PEVs for just 3‚Äì5 min. We find that the experience of riding in a PEV on average had a significant, positive effect on participants‚Äô consideration ratings. We also find that the vast majority of respondents were unable to correctly answer basic knowledge questions about refueling a PEV and federal subsidies available for purchasing a PEV. These results suggest that while consumer knowledge about PEVs remains low, short rides or drives in a PEV could be an effective, more scalable strategy for increasing PEV consideration across larger populations.\nBibtex:\n\n@article{roberson2020electric,\n  title={Electric vehicle adoption: can short experiences lead to big change?},\n  author={Roberson, Laura A and Helveston, John P},\n  journal={Environmental Research Letters},\n  volume={15},\n  number={9},\n  pages={0940c3},\n  year={2020},\n  publisher={IOP Publishing}\n}\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "research/2021-systems-engineering/index.html",
    "href": "research/2021-systems-engineering/index.html",
    "title": "Evolvability Analysis Framework: Adding Transition Path and Stakeholder Diversity to Infrastructure Investment Decisions",
    "section": "",
    "text": "Evolvability Analysis Framework: Adding Transition Path and Stakeholder Diversity to Infrastructure Investment Decisions\n\n\n\n\nHaiku Summary\n\n\n\n\n\n\n Szajnfarber, Z., Groover, J.A., Wei, Z., Broniatowski, D.A., Chernicoff, W., & Helveston, J.P. (2021) ‚ÄúEvolvability Analysis Framework: Adding Transition Path and Stakeholder Diversity to Infrastructure Investment Decisions‚Äù Systems Engineering. 25(1):35-50. DOI: 10.1002/sys.21600\n\n\n\n\n\n\n View PDF Scholar\n\n\n  \n    \n      Transition pathways\n      ‚Ä¢\n      are important for upgrades\n      ‚Ä¢\n      to infrastructure\n    \n  \n\n\n\n  Key Figure  \n\n\n\n\n\n\n\n\n\nAbstract:\nThis paper presents the Evolvability Analysis Framework (EAF), a new perspective on evaluating complex infrastructure systems. EAF enables decision makers to explore alternative transition paths, thus providing several multi-step options to achieve a desired end state. These multi-step transition paths can be particularly valuable when they mitigate the impact of system degradation during the deployment of new capabilities. Additionally, EAF is formulated in a manner that empowers decision makers to apply decision variables, such as a cost cap or an equity metric, which are increasingly relevant to modern decision-making. To demonstrate the method and its value, we apply the EAF to a case study inspired by Los Angeles‚Äô Vision 2028. We identify 26 transition paths across different performance dimensions. We model the cost and performance of each transition pathway and compare them using multiple measures, including traditional benefit-cost metrics and differential impacts on different stakeholder groups. Our results show that multi-step paths outperform single-step transitions to an end state (‚Äúbig bang‚Äù approaches) in most scenarios. Multi-step paths also provide valuable alternatives when particular stakeholders value non-cost metrics.\nBibtex:\n\n@article{szajnfarber2021evolvability,\n  title={Evolvability analysis framework: Adding transition path and stakeholder diversity to infrastructure planning},\n  author={Szajnfarber, Zoe and Groover, Joshua A and Wei, Zhenglin and Broniatowski, David A and Chernicoff, William and Helveston, John P},\n  journal={Systems Engineering},\n  year={2021},\n  publisher={Wiley Online Library}\n}\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "research/2022-nature/index.html",
    "href": "research/2022-nature/index.html",
    "title": "Quantifying the cost savings of global solar photovoltaic supply chains",
    "section": "",
    "text": "Quantifying the cost savings of global solar photovoltaic supply chains\n\n\n\n\nHaiku Summary\n\n\n\n\n\n\n Helveston, J.P., He, G., & Davidson, M.R. (2022) ‚ÄúQuantifying the cost savings of global solar photovoltaic supply chains‚Äù Nature. 612 (7938), pg. 83-87. DOI: 10.1038/s41586-022-05316-6\n\n\n\n\n\n\n View PDF Code & Data ‰∏≠Êñá RG Scholar\n\n\n  \n    \n      Global supply chains\n      ‚Ä¢\n      are important for reaching\n      ‚Ä¢\n      lower green tech costs\n    \n  \n\n\n\n  Key Figure  \n\n\n\n\n\n\n\n\n\nAbstract:\nAchieving carbon neutrality requires deploying renewable energy at unprecedented speed and scale, yet countries sometimes implement policies that increase costs by restricting the free flow of capital, talent and innovation in favour of localizing benefits such as economic growth, employment and trade surpluses. Here we assess the cost savings from a globalized solar photovoltaic (PV) module supply chain. We develop a two-factor learning model using historical capacity, component and input material price data of solar PV deployment in the United States, Germany and China. We estimate that the globalized PV module market has saved PV installers US$24 (19‚Äì31) billion in the United States, US$7 (5‚Äì9) billion in Germany and US$36 (26‚Äì45) billion in China from 2008 to 2020 compared with a counterfactual scenario in which domestic manufacturers supply an increasing proportion of installed capacities over a ten-year period. Projecting the same scenario forwards from 2020 results in estimated solar module prices that are approximately 20‚Äì25 per cent higher in 2030 compared with a future with globalized supply chains. International climate policy benefits from a globalized low-carbon value chain, and these results point to the need for complementary policies to mitigate welfare distribution effects and potential impacts on technological crowding out.\nBibtex:\n\n@article{helveston2022nature,\n    author={Helveston, John Paul and He, Gang and Davidson, Michael R.},\n    title={Quantifying the cost savings of global solar photovoltaic supply chains},\n    journal={Nature},\n    pages={1--5},\n    year={2022},\n    publisher={Nature Publishing Group UK London},\n    doi = {10.1038/s41586-022-05316-6}\n}\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "research/2023-journal-of-statistical-software/index.html",
    "href": "research/2023-journal-of-statistical-software/index.html",
    "title": "logitr: Fast Estimation of Multinomial and Mixed Logit Models with Preference Space and Willingness to Pay Space Utility Parameterizations",
    "section": "",
    "text": "logitr: Fast Estimation of Multinomial and Mixed Logit Models with Preference Space and Willingness to Pay Space Utility Parameterizations\n\n\n\n\nHaiku Summary\n\n\n\n\n\n\n Helveston, John P. (2023) ‚Äúlogitr: Fast Estimation of Multinomial and Mixed Logit Models with Preference Space and Willingness to Pay Space Utility Parameterizations‚Äù Journal of Statistical Software. 105(10), 1-37. DOI: 10.18637/jss.v105.i10\n\n\n\n\n\n\n View PDF Code & Data RG Scholar\n\n\n  \n    \n      Fast estimation\n      ‚Ä¢\n      of mixed logit models and\n      ‚Ä¢\n      WTP in R\n    \n  \n\n\n\n  Key Figure  \n\n\n\n\n\n\n\n\n\nAbstract:\nThis paper introduces the logitr R package for fast maximum likelihood estimation of multinomial logit and mixed logit models with unobserved heterogeneity across individuals, which is modeled by allowing parameters to vary randomly over individuals according to a chosen distribution. The package is faster than other similar packages such as mlogit, gmnl, mixl, and apollo, and it supports utility models specified with ‚Äúpreference space‚Äù or ‚Äúwillingness to pay (WTP) space‚Äù parameterizations, allowing for the direct estimation of marginal WTP. The typical procedure of computing WTP post-estimation using a preference space model can lead to unreasonable distributions of WTP across the population in mixed logit models. The paper provides a discussion of some of the implications of each utility parameterization for WTP estimates. It also highlights some of the design features that enable logitr‚Äôs performant estimation speed and includes a benchmarking exercise with similar packages. Finally, the paper highlights additional features that are designed specifically for WTP space models, including a consistent user interface for specifying models in either space and a parallelized multi-start optimization loop, which is particularly useful for searching the solution space for different local minima when estimating models with non-convex log-likelihood functions.\nBibtex:\n\n@article{helveston2022jss,\n    author = {John Paul Helveston},\n    title = {logitr: Fast Estimation of Multinomial and Mixed Logit Models with Preference Space and Willingness to Pay Space Utility Parameterizations},\n    journal={Journal of Statistical Software},\n    url = {https://jhelvy.github.io/logitr/},\n    year = {2023},\n    volume = {105},\n    number = {10},\n    pages = {1--37},\n    doi = {10.18637/jss.v105.i10}\n}\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "research/2023-transportation-research-record/index.html",
    "href": "research/2023-transportation-research-record/index.html",
    "title": "Undercutting Transit? Exploring potential competition between autonomous vehicles and public transportation in the U.S.",
    "section": "",
    "text": "Undercutting Transit? Exploring potential competition between autonomous vehicles and public transportation in the U.S.\n\n\n\n\nHaiku Summary\n\n\n\n\n\n\n Kaplan, Leah & Helveston, John P. (2023) ‚ÄúUndercutting Transit? Exploring potential competition between autonomous vehicles and public transportation in the U.S.‚Äù Transportation Research Record.  DOI: 10.1177/03611981231208976\n\n\n\n\n\n\n View PDF Code & Data RG Scholar\n\n\n  \n    \n      Robo-taxis won't\n      ‚Ä¢\n      (at the moment) take over\n      ‚Ä¢\n      transit ridership\n    \n  \n\n\n\n  Key Figure  \n\n\n\n\n\n\n\n\n\nAbstract:\nAutomated vehicles (AVs) have the potential to dramatically disrupt current transportation patterns and practices. One particular area of concern is AVs‚Äô impacts on public transit systems. If vehicle automation enables significant price decreases or performance improvements for ride-hailing services, some fear that it could undercut public transit, which could have significant implications for the environment and transportation equity. The extent to which individuals adopt automated transportation modes will drive many system-level outcomes, and research on public preferences for AVs is immature and inconclusive. In this study, we used responses from an online choice-based conjoint survey fielded in the Washington, D.C. metropolitan region (N = 1,694) in October 2021 to estimate discrete choice models of public preferences for different automated (ride-hailing, shared ride-hailing, bus) and nonautomated (ride-hailing, shared ride-hailing, bus, rail) modes. We used the estimated models to simulate future marketplace competition across a range of trip scenarios. Respondents on average were only willing to pay a premium for automated modes when a vehicle attendant was also present, limiting the potential cost-savings that AV operators might achieve by removing the driver. Scenario analysis additionally revealed that for trips where good transit options were available, transit remained competitive with automated ride-hailing modes. These results suggest that fears of a mass transition away from transit to AVs may be limited by people‚Äôs willingness to use AVs, at least in the short term. Future AV operators should also recognize the presence of an AV attendant as a critical feature for early AV adoption.\nBibtex:\n\n@article{kaplan2023,\nauthor = {Leah Kaplan and John Paul Helveston},\ntitle ={Undercutting Transit? Exploring Potential Competition Between Automated Vehicles and Public Transportation in the United States},\njournal = {Transportation Research Record},\nvolume = {0},\nnumber = {0},\nyear = {2023},\ndoi = {10.1177/03611981231208976},\nURL = {https://doi.org/10.1177/03611981231208976},\n}\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "talks/2021-07-06-useR-healthy-hands/index.html",
    "href": "talks/2021-07-06-useR-healthy-hands/index.html",
    "title": "Healthier ‚ù§Ô∏è & Happier üòÑ Hands üôå",
    "section": "",
    "text": "I prepared an ‚ÄúElevator Pitch‚Äù (aka lightning talk) for the 2021 useR! Conference where I discussed a quick overview of software and hardware solutions for more ergonomic typing. The recording and slides are below.\nSee also my related blog post for more details on the topics covered in the talk.\n\nTalk\n\n\n\n\nSlides\nMy slides were built using the {xaringan} R package. You can see the source code for the slides here.\n\n\n Full screen slides\n\n\n Slides as PDF\n\n\nKeyboard Shortcuts for Slides:\n\nUse ‚Üê and ‚Üí to navigate through the slides.\nUse f to toggle full screen.\nUse o to view an overview of all slides.\nUse h to see a list of other shortcuts.\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "charts.html",
    "href": "charts.html",
    "title": "Charts",
    "section": "",
    "text": "A bunch of reproducible charts. All data and source code are available on this repo.\nAll charts are licensed under a Creative Commons Attribution-ShareAlike 4.0 International License\n\n\n\n\nchallengerOrings\nDescription: Reproduction of Tufte‚Äôs famous scatterplot of rocket o-ring damage vs.¬†launch temperature for test launches prior to Jan.¬†28, 1986 Challenger launch. Original figure in Tufte E.R. 1997. Visual Explanations. Graphics Press. Cheshire, Connecticut, U.S.A.\nData: Presidential Commission on the Space Shuttle Challenger Accident, Vol. 1, 1986: 129-131.\n\n\n\n\n\nScatterplot of rocket o-ring damage vs.¬†launch temperature.\n\n\n\n\n\n\nclimateChangeBarcode\nDescription: ‚ÄúBarcode‚Äù plots showing the long term rise in global and US temperatures. Each vertical stripe represents the average temperature of a single year, ordered from the earliest available data to the present. Original figures by Ed Hawkins.\nData: 1) NASA (2018) ‚ÄúGoddard Institute for Space Studies (GISS)‚Äù; 2) NOAA National Centers for Environmental information.\n\n\n\n\n\nGlobal temperatures, 1880 - 2018, NASA.\n\n\n\n\n\n\nelectionMargins\nDescription: Bar plots of the popular vote margin by elected U.S. Presidents from 1824 to present.\nData: Encyclopaedia Britannica, United States Presidential Election Results.\n\n\n\n\n\nBar plots of the popular vote margin by elected U.S. Presidents.\n\n\n\n\n\n\nelectricityEIA\nDescription: Barplots of energy capacity and generation by country / region using EIA data.\nData: U.S. Energy Information Administration (EIA).\n\n\n\n\n\nInstalled Wind and Nuclear Power Capacity by Country / Region, 2000 - 2016.\n\n\n\n\n\n\nlcetPatenting\nDescription: Patenting in clean energy technologies by country and over time.\nData: 2018 U.S. NSF Science & Engineering Indicators.\n\n\n\n\n\nAnnual USPTO Patents in Clean Energy Technologies, 2006 - 2016.\n\n\n\n\n\n\nnewEnergyInvestment\nDescription: Plots of new clean energy investment by country and type.\nData: Clean energy investment by Bloomberg New Energy Finance.\n\n\n\n\n\nNew Investment in Clean Energy ($USD Billion), 2005 - 2018.\n\n\n\n\n\n\nscienceCommentary2019\nDescription: The chart in our 2019 Science Policy Forum article - investment and patenting in clean energy technologies by country and over time.\nData: Clean energy investment by Bloomberg New Energy Finance; Patenting by 2018 U.S. NSF Science & Engineering Indicators.\n\n\n\n\n\nInvestment and patenting in clean energy technologies by country and over time.\n\n\n\n\n\n\nscotusNominations\nDescription: Time from Nomination to Result of Every US Supreme Court Justice.\nData: Wikipedia The Green Papers.\n\n\n\n\n\nTime from Nomination to Result of Every US Supreme Court Justice.\n\n\n\n\n\n\nsolarPvProduction\nDescription: Bar plot of global annual solar photovoltaic cell production by country.\nData: 1995 to 2013: Earth Policy Institute; 2014 to 2018: J√§ger-Waldau, A. (2019). Snapshot of Photovoltaics‚ÄîFebruary 2019. Energies, 12(5), 769. Data reverse engineered from Figure 1 using WebPlotDigitizer.\n\n\n\n\n\nAnnual Solar Voltaic Cell Production (GW), 2000 - 2018.\n\n\n\n\n\n\nusGHGs\nDescription: Line chart of US greenhouse gas emissions by sector. Data are from the US EPA.\nData: U.S. EPA Greenhouse Gas Inventory Data Explorer\n\n\n\n\n\nUS Greenhouse Gas Emissions by Sector, 1990 - 2021.\n\n\n\n\n\n\nusHighwayFund\nDescription: The chart in my 2017 article: ‚ÄúPerspective: Navigating an Uncertain Future for US Roads,‚Äù Issues in Science and Technology 34, no. 1 (Fall 2017)‚Äù. The chart shows federal highway fund revenues and expenditures in real dollars from 1980 to 2015.\nData: Status of the Highway Trust Fund, Fiscal Years 1957-2015.\n\n\n\n\n\nFederal highway fund revenues and expenditures in real dollars, 1980 - 2015.\n\n\n\n\n\n\nusPevSales\nDescription: The chart in my 2021 article in Issues in Science and Technology titled, ‚ÄúWhy the US Trails the World in Electric Vehicles‚Äù. The chart shows monthly sales of plug-in electric vehicles in the US from 2014 to 2020.\nData: hybridcars.com (‚Äô14-‚Äô17) and insideEVs.com (‚Äô18-‚Äô19).\n\n\n\n\n\nU.S. Monthly Sales of Plug-in Electric Vehicles, 2014 - 2020.\n\n\n\n\n\n\nworldNuclearAssociation\nDescription: Barplots of nuclear energy capacity by country.\nData: Webscraped data from the World Nuclear Association.\n\n\n\n\n\nNew Nuclear Energy Capacity (GW) by Country, 2008 - 2019.\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "talks/2021-01-21-surveys-with-formr/index.html",
    "href": "talks/2021-01-21-surveys-with-formr/index.html",
    "title": "Using formr to create R-powered surveys with individualized feedback",
    "section": "",
    "text": "Watch the talk\nI gave a lightning talk at the 2021 rstudio conference on using {formr} to create R-powered surveys.\n\n\n Watch the lightning talk\n\n\nI also gave an extended version of the talk at the GW Coders Meetup on Feb.¬†19, 2021. You can see that below (the first 5 minutes is the same as my rstudio::conf lightning talk):\n\n\n\n\nSlides\nHere are my slides for my rstudio::conf lightning talk built using the {xaringan} R package. You can also see the source code for the slides here.\n\n\n Full screen slides\n\n\n Slides as PDF\n\n\nKeyboard Shortcuts for Slides:\n\nUse ‚Üê and ‚Üí to navigate through the slides.\nUse f to toggle full screen.\nUse o to view an overview of all slides.\nUse h to see a list of other shortcuts.\n\n\n\n&lt;iframe class=\"golden-ratio-iframe\" src=\"https://jhelvy.github.io/surveys-with-formr/index.html\"&gt;&lt;/iframe&gt;\n\n\n\n\nSurveys with {formr}\nIn my presentation, I showed several examples of how to use the {formr} package to create different types of surveys. The surveys are all generated from Google sheets, which can be found here:\n\nRandom images demonstrates how to randomly display different images.\nConjoint surveys demonstrates how to create a conjoint survey with formr (go to the formr4conjoint repo for a more detailed description)\nTimed quizzes demonstrates how to create a timed quiz with randomly generated questions.\n\nTo use any of these surveys yourself, go to formr.org, create an account. Once you log in, go to the admin page and create a new survey. You can then paste in the link to the Google sheet there. If you want to edit it, just create copy of the Google sheet into your own Google Drive account and use the shared link to that Google sheet.\nOnce you have a survey uploaded, you can make it live by creating a ‚ÄúRun‚Äù and inserting the survey you created by clicking on the  icon as well as a ‚ÄúStop‚Äù point to end the survey by clicking on the  icon. The link to the survey will be https://your_run_name.formr.org.\nYou can control the ‚Äúpublicness‚Äù of the survey by modifying the ‚Äúvolume‚Äù icons:\n\n means only you can access the survey\n means you and people who have an access code can access (no new users can enroll).\n means people who have the link can access.\n means the link is public, everyone can access.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "blog/2023-02-28-parameterized-pdfs-with-quarto/index.html",
    "href": "blog/2023-02-28-parameterized-pdfs-with-quarto/index.html",
    "title": "Render parameterized reports with Quarto",
    "section": "",
    "text": "Quarto is an open-source scientific and technical publishing system built on Pandoc. Many view it as the ‚Äúnext generation‚Äù of RMarkdown, though it is more general in that is supports mutliple languages and is not R-specific.\nOne of the most common use cases for me is creating parameterized reports. A parameterized report is one that uses a .qmd file with parameters that can be passed to it while rendering, enabling the ability to create different versions of the output report based on the parameters.\nAs a professor, one way I use parameterized reports is in providing my student‚Äôs unique feedback for their assignments. Using parameters like student_name, grade, and feedback, I am able to use a single .qmd file and then render a unique report for each student where those parameters are replaced with the appropriate information for each student.\nRMarkdown and Quarto use almost identical interfaces for rendering parameterized reports, so most of this post applies directly to RMarkdown. But since Quarto is more general and newer, I‚Äôm going to focus on Quarto for this post.\nOne more side note‚Äîthese examples only apply when using knitr as the rendering engine (you can also use parameters with Jupyter, which uses a different syntax)."
  },
  {
    "objectID": "blog/2023-02-28-parameterized-pdfs-with-quarto/index.html#adding-parameters-in-.qmd-files",
    "href": "blog/2023-02-28-parameterized-pdfs-with-quarto/index.html#adding-parameters-in-.qmd-files",
    "title": "Render parameterized reports with Quarto",
    "section": "Adding parameters in .qmd files",
    "text": "Adding parameters in .qmd files\nIn the YAML, you can define any parameters you want using params. For example, if I wanted to make a report with the parameter name that you will replace with a person‚Äôs name when rendering, you would add this to the YAML:\n---\nparams:\n  name: \"John\"\n---\nThe value \"John\" is the default value for the parameter, which will be used if no parameter is passed. This parameter can now be used anywhere in the .qmd file using params$name, which will be replaced with whatever the parameter value is. Note that in a code chunk you can just use params$name directly, but if you want to use it in-line (e.g.¬†in a sentence) you have use an in-line R command, like so:\n\n`r params$name`\n\nYou can include as many parameters as you want, just add them to params. For example, here is how you would add a parameter for name and grade:\n---\nparams:\n  name: \"John\"\n  grade: \"100%\"\n---\nOne nice feature about using parameters is that you an preview the output with the default values, that way you can make sure everything looks the way you want before creating different versions of the document.\nI tend to save these files as something like ‚Äútemplate.qmd‚Äù, since it is a template that I will use to render to multiple different versions."
  },
  {
    "objectID": "blog/2023-02-28-parameterized-pdfs-with-quarto/index.html#passing-parameters-while-rendering",
    "href": "blog/2023-02-28-parameterized-pdfs-with-quarto/index.html#passing-parameters-while-rendering",
    "title": "Render parameterized reports with Quarto",
    "section": "Passing parameters while rendering",
    "text": "Passing parameters while rendering\nOnce you have a ‚Äútemplate.qmd‚Äù file ready with parameters in place, you can pass new parameters to it while rendering. If you prefer to work in the terminal, you can pass parameters in the quarto render command, e.g.:\nquarto render template.qmd -P name:'Paul' -P grade:'98%'\nIf you‚Äôre more comfortable working in R than the terminal (like me), you can use the {quarto} R package to render the .qmd file. The main function is quarto::quarto_render(), which takes an input argument for the path to the ‚Äútemplate.qmd‚Äù file. To pass parameters, you use the execute_params argument, which must be a list of parameters. For example, to render the same output as in the terminal example above, you would use:\n\nquarto::quarto_render(\n    input = \"template.qmd\",\n    execute_params = list(\n        name = \"Paul\",\n        grade = \"98%\"\n    )\n)"
  },
  {
    "objectID": "blog/2023-02-28-parameterized-pdfs-with-quarto/index.html#iterative-rendering",
    "href": "blog/2023-02-28-parameterized-pdfs-with-quarto/index.html#iterative-rendering",
    "title": "Render parameterized reports with Quarto",
    "section": "Iterative rendering",
    "text": "Iterative rendering\nI tend to have more than one set of parameters I need to pass to my ‚Äútemplate.qmd‚Äù file (e.g.¬†I need a report for every student in my class). In these cases, I use the quarto::quarto_render() command inside a loop.\nFor example, imagine that I had a ‚Äúgrades.csv‚Äù file with the columns name and grade for each student in my class. I could read in that data file and then iteratively render the ‚Äútemplate.qmd‚Äù file for each student. Here I have to be careful to make sure I also provide an output_file argument so that each report has a unique name. My code would look something like this:\n\ndf &lt;- readr::read_csv(\"grades.csv\")\n\nfor (i in 1:nrow(df)) {\n    student &lt;- df[i, ] # Each row is a unique student\n    quarto::quarto_render(\n        input = \"template.qmd\",\n        output_file = paste0(\"feedback-\", student$name, \".pdf\"),\n        execute_params = list(\n            name = student$name,\n            grade = student$grade\n        )\n    )\n}\n\nIf I ran this code, I would end up with a lot of PDF files in my directory, each with the name ‚Äúfeedback-{name}.pdf‚Äù, where ‚Äú{name}‚Äù is replaced with each student‚Äôs name (e.g.¬†‚Äúfeedback-John.pdf‚Äù).\n\nAside for the {purrr} people: Yes I know there are other ways to iterate, but for this specific purpose I prefer loops as I find it easier for passing parameters (especially if there are multiple parameters)."
  },
  {
    "objectID": "blog/2023-02-28-parameterized-pdfs-with-quarto/index.html#passing-data-frames-as-parameters",
    "href": "blog/2023-02-28-parameterized-pdfs-with-quarto/index.html#passing-data-frames-as-parameters",
    "title": "Render parameterized reports with Quarto",
    "section": "Passing data frames as parameters",
    "text": "Passing data frames as parameters\nSince Quarto is a separate program from R, it doesn‚Äôt know what a data frame is, so if you pass a data frame object as a parameter in execute_params, it will convert it to a list. This issue was posted in the Posit Community forum here.\nAfter posting about the issue in the Fediverse, both Micka√´l Canouil and Garrick Aden-Buie suggested using the {jsonlite} package to serialize the data frame to pass it as a parameter and then un-serialize it back to a data frame inside the .qmd file. Turns out this worked perfectly!\nThe specific functions I use to handle the job are jsonlite::toJSON() and jsonlite::fromJSON(). In the quarto::quarto_render() command, I have to serialize the data frame inside the parameter list like so:\n\nquarto::quarto_render(\n    input = \"template.qmd\",\n    execute_params = list(\n        df = jsonlite::toJSON(df), # Serialize the data frame\n        month = month\n    )\n)\n\nThen inside my ‚Äútemplate.qmd‚Äù file I un-serialize it back to a data frame inside a code chunk with the following line:\n\ndf &lt;- jsonlite::fromJSON(params$df)\n\nFrom there on I can use the df object anywhere in my ‚Äútemplate.qmd‚Äù file as a data frame. The reason this isn‚Äôt an issue when using RMarkdown is that RMarkdown runs inside R, so it ‚Äúknows‚Äù what a data frame is throughout the whole process.\nIn the ‚Äúdata-frames‚Äù example, I create monthly summary tables of flight departure and arrival delays by airline using the {nycflights} package.\nIn this specific example, an easier approach would be to simply pass the ‚Äúmonth‚Äù as a parameter to the ‚Äútemplate.qmd‚Äù file and then compute the summary table there (this is in fact my recommended approach if possible). But that requires that the data be accessible from outside the ‚Äútemplate.qmd‚Äù file (e.g.¬†saved to disc), and that the summary calculations be relatively fast. If, for example, reading in and summarizing the data is computationally expensive, then it may be easier to do what I have done in this example, which is first read in and summarize all the data, then pass along the summary data frame to the ‚Äútemplate.qmd‚Äù file as a serialized data frame."
  },
  {
    "objectID": "blog/2023-02-28-parameterized-pdfs-with-quarto/index.html#rendering-to-a-different-directory",
    "href": "blog/2023-02-28-parameterized-pdfs-with-quarto/index.html#rendering-to-a-different-directory",
    "title": "Render parameterized reports with Quarto",
    "section": "Rendering to a different directory",
    "text": "Rendering to a different directory\nUnfortunately, at least at the moment it appears that quarto::quarto_render() is not capable of rendering an output file to any location other than the current directory. I noted this in the quarto-cli discussion forums here. The best solution for now seems to be to simply render the output and then copy it over to a desired output directory.\nIn practice, this is a bit cumbersome as there are a number of different conditions to consider that make the copy-pasting not so simple, so my solution was to write my own custom function that works as a wrapper around quarto::quarto_render() and allows the user to provide an optional output_dir for where the output file will be moved post-rendering.\nI have put this function inside my person R package {jph}, which you can install if you wish to use it yourself. I named the function quarto_render_move(), which renders and then optionally moves the file to a desired location. The function source is available here.\nIn practice, it works as a drop-in replacement for quarto::quarto_render(). Here is an example:\n\njph::quarto_render_move(\n    input = \"template.qmd\",\n    output_file = \"feedback-student.pdf\",\n    output_dir = \"output_folder\",\n    execute_params = list(\n        name = \"Paul\",\n        grade = \"98%\"\n    )\n)\n\nUsing this code, the output file would be placed inside a folder called ‚Äúoutput_folder‚Äù."
  },
  {
    "objectID": "blog/2021-03-25-customizing-distill-with-htmltools-and-css/index.html",
    "href": "blog/2021-03-25-customizing-distill-with-htmltools-and-css/index.html",
    "title": "Customizing distill with {htmltools} and CSS",
    "section": "",
    "text": "One of the things I love about {distill} as a site builder is that it is super light weight. It comes out of the box with very few bells and whistles, enabling you to create a site from scratch in minutes. I tried using {blogdown} with the Hugo Academic theme, but in the end I found the overall configuration a bit overwhelming, even with the guidance of Alison Hill‚Äôs incredible post on how to do it (btw, if you want to make a blogdown site, you totally should read her posts on blogdown). Distill was just simpler, so I dove in.\nThat said, once I did get my distill site running, I found myself longing for some of the really cool features I‚Äôve seen on peoples‚Äô blogdown sites, like Alison Hill‚Äôs site (if you can‚Äôt tell, Alison‚Äôs work has been a major source of inspiration for me). But then I realized, ‚Äúwait a minute‚Ä¶I‚Äôm working in R, and whenever I want some functionality that doesn‚Äôt yet exist, I can just write my own functions!‚Äù\nSo that‚Äôs what I set out to do - write a bunch of functions and hack away at CSS to construct the features I wanted. This post walks through my general strategy and then shows how I implemented some of the features on my site."
  },
  {
    "objectID": "blog/2021-03-25-customizing-distill-with-htmltools-and-css/index.html#side-note-on-academic-icons",
    "href": "blog/2021-03-25-customizing-distill-with-htmltools-and-css/index.html#side-note-on-academic-icons",
    "title": "Customizing distill with {htmltools} and CSS",
    "section": "Side note on academic icons",
    "text": "Side note on academic icons\nThe distill package supports fontawesome icons out of the box, but if you want to include academic icons you‚Äôll need to include a link to the style sheet in the page header. You can quickly add it to all pages by making a header.html file in your root directory that contains this line:\n\n&lt;link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css\"&gt;\n\nThen in your _site.yml you can add it to every page by changing the output parameter:\noutput:\n  distill::distill_article:\n    includes:\n      in_header:\n      - header.html"
  },
  {
    "objectID": "blog/2021-03-25-customizing-distill-with-htmltools-and-css/index.html#float-a-single-image",
    "href": "blog/2021-03-25-customizing-distill-with-htmltools-and-css/index.html#float-a-single-image",
    "title": "Customizing distill with {htmltools} and CSS",
    "section": "Float a single image",
    "text": "Float a single image\nIf you have just a single image that you want to wrap text around, you can do it like this:\n:::float-image\n\n```{r out.width='150px', out.extra='style=\"float:left; padding:10px\"', echo=FALSE}\nknitr::include_graphics(\"path/to/image\")\n```\n\nHere is some text you want to wrap around the image.\n:::\nYou can name the div whatever you want - I just used float-image to be descriptive. I included all the CSS needed to float the image in the code chunk settings: out.width='150px', out.extra='style=\"float:left; padding:10px\"'. You may want to adjust the padding to fit your site‚Äôs look and feel, but this should be all you need to get the job done."
  },
  {
    "objectID": "blog/2021-03-25-customizing-distill-with-htmltools-and-css/index.html#float-multiple-images",
    "href": "blog/2021-03-25-customizing-distill-with-htmltools-and-css/index.html#float-multiple-images",
    "title": "Customizing distill with {htmltools} and CSS",
    "section": "Float multiple images",
    "text": "Float multiple images\nSince I use this layout frequently, I decided to define two classes, float-left and float-right, in my jhelvy.css theme that style any images in a div with those classes to float left or right, with a little padding:\n\n.float-left img {\n    float:left;\n    padding: 5px 10px 5px 0px;\n}\n\n.float-right img {\n    float:right;\n    padding: 5px 0px 5px 10px;\n}\n\n\nNow to float an image and wrap text around it, all I need to do is use one of those classes for the div name, and any images between the ::: marks will be floated left or right:\n:::float-left\n\n```{r, out.width='150px'}\nknitr::include_graphics(\"path/to/image\")\n```\n\nHere is some text you want to wrap around the image.\n:::\nYou can use whatever method you want to insert images, like knitr::include_graphics() or just insert direct html (which is what I actually end up doing most often).\n\nCaveat: Anything in the div created by ::: will be masked to the table of contents, so I don‚Äôt recomment wrapping a whole article inside ::: to float multiple images (though you could) and instead recommend wrapping just the elements you want to float."
  },
  {
    "objectID": "blog/2021-10-19-monte-carlo-bridge-game/index.html",
    "href": "blog/2021-10-19-monte-carlo-bridge-game/index.html",
    "title": "Simulating the Squid Game bridge scene in R",
    "section": "",
    "text": "If you had a Netflix account in 2021, chances are you‚Äôve at least heard of Squid Game ‚Äì a South Korean survival drama in which players play a series of children‚Äôs games for the chance to win a large sum of money, with the penalty of death if they lose. The show is like a mixture of Richard Connell‚Äôs The Most Dangerous Game, the Hunger Games, and the horror stories of Edgar Allan Poe. It quickly became the #1 most most-watched show after just one week of being released.\n\nSPOILER ALERT: I mention a few details in this post that might be spoilers if you haven‚Äôt yet watched the show.\n\nIn Episode 7, the remaining 16 players play a game where they must cross a glass bridge with 18 steps. At each step, the lead player must choose between two glass panes ‚Äì one made of tempered glass strong enough to support two players, and the other of regular glass that will shatter if stepped on, in which case the player will plummet to their death. You can watch the scene here.\nWhen I watched the episode, I immediately started trying to calculate the expected number of survivors for the game. While seemingly straightforward, the problems is a bit more complex when you realize that each person behind the leader learns information from the leader‚Äôs choices. That is, if the lead player chooses the ‚Äúnot safe‚Äù pane, that player dies, but every remaining player now knows which glass pane is ‚Äúsafe‚Äù at that step.\nRather than try and work the math, I decided to take a Monte Carlo approach ‚Äì just simulate a bunch of trials of the game, then count up how many players ‚Äúsurvived‚Äù in each trial.\n\nDefining the simulation\nThe first step I took in trying to simulate the game is to simplify the problem. The actual game has two glass panes (one ‚Äúsafe‚Äù and one ‚Äúnot safe‚Äù) at each step in the bridge. This same situation can be modeled with a series of single steps where the lead player has a 50% chance of surviving at each step. If the lead player steps on a ‚Äúnot safe‚Äù pane, we mark that player as dead and replace that pane with a ‚Äúsafe‚Äù one, allowing all remaining players to safely cross it.\nTo run a simulation, I first had to create the players, which I modeled using a simple data.table of 1s and 0s for ‚Äúalive‚Äù and ‚Äúdead‚Äù. Everyone starts out alive.\n\n# Create an initial data.table of players\nlibrary(data.table)\n\nnum_players &lt;- 16\nplayers &lt;- data.table(player = seq(num_players), alive = 1)\nplayers\n\n#&gt;     player alive\n#&gt;  1:      1     1\n#&gt;  2:      2     1\n#&gt;  3:      3     1\n#&gt;  4:      4     1\n#&gt;  5:      5     1\n#&gt;  6:      6     1\n#&gt;  7:      7     1\n#&gt;  8:      8     1\n#&gt;  9:      9     1\n#&gt; 10:     10     1\n#&gt; 11:     11     1\n#&gt; 12:     12     1\n#&gt; 13:     13     1\n#&gt; 14:     14     1\n#&gt; 15:     15     1\n#&gt; 16:     16     1\n\n\nTo simulate a single game, I created a run_game() function that iterates through a specified number of bridge steps, each with a 50% chance of being ‚Äúsafe‚Äù. The function iterates through each step until all ‚Äúsafe‚Äù panels are known, at which point the remaining ‚Äúalive‚Äù players are assumed to all be able to safely finish crossing the bridge (I am assuming that all players have sufficient time to cross the bridge).\n\n# Define a function for simulating one game\nrun_game &lt;- function(players, num_steps) {\n    lead_player &lt;- 1\n    for (step in seq(num_steps)) {\n        # 50% chance that the pane is safe\n        if (sample(c(TRUE, FALSE), 1)) {\n            # The pane is safe, keep going!\n            next\n        } else {\n            # The pane broke üíÄ\n            # Before continuing, check if any players are still alive\n            if (sum(players$alive) == 0) { return(players$alive) }\n            # The lead player died\n            players$alive[lead_player] &lt;- 0\n            lead_player &lt;- lead_player + 1\n        }\n    }\n    return(players$alive)\n}\n\nWith that, let‚Äôs run one game of 18 steps and 16 players (same as in the show):\n\n# Run one iteration of the game\nsingle_game &lt;- run_game(players, num_steps = 18)\nsingle_game\n\n#&gt;  [1] 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1\n\n\nSo after one game, we had 4 survivors. But of course if we want to get an estimate of the expected number of survivors, we need to run lots of trials of the game (a lot of bits are about to die).\n\n\nEstimating the expected number of survivors\nI ran my trials inside a data.table, a simulation strategy I picked up from Grant McDermott and his wonderful post on efficient simulations in R.\n\n# Run the main trials\n\n# Repeat the \"players\" data.table for each trial\nnum_trials &lt;- 10000\nsims &lt;- players[rep(seq(num_players), num_trials),]\n\n# Keep track of the trial number\nsims[, trial := rep(seq(num_trials), each = num_players)]\n\n# Now run the simulation for each trial\nsims[, alive := run_game(.SD, num_steps = 18), by = trial]\n\nIn addition to being very fast, one really nice thing about running the trials using {data.table} is that you get all of the results back in a nicely-formatted data.table, which you can then use to compute all sorts of statistics.\nFor example, if you wanted to see the outcome of an individual trial, just filter for it:\n\n# View one trial outcome\nsims[trial == 42]\n\n#&gt;     player alive trial\n#&gt;  1:      1     0    42\n#&gt;  2:      2     0    42\n#&gt;  3:      3     0    42\n#&gt;  4:      4     0    42\n#&gt;  5:      5     0    42\n#&gt;  6:      6     0    42\n#&gt;  7:      7     0    42\n#&gt;  8:      8     0    42\n#&gt;  9:      9     0    42\n#&gt; 10:     10     1    42\n#&gt; 11:     11     1    42\n#&gt; 12:     12     1    42\n#&gt; 13:     13     1    42\n#&gt; 14:     14     1    42\n#&gt; 15:     15     1    42\n#&gt; 16:     16     1    42\n\n\nOf course, we can also use the trials to compute the expected number of survivors from the game. Since the outcomes are discrete, I take median number of survivors across all trials to reflect the expected number of survivors:\n\n# Compute the expected number of survivors across all trials\ntrials_counts &lt;- sims[, .(count = sum(alive)), by = trial]\nexpected_survivors &lt;- median(trials_counts$count)\nexpected_survivors\n\n#&gt; [1] 7\n\n\nThe simulation suggests that we should expect 7 players to survive when running a game with 16 players and 18 steps. When we look at the distribution of trial outcomes, we can also see that there is a pretty good chance of having 6 or 8 survivors in any one round of the game:\n\n# Plot the distribution of survivors across all trials\nlibrary(ggplot2)\n\ntrial_count_summary &lt;- as.data.frame(table(trials_counts$count))\nnames(trial_count_summary) &lt;- c(\"n_survivors\", \"count\")\n\nggplot(trial_count_summary) +\n  geom_col(aes(x = n_survivors, y = count), width = 0.1) + \n  theme_bw() +\n  theme(panel.grid.minor = element_blank()) +\n  labs(\n    title = \"Outcomes of 10,000 trials\",\n    x = \"Number of survivors\", \n    y = \"Count\"\n  )\n\n\n\n\n\n\n\n\n\n\nChoose wisely\nWhile the expected number of survivors from these trials is higher than the actual number in the TV series (only 3 survive), keep in mind that these trials reflect ideal conditions in which all the players act strictly rationally. In the show, multiple players die as a result of the selfish or revengeful actions of other players, not strictly because of the breaking glass panes.\nBut perhaps the more important question from the perspective of the players is:\n\n‚ÄúWhich number should I choose?‚Äù\n\nObviously choosing a larger number closer to the back of the line gives the player a higher probability of survival because the players in front identify all the ‚Äúsafe‚Äù glass panes. But how likely would you be to survive if you chose a number near the middle (which most players in the TV series chose first)?\nSince we have all the results of every trial outcome for every player in a convenient data.table, computing the probability of surviving for each player is straightforward:\n\n# Plot the probability of survival based on the player order number\nsurvival_summary &lt;- sims[, .(p_survive = sum(alive) / num_trials), by = player]\n\nggplot(survival_summary) +\n  geom_point(aes(x = player, y = p_survive)) + \n  scale_y_continuous(labels = scales::percent) +\n  scale_x_continuous(breaks = seq(16)) +\n  theme_bw() +\n  theme(panel.grid.minor = element_blank()) +\n  labs(\n    title = \"Probability of survival based on player order number\",\n    x = \"Player order number\", \n    y = \"Probability\"\n  )\n\n\n\n\n\n\n\n\nSo even though the expected number of survivors is 7 out of 16 players, those survivors are overwhelmingly more likely to be the players who chose the highest order numbers.\n\n\nHow many steps to include?\nOne final question I had was what if the game designers chose to include more steps in the bridge? Because this was not supposed to be the last game, the designers needed to make sure at least two players survived, otherwise the games would simply end.\nWe can see from the previous simulations that with 16 players, the choice of 18 steps already puts a small (but non-zero) probability on having less than two survivors:\n\n# Probability of having less than two survivors\nsum(trials_counts$count &lt; 2) / num_trials\n\n#&gt; [1] 0.0036\n\n\nOf course this is probably an under-estimate of the true probability of having less than two survivors because the players are human beings who tend to make irrational choices when playing a deadly game (as we saw play out in the TV series version of the game).\nStill, what if the game designers were more risk seeking? How many steps could they include if they were willing to live with, for example, a 5% chance of having less than 2 players remaining at the end of the bridge game?\nTo answer that, we have to re-run our simulations, but with an increasing number of steps. To keep things simple, I run 1,000 iterations of the game over an increasing number of steps from 10 to 30:\n\n# Re-run the trials using an increasing number of bridge steps (10 to 30)\n\n# Repeat the \"players\" data.table for each trial\nmin_num_steps &lt;- 10\nmax_num_steps &lt;- 30\nstep_trials &lt;- seq(min_num_steps, max_num_steps, by = 1)\nnum_step_trials &lt;- length(step_trials)\nnum_trials &lt;- 1000\nstep_sims &lt;- players[rep(seq(num_players), num_trials*num_step_trials),]\n\n# Keep track of the trial number and the step number\nstep_sims[, trial := rep(seq(num_trials*num_step_trials), each = num_players)]\nstep_sims[, steps := rep(step_trials, each = num_players*num_trials)]\n\n# Now run the simulation for each trial\nstep_sims[, alive := run_game(.SD, num_steps = unique(steps)), by = trial]\n\nNow I can compute the probability of having less than two survivors for each step size:\n\n# Compute probability of having less than two survivors for each step size\nstep_counts &lt;- step_sims[, .(count = sum(alive)), by = c(\"trial\", \"steps\")]\nstep_summary &lt;- step_counts[, .(p_under2 = sum(count &lt; 2) / num_trials), by = steps]\n\nggplot(step_summary) +\n  geom_point(aes(x = steps, y = p_under2)) + \n  scale_y_continuous(labels = scales::percent) +\n  scale_x_continuous(breaks = step_trials) +\n  theme_bw() +\n  theme(panel.grid.minor = element_blank()) +\n  labs(\n    title = \"Probability of having less than two remaining players\",\n    x = \"Number of bridge steps\", \n    y = \"Probability\"\n  )\n\n\n\n\n\n\n\n\nI found it interesting that 18 steps seems to be the point at which the probability of having less than two remaining players begins to increase from essentially 0. With just a few more steps, the probability rapidly increases:\n\nstep_summary[steps %in% seq(18, 23)]\n\n#&gt;    steps p_under2\n#&gt; 1:    18    0.005\n#&gt; 2:    19    0.008\n#&gt; 3:    20    0.024\n#&gt; 4:    21    0.040\n#&gt; 5:    22    0.057\n#&gt; 6:    23    0.107\n\n\nOkay, that‚Äôs it! I‚Äôm sure I probably made an error somewhere - let me know if you find one, and hopefully this was an interesting example of how to conduct some relatively efficient Monte Carlo simulations in R with the help of the {data.table} package.\n\n\nUpdate 1 - including time\nUpdated October 22, 2021\nMany people on twitter and reddit had some great suggestions about this post. In particular, @evalparse had a brilliant, one-line solution for simulating the number of survivors in one game:\n\n\n\nOne critique that was mentioned multiple times was that my simulations left out a critical element in the game: time. In the show, the players had just 16 minutes to cross the bridge, otherwise all of the glass panes shatter and anyone left behind dies. I originally omitted time for simplicity, but looking back at it now this is a pretty crucial element in the game because it means that the latter order numbers aren‚Äôt necessarily so safe after all ‚Äì the further back in line you are, the higher risk you face of running out of time.\nSo, here‚Äôs one attempt at including time in the simulation.\nMy immediate thought was to assume a distribution for the amount of time delay it takes for a player to take a step and then sample from that distribution for each player in each trial of the game. The key question is what should that distribution look like?\nObviously time needs to be positive, so I can‚Äôt use distributions that could have negative numbers. But time also can‚Äôt go on forever ‚Äì as we saw in the show, the people in the back of the line start to get impatient if the lead player takes too long and might ‚Äúencourage‚Äù them to make a choice.\nSince I didn‚Äôt have any real-world data to inform my decision (I sure hope there are no real-world data on this!), I decided to use the data from the show itself. I re-watched the scene and timed how long each lead player took to take a step. Time in the show isn‚Äôt quite preserved because the camera cuts to other scenes, there‚Äôs slow motion, etc., but many of the steps could be timed, so here‚Äôs what I measured:\n\n# Lead player step times in seconds\nseconds &lt;- c(36, 20, 25, 49, 66, 22, 112, 10, 115, 184, 144, 18, 22, 36, 28, 15, 10)\nsummary(seconds)\n\n#&gt;    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#&gt;   10.00   20.00   28.00   53.65   66.00  184.00\n\n\nMost lead players moved relatively quickly, with a median of just 28 seconds. But a few players took longer. In the show, player 9 (the bully guy) took quite a long time, and he might have taken longer if he wasn‚Äôt forced to move by the woman he scorned.\nGiven these considerations, I chose to model the step time with a log-normal distribution because it prevents negative times and it has a long tail for those one or two players who might take a long time to move. Here are the parameters that fit these data, using the lovely fitdistr() function from the {MASS} package:\n\nfit &lt;- MASS::fitdistr(seconds, \"log-normal\")\nfit\n\n#&gt;     meanlog      sdlog  \n#&gt;   3.5781872   0.8824273 \n#&gt;  (0.2140201) (0.1513350)\n\n\nLet‚Äôs take a quick visual check of the fit:\n\nmeanlog &lt;- fit$estimate[1]\nsdlog &lt;- fit$estimate[2]\nggplot() + \n    geom_histogram(aes(x = seconds, y = ..density..), \n                   binwidth = 10, fill = \"grey60\") +\n    geom_density(aes(x = rlnorm(1000, meanlog, sdlog)), color = \"red\") +\n    scale_x_continuous(limits = c(0, 200)) +\n    theme_bw() + \n    labs(\n        title = \"Log-normal fit of time delay for each lead player step\",\n        x = \"Time (seconds)\",\n        y = \"Density\"\n    )\n\n\n\n\n\n\n\n\nIs it a good fit? Eh, sort of?\nDo I have time to do a better job? Not really.\nOne issue with the log-normal though is that you can occasionally get a really high number out on that long tail, which I would think is highly unlikely because at some point the next player is just going to push you off the bridge. So I censored my log-normal fit at 200 seconds. So, with this in mind, I created a new run_game_timed() function that includes a time delay for each step, sampling from a censored log-normal distribution.\n\n# Modified function for simulating one game with time\nrun_game_timed &lt;- function(players, num_steps, max_seconds, meanlog, sdlog) {\n    lead_player &lt;- 1\n    cum_time &lt;- 0\n    for (step in seq(num_steps)) {\n        cum_time &lt;- cum_time + min(rlnorm(1, meanlog, sdlog), 200)\n        if (cum_time &gt;= max_seconds) { return(players$alive*0) }\n        if (sample(c(TRUE, FALSE), 1)) { next }\n        if (sum(players$alive) == 0) { return(players$alive) }\n        players$alive[lead_player] &lt;- 0\n        lead_player &lt;- lead_player + 1\n    }\n    return(players$alive)\n}\n\nNow I can re-run all the trials and compute a new expected number of survivors:\n\n# Re-run trials\nnum_trials &lt;- 10000\nsims_timed &lt;- players[rep(seq(num_players), num_trials),]\nsims_timed[, trial := rep(seq(num_trials), each = num_players)]\nsims_timed[, alive := run_game_timed(\n    .SD, num_steps = 18, max_seconds = 16*60, meanlog, sdlog), by = trial]\n\n# Compute the new expected number of survivors across all trials\ntrials_counts_timed &lt;- sims_timed[, .(count = sum(alive)), by = trial]\nexpected_survivors &lt;- median(trials_counts_timed$count)\nexpected_survivors\n\n#&gt; [1] 5\n\n\nAs would be expected, the expected number of survivors decreased, which is now closer to the actual number of survivors in the show (3).\nBut how about the distribution? Well, by introducing time, all we‚Äôve really done is modify the original distribution to be ‚Äúzero-inflated‚Äù (which is super common in data sets you run across in the wild):\n\n# Plot the distribution of survivors across all trials\ntrial_count_timed_summary &lt;- as.data.frame(table(trials_counts_timed$count))\nnames(trial_count_timed_summary) &lt;- c(\"n_survivors\", \"count\")\nggplot(trial_count_timed_summary) +\n  geom_col(aes(x = n_survivors, y = count), width = 0.1) +\n  theme_bw() +\n  theme(panel.grid.minor = element_blank()) +\n  labs(\n    title = \"Outcomes of 10,000 trials\",\n    x = \"Number of survivors\",\n    y = \"Count\"\n  )\n\n\n\n\n\n\n\n\nOf course, this also impacts the likelihood of survival for each individual player. As might be expected, zero-inflating the distribution of survivors simply reduces the probability of survival for all players, with the higher-number players still ranking the most likely to survive:\n\n# Plot the probability of survival based on the player order number\nsurvival_summary_timed &lt;- sims_timed[, \n    .(p_survive = sum(alive) / num_trials), by = player]\nggplot(survival_summary_timed) +\n  geom_point(aes(x = player, y = p_survive)) +\n  scale_y_continuous(labels = scales::percent) +\n  scale_x_continuous(breaks = seq(16)) +\n  theme_bw() +\n  theme(panel.grid.minor = element_blank()) +\n  labs(\n    title = \"Probability of survival based on player order number\",\n    x = \"Player order number\",\n    y = \"Probability\"\n  )\n\n\n\n\n\n\n\n\nThis is of course is not quite what might be expected. Instead, I would expect the probability to be a tiny bit lower for the very last player or two as they could get left behind. But I chose to ignore feature as the lead player delay seemed to be a much bigger factor in determining survival. Plus, if you have an issue with how ‚Äúrealistic‚Äù my modeling is, I would encourage you to remember the context of this entire exercise (if you think anything about this is realistic, please see a psychiatrist).\n\n\nUpdate 2\nUpdated December 21, 2021\nLukas Gr√∂ninger wrote a similar post on his blog where he also provides the mathematical solution to the expected number of survivors - check it out!\n\n\nUpdate 3\nUpdated May 9, 2022\nHenk Tijms, Professor Emeritus at VU University Amsterdam, wrote a fantastic article introducing the concept of Markov Chains. In the article, he uses the Squid Game bridge scene as an example (along with several other classic probability problems, like Egg Russian Roulette) to demonstrate the power of Markov Chains. In his analysis he computes the expected number of survivors, the probability of survival for each player, and the probability distribution of the number of survivors. The Squid Game example starts on page 7.\n\n\nAppendix\nHere is the combined code for this entire simulation:\n\n# Rmd settings\nknitr::opts_chunk$set(\n    warning    = FALSE,\n    message    = FALSE,\n    comment    = \"#&gt;\",\n    fig.align  = \"center\",\n    fig.path   = \"figs/\",\n    fig.retina = 3\n)\nset.seed(5678)\n# Create an initial data.table of players\nlibrary(data.table)\n\nnum_players &lt;- 16\nplayers &lt;- data.table(player = seq(num_players), alive = 1)\nplayers\n# Define a function for simulating one game\nrun_game &lt;- function(players, num_steps) {\n    lead_player &lt;- 1\n    for (step in seq(num_steps)) {\n        # 50% chance that the pane is safe\n        if (sample(c(TRUE, FALSE), 1)) {\n            # The pane is safe, keep going!\n            next\n        } else {\n            # The pane broke üíÄ\n            # Before continuing, check if any players are still alive\n            if (sum(players$alive) == 0) { return(players$alive) }\n            # The lead player died\n            players$alive[lead_player] &lt;- 0\n            lead_player &lt;- lead_player + 1\n        }\n    }\n    return(players$alive)\n}\n# Run one iteration of the game\nsingle_game &lt;- run_game(players, num_steps = 18)\nsingle_game\n# Run the main trials\n\n# Repeat the \"players\" data.table for each trial\nnum_trials &lt;- 10000\nsims &lt;- players[rep(seq(num_players), num_trials),]\n\n# Keep track of the trial number\nsims[, trial := rep(seq(num_trials), each = num_players)]\n\n# Now run the simulation for each trial\nsims[, alive := run_game(.SD, num_steps = 18), by = trial]\n# View one trial outcome\nsims[trial == 42]\n# Compute the expected number of survivors across all trials\ntrials_counts &lt;- sims[, .(count = sum(alive)), by = trial]\nexpected_survivors &lt;- median(trials_counts$count)\nexpected_survivors\n# Plot the distribution of survivors across all trials\nlibrary(ggplot2)\n\ntrial_count_summary &lt;- as.data.frame(table(trials_counts$count))\nnames(trial_count_summary) &lt;- c(\"n_survivors\", \"count\")\n\nggplot(trial_count_summary) +\n  geom_col(aes(x = n_survivors, y = count), width = 0.1) + \n  theme_bw() +\n  theme(panel.grid.minor = element_blank()) +\n  labs(\n    title = \"Outcomes of 10,000 trials\",\n    x = \"Number of survivors\", \n    y = \"Count\"\n  )\n# Plot the probability of survival based on the player order number\nsurvival_summary &lt;- sims[, .(p_survive = sum(alive) / num_trials), by = player]\n\nggplot(survival_summary) +\n  geom_point(aes(x = player, y = p_survive)) + \n  scale_y_continuous(labels = scales::percent) +\n  scale_x_continuous(breaks = seq(16)) +\n  theme_bw() +\n  theme(panel.grid.minor = element_blank()) +\n  labs(\n    title = \"Probability of survival based on player order number\",\n    x = \"Player order number\", \n    y = \"Probability\"\n  )\n# Probability of having less than two survivors\nsum(trials_counts$count &lt; 2) / num_trials\n# Re-run the trials using an increasing number of bridge steps (10 to 30)\n\n# Repeat the \"players\" data.table for each trial\nmin_num_steps &lt;- 10\nmax_num_steps &lt;- 30\nstep_trials &lt;- seq(min_num_steps, max_num_steps, by = 1)\nnum_step_trials &lt;- length(step_trials)\nnum_trials &lt;- 1000\nstep_sims &lt;- players[rep(seq(num_players), num_trials*num_step_trials),]\n\n# Keep track of the trial number and the step number\nstep_sims[, trial := rep(seq(num_trials*num_step_trials), each = num_players)]\nstep_sims[, steps := rep(step_trials, each = num_players*num_trials)]\n\n# Now run the simulation for each trial\nstep_sims[, alive := run_game(.SD, num_steps = unique(steps)), by = trial]\n# Compute probability of having less than two survivors for each step size\nstep_counts &lt;- step_sims[, .(count = sum(alive)), by = c(\"trial\", \"steps\")]\nstep_summary &lt;- step_counts[, .(p_under2 = sum(count &lt; 2) / num_trials), by = steps]\n\nggplot(step_summary) +\n  geom_point(aes(x = steps, y = p_under2)) + \n  scale_y_continuous(labels = scales::percent) +\n  scale_x_continuous(breaks = step_trials) +\n  theme_bw() +\n  theme(panel.grid.minor = element_blank()) +\n  labs(\n    title = \"Probability of having less than two remaining players\",\n    x = \"Number of bridge steps\", \n    y = \"Probability\"\n  )\nstep_summary[steps %in% seq(18, 23)]\n# Lead player step times in seconds\nseconds &lt;- c(36, 20, 25, 49, 66, 22, 112, 10, 115, 184, 144, 18, 22, 36, 28, 15, 10)\nsummary(seconds)\nfit &lt;- MASS::fitdistr(seconds, \"log-normal\")\nfit\nmeanlog &lt;- fit$estimate[1]\nsdlog &lt;- fit$estimate[2]\nggplot() + \n    geom_histogram(aes(x = seconds, y = ..density..), \n                   binwidth = 10, fill = \"grey60\") +\n    geom_density(aes(x = rlnorm(1000, meanlog, sdlog)), color = \"red\") +\n    scale_x_continuous(limits = c(0, 200)) +\n    theme_bw() + \n    labs(\n        title = \"Log-normal fit of time delay for each lead player step\",\n        x = \"Time (seconds)\",\n        y = \"Density\"\n    )\n# Modified function for simulating one game with time\nrun_game_timed &lt;- function(players, num_steps, max_seconds, meanlog, sdlog) {\n    lead_player &lt;- 1\n    cum_time &lt;- 0\n    for (step in seq(num_steps)) {\n        cum_time &lt;- cum_time + min(rlnorm(1, meanlog, sdlog), 200)\n        if (cum_time &gt;= max_seconds) { return(players$alive*0) }\n        if (sample(c(TRUE, FALSE), 1)) { next }\n        if (sum(players$alive) == 0) { return(players$alive) }\n        players$alive[lead_player] &lt;- 0\n        lead_player &lt;- lead_player + 1\n    }\n    return(players$alive)\n}\n# Re-run trials\nnum_trials &lt;- 10000\nsims_timed &lt;- players[rep(seq(num_players), num_trials),]\nsims_timed[, trial := rep(seq(num_trials), each = num_players)]\nsims_timed[, alive := run_game_timed(\n    .SD, num_steps = 18, max_seconds = 16*60, meanlog, sdlog), by = trial]\n\n# Compute the new expected number of survivors across all trials\ntrials_counts_timed &lt;- sims_timed[, .(count = sum(alive)), by = trial]\nexpected_survivors &lt;- median(trials_counts_timed$count)\nexpected_survivors\n# Plot the distribution of survivors across all trials\ntrial_count_timed_summary &lt;- as.data.frame(table(trials_counts_timed$count))\nnames(trial_count_timed_summary) &lt;- c(\"n_survivors\", \"count\")\nggplot(trial_count_timed_summary) +\n  geom_col(aes(x = n_survivors, y = count), width = 0.1) +\n  theme_bw() +\n  theme(panel.grid.minor = element_blank()) +\n  labs(\n    title = \"Outcomes of 10,000 trials\",\n    x = \"Number of survivors\",\n    y = \"Count\"\n  )\n# Plot the probability of survival based on the player order number\nsurvival_summary_timed &lt;- sims_timed[, \n    .(p_survive = sum(alive) / num_trials), by = player]\nggplot(survival_summary_timed) +\n  geom_point(aes(x = player, y = p_survive)) +\n  scale_y_continuous(labels = scales::percent) +\n  scale_x_continuous(breaks = seq(16)) +\n  theme_bw() +\n  theme(panel.grid.minor = element_blank()) +\n  labs(\n    title = \"Probability of survival based on player order number\",\n    x = \"Player order number\",\n    y = \"Probability\"\n  )\n\n\n\n\n\n Back to top"
  }
]